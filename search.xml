<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[福格行为模型]]></title>
    <url>%2F2023%2F08%2F21%2FBJ_Foog's_Behaviour_Model%2F</url>
    <content type="text"><![CDATA[本文章简单介绍《福格行为模型》。推荐语：如果你想掌控，理解自己的行为，完善自己的生活，《福格行为模型》从行为的核心本质，以及配套的思考方法论，以及具体的建议，让你能够彻底的理解行为，从而养成好习惯，改掉坏习惯，做一个自律有方法的人. 前言福格行为模型: B(Behavior) = M(Motivation) + A (Ability) + P (Prompt) 即 行为=动机+能力+提示 其他一些建议1、建议从序言到文章的附录，最好都阅读一遍。 最后的附录可以作为工具，随时翻阅 2、建议每张的练习都要阅读玩，实际练习下，能够让你真正落地到现实]]></content>
      <tags>
        <tag>个人成长</tag>
        <tag>荐书</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Druid-Source-Block踩坑]]></title>
    <url>%2F2021%2F09%2F27%2FDruid-Source-Block%2F</url>
    <content type="text"><![CDATA[本文分享下最近一个很有意思的线上问题。 问题现象: 业务上游发现所有的请求都超时 问题定位 业务上游发现所有的请求都超时 去线上机器通过手动调用接口curl http://localhost:8051/rest/status?job_id=1 命令查询，同样阻塞 jstack -l pid 将堆栈打印出来。发现http-nio-8051 线程都是阻塞在com.alibaba.druid.pool.DruidDataSource.takeLast 网上查了一下参考， 是因为连接池被打满并且maxWait=-1，通过查看application.yml，确实是使用的DruidDataSource并且没有设置maxWait. 初步定位到是MySQL连接池被打满，阻塞住了。接下来查找为什么阻塞。 结果发现代码存在如下代码:(这里其实直接看堆栈就可以看出来是哪里阻塞住了) 1234567891011121314#####RestTaskDAO.updateTaskStatus@Transactional(rollbackFor = Exception.class, propagation = Propagation.REQUIRES_NEW) // // 此处使用了REQUIRES_NEW 即每次都创建一个新的事务(即需要新的一个MySQL连接)public void updateTaskStatus(String taskId, String bizType, Integer taskStatus,String msg) &#123; mapper.updateTaskStatus(taskId, bizType, taskStatus, msg);&#125; ####RestTaskMapper.updateTaskStatus @Transactional(rollbackFor = Exception.class, propagation = Propagation.REQUIRES_NEW) // 此处使用了REQUIRES_NEW 即每次都创建一个新的事务(即需要新的一个MySQL连接) @Update(value = &quot;update task set task_status = #&#123;taskStatus&#125;, msg = #&#123;msg&#125; where task_id = #&#123;taskId&#125; and biz_type= #&#123;bizType&#125;&quot;) void updateTaskStatus(@Param(&quot;taskId&quot;) String taskId, @Param(&quot;bizType&quot;) String bizType, @Param(&quot;taskStatus&quot;) Integer taskStatus, @Param(&quot;msg&quot;) String msg); 根据上面的事务嵌套，就是一个updateTaskStatus需要进行两次串行的getConnection。 综上当并发到一定程度的时候(默认是8个)，即同时有8个RestTaskDAO.updateTaskStatus先获取到了MySQL的connection. 大家都需要获取到RestTaskMapper.updateTaskStatus,但是因为maxWait=-1 ，8个RestTaskDAO.updateTaskStatus不会被释放掉，但是又需要8个``RestTaskMapper.updateTaskStatus`, 就陷入了逻辑上的死锁。现象就是所有都卡死在获取MySQL的connection上。 本地复现 设置maxActive为1，在com.alibaba.druid.pool.DruidDataSource#getConnectionInternal打断点。 调用RestTaskDAO.updateTaskStatus。 结果就是发现`com.alibaba.druid.pool.DruidDataSource#getConnectionInternal被调用了两次 第一次RestTaskDAO.updateTaskStatus 下面是堆栈信息 1234567891011doBegin:256, DataSourceTransactionManager (org.springframework.jdbc.datasource)getTransaction:378, AbstractPlatformTransactionManager (org.springframework.transaction.support)createTransactionIfNecessary:474, TransactionAspectSupport (org.springframework.transaction.interceptor)invokeWithinTransaction:289, TransactionAspectSupport (org.springframework.transaction.interceptor)invoke:98, TransactionInterceptor (org.springframework.transaction.interceptor)proceed:186, ReflectiveMethodInvocation (org.springframework.aop.framework)intercept:688, CglibAopProxy$DynamicAdvisedInterceptor(org.springframework.aop.framework)updateTaskStatus:-1, RestTaskDAO$$EnhancerBySpringCGLIB$$39ce0413 // 注意这里 (com.rest.rest.openapi.repository.dao)update:104, RestController (com.rest.rest.openapi.facade.rest)invoke:-1, RestController$$FastClassBySpringCGLIB$$a85862fd (com.rest.rest.openapi.facade.rest)invoke:218, MethodProxy (org.springframework.cglib.proxy) 第二次RestTaskMapper.updateTaskStatus, 下面是具体的堆栈信息 12345678910111213141516doBegin:256, DataSourceTransactionManager (org.springframework.jdbc.datasource)handleExistingTransaction:430, AbstractPlatformTransactionManager (org.springframework.transaction.support)getTransaction:354, AbstractPlatformTransactionManager (org.springframework.transaction.support)createTransactionIfNecessary:474, TransactionAspectSupport (org.springframework.transaction.interceptor)invokeWithinTransaction:289, TransactionAspectSupport (org.springframework.transaction.interceptor)invoke:98, TransactionInterceptor (org.springframework.transaction.interceptor)proceed:186, ReflectiveMethodInvocation (org.springframework.aop.framework)invoke:49, DynamicDataSourceAnnotationInterceptor(com.baomidou.dynamic.datasource.aop)proceed:186, ReflectiveMethodInvocation (org.springframework.aop.framework)invoke:212, JdkDynamicAopProxy (org.springframework.aop.framework)updateTaskStatus:-1, $Proxy141 (com.sun.proxy) // 这里是Mapper代理类, 这里是第二次调用updateTaskStatus:33, RestTaskDAO (com.rest.rest.openapi.repository.dao) // 就是DAOinvoke:-1, RestTaskDAO$$FastClassBySpringCGLIB$$a73442ff(com.rest.rest.openapi.repository.dao)invoke:218, MethodProxy (org.springframework.cglib.proxy)invokeJoinpoint:749, CglibAopProxy$CglibMethodInvocation(org.springframework.aop.framework)proceed:163, ReflectiveMethodInvocation (org.springframework.aop.framework) 再次调用updateStatus接口，就直接被阻塞住了。 解决方案: 去除掉RestTaskMapper.updateTaskStatus上面的Transaction. 并且将RestTaskDAO.updateTaskStatus事务的传播属性改为默认(与主线程使用一个) 设置druid.maxWait具体时间，这里我们结合实际业务是3000ms 复盘原因： 本次主要出现问题的原因主要还是在于对Spring的事务不熟悉，导致乱用出错。]]></content>
      <tags>
        <tag>线上问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊Apollo【基本架构&&核心概念】]]></title>
    <url>%2F2021%2F09%2F27%2Fapollo-1%2F</url>
    <content type="text"><![CDATA[通过本文，你可以了解到Apollo的总体交互流程，整体架构，以及一些核心概念. 前言最近在听杨波老师的微服务课程，对配置中心Apollo十分感兴趣，想深入了解下。所以接下来会逐步通过几篇文章来深入浅出Apollo。本文是第一篇，主要从整体上来感知下。 整体交互模型 核心分三个部分: 用户 配置中心 客户端 核心概念应用(application) 描述: 标识介入应用的唯一标识，后续更改配置都是基于某个应用层次修改 主要场景: 服务隔离环境(enviorent) 描述: 不同环境中，可以配置不同的配置 主要场景: 环境隔离集群(cluster) 描述: 一个应用下不同实例的分组, 不同的cluster，可以有不同的配置 主要场景: 多数据中心，不同数据中心可以有不同的配置:名称空间(namespace) 描述: 一个应用下的不同配置的分组 主要场景: 不同配置的分组(数据库配置，应用元数据配置) 公共组件之间的配置(public) 应用默认有自己的配置(private) 名称空间类型 private私有类型: 只能被所属应用获取 public共有类型: 多应用共享配置，需全局唯一 部门级别共享配置 小组级别共享配置 .. 关联类型(继承类型) : 私有继承共有会覆盖共有类型(缺省默认), 默认共有配置 定制中间件配置场景配置项(Item) 描述: 具体配置。KV结构 Apollo配置唯一标识 私有配置: env+application+cluster+namespace+itemkey 共有配置env+cluster+namespace+itemkey 权限 描述: 编辑，发布，项目管理 角色: 系统管理员: 拥有全部的权限 项目管理员: 可串讲Namespace,cluster,管理项目。 普通用户: 可以查看 权限 Namespace 编辑，创建 Item编辑(不可以发布)，发布(不可编辑)。 系统架构 同时食用波波老师的文章(见参考链接)更佳。 注意: 参考地址中波波老师是分5步逐步演进。我是分为了三步。对应主要是基于下游几个点: V1本质是最原始的配置中心。包含了配置中心Apollo最基本的模块。 对应波波老师演进中的V1 V2本质是解决了V1中Client与服务端服务注册与感知问题。对应波波老师演进中的V2和V3 V3版本本质是解决语言兼容以及其他模块(portal，metaServer等)服务于发现。 对应波波老师演进中的V4和V5 参考大佬微服务架构~携程Apollo配置中心架构剖析]]></content>
      <tags>
        <tag>apollo</tag>
        <tag>权限</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊java线上问题排查]]></title>
    <url>%2F2020%2F08%2F15%2Fjava-troubleshooting%2F</url>
    <content type="text"><![CDATA[因为最近有次是疑似内存溢出，特地去线上排查了下。本篇是总结性的把如何排查Java线上问题做个汇总 内存溢出如何查 什么是内存溢出 简单讲:内存溢出就是在你申请内存的时候，内存不够了。 现象是错误栈带有OutOfMemoryError 出现原因 简单讲分为2种 一种是因为内存泄露(认为原因) 导致内存一直在增加 (解决办法是排查内存溢出的代码块，修复调即可) 另外一种是因为设计上的原因，导致一次性加载数据过多，导致内存溢出(解决办法是有两个: 1 优化代码(不要一次性读取那么多) 2 增加jvm运行内存) 什么是内存泄露 简单讲:内存泄露就是申请到了内存，但是因为某些原因一直无法释放(应该是要释放)。这就是内存泄露 线上问题排查步骤使用jps 确定当前进程 使用jstat 查看当前gc的频率 使用jstat [ option vmid [interval[s|ms] [count]] ] jstat -gcutil 24988 1000 // 对进程pid 24988 查看gc 每1000ms打印一次gc日志 图片中的参数解释 这台服务器的新生代Eden区（E，表示Eden）使用了16.81%（最后）的空间，两个Survivor区（S0、S1，表示Survivor0、Survivor1）分别是0和20.73%，老年代（O，表示Old）使用了43.43%。程序运行以来共发生Minor GC（YGC，表示Young GC）19283次，总耗时212.222秒，发生Full GC（FGC，表示Full GC）7次，Full GC总耗时2.741秒，总的耗时（GCT，表示GC Time）为214.963秒。 找出疯狂FullGC的原因使用jmap命令可以在线简单分析下，也可以dump当时内存情况然后离线分析。 ####### 在线分析 第一种 使用jmap使用./jmap -histo:live pid |head -n num 查看当前程序中存活的对象实例数，以及持有的内存。 上面看起来程序是正常的。 根据参考的大佬博文中的图从上面的图可以看出来，HashTable 有大概5000w+的实例数，以及1.5G左右的数据，大概率是有问题的。 第二种 使用 阿里开源的arthas 。https://alibaba.github.io/arthas/ 可参考教程。arthas提供了丰富的排查命令，具体可以通过链接看下文档. 我下面只放了dashboard 运行后的情况,可以看到线程的执行状态，内存的使用情况都是一目了然 第三种 把线上的内存情况使用jmap -dump:format=b,file=xx.dump pid 把线上内存情况保存下来。 然后从服务器上同步到本地，本地使用jvisualvm 或者是eclips 的MAT来分析。具体可以google下使用教程，这里就不在细讲了。 cpu 飙升怎么查第一步 找到cpu飙升的线程使用ps p pid -L -o pcpu,pid,tid,time,tname,cmd 第一个pid 就是java进程pid使用完之后 找到cpu占用最多的那个tid。 将tid转为16进制使用printf &quot;%x\n&quot; Tid 例如printf &quot;%x\n&quot; 36444 -&gt; “8e5c”. 使用jstack 找到正在运行的代码块jstack -l &lt;pid&gt; | grep &lt;thread-hex-id&gt; -A 10 命令显示出错的堆栈信息 参考大佬 一个Java内存泄漏的排查案例]]></content>
      <tags>
        <tag>java</tag>
        <tag>线上问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊Java中的ThreadLocal]]></title>
    <url>%2F2020%2F08%2F12%2FThreadLocal%2F</url>
    <content type="text"><![CDATA[本篇深度剖析下ThreadLocal。主要从下面几个方面: 为什么要用ThreadLocal ThreadLocal 内部实现原理(原理剖析) ThreadLocal为什么会内存溢出可能性. 为什么要用ThreadLocal通常情况下，我们在方法中需要使用方法外的变量，有下面两种方式: 命名为静态变量 弊端：会有线程不安全的问题 作为方法传参 弊端，改动比较大 所以SUN公司就提出了ThreadLocal。存储变量的时候, ThreadLocal会获取当前线程，并将需要存储的变量存储关联到Thread.threadLocals（实际类型是ThreadLocalMap） 引用中。获取的时候，ThreadLocal会获取当前线程中的threadLocals, 从其获取对应的数据。这样子就避免了线程安全问题，以及方法传参复杂性过高问题。 适用场景从上面的解释来看，ThreadLocal的使用场景，就是在方法内使用方法外的变量，并且不希望对整个项目接口改动，就可以使用ThreadLocal. ThreadLocal 内部实现原理概览: ThreadLocal 实现原理简单讲，就是根据本地的 set12345678910111213141516public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); &#125; // 获取当前线程中的map连接ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals; &#125; // 创建一个新的mappervoid createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue); &#125; ThreadLocalMap主要功能是，根据传入的Threadlocal对象做key,创建一个Entry对象(其中Entry key为弱引用，value为强引用)，存放到数组中。 从上面也可以看出ThreadLoacl 不做实际的存储，是做查找的key 类方法图 set123456789101112131415161718192021222324252627282930313233343536 private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; // We don&apos;t use a fast path as with get() because it is at // least as common to use set() to create new entries as // it is to replace existing ones, in which case, a fast // path would fail more often than not. Entry[] tab = table; int len = tab.length; // 获取ThreadLocal的唯一标识。注意这个threadLocalHashCode 是new ThreadLocal的时候，就已经创建了。并且是final修饰了 int i = key.threadLocalHashCode &amp; (len-1);// 开放定址法 for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; e.value = value; return; &#125; if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125;// 没有命中，创建新的 tab[i] = new Entry(key, value); int sz = ++size; // 如果没有清楚之前旧的entry, 并且sz大于阈值。扩容重新hash // cleanSomeSlots 是清楚key==null 的entry if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash(); &#125; getEntry获取entry 123456789private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; else // 如果直接查找的找不到，使用开放定址法查找，查找不到返回null return getEntryAfterMiss(key, i, e); &#125; remove 移除一个entry123456789101112131415161718/** * Remove the entry for key. */ private void remove(ThreadLocal&lt;?&gt; key) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; if (e.get() == key) &#123; e.clear(); // 重新hash 重新赋值， 如果是碰到了key==null,那么value也是会变成null的 expungeStaleEntry(i); return; &#125; &#125; &#125; get &amp;&amp; removeget其实就是ThreadLocalMap.getEntry的代理。remove其实就是ThreadLocalMap.remove的代理。 12345678910111213141516171819public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125;public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this); &#125; ThreadLocal为什么会内存溢出可能性.ThreadLocalMap 中的Entry数据结构 123456789static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; 注意到Entry的key 是WeakReference类型了么，这个是弱引用。 如果线程一直存在，但是Entry中的key为null,但是value是强引用，其实就是会存在某些value一直没有被gc回收，所以就是会存在内存溢出。 解决办法使用完之后调用下remove即可。 ThreadLocalMap.getEntry和setEntry的都是会调用expungeStaleEntry，expungeStaleEntry如果检测到key==null,也是会将value置为null的 参考大佬 别再问我ThreadLocal是什么？一文带你剖析ThreadLocal（真实案例加源码分析） 为什么需要ThreadLocal模式 ThreadLocal-面试必问深度解析]]></content>
      <tags>
        <tag>java</tag>
        <tag>ThreadLocal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊MySQL[索引概念梳理]]]></title>
    <url>%2F2020%2F08%2F05%2FMySQL-2%2F</url>
    <content type="text"><![CDATA[本篇文章聊下MySQL索引。 索引使用来解决什么问题。 没有索引，那么查询数据，每次都是遍历查询全部的数据，那么如果数据量大的话，会慢的要死。所以索引创建出来的本质目的就是为了解决查询慢的问题 MySQL支持哪些索引 primary key 唯一索引，不允许为NULL Unique 唯一索引，允许为NULL Index 普通索引以及组合索引 FullText 全文索引 MySQL支持哪些数据结构 Hash B+ 从无序数据结构VS有序数据结构的角度，聊下为啥MySQL索引是B+树为什么这么多都可以优化索引，为什么MySQL选择了B+,我们从下面几个方面来解释下。 无序数据结构数据结构是没有顺序的，所以一般就是KV等值查询，对范围查询支持性还是不行 Hash简单讲Hash就是一个KV结构的数据结构。 优点 对于等值查询查询速度会非常快 缺点 对于KV结构的很明显支持不了非等值查询的场景。 最佳适用场景: 对于需要等值查询的茶镜比如Redis、Memcached这些中间件使用Hash效果就会更好有序数据结构有序的数据结构有很多，基本的有序数组，二叉排序树，平衡二叉树，B树(B-树)，B+树，红黑树。下面我们就逐个来解释下其优缺点. 有序数组顾名思义，就是一个排好序的数组。 优点 其对于等值（二分或者其他的查找方式）或者是范围查询都可以很好的支持. 缺点 对于update类型操作(增删改)数据，会改变其原有数据结构，成本会有点高. 适用场景：缓存静态数据(不会被修改，或者是极少被修改的场景) 二叉排序树二叉排序树数据结构分析，参见博客相关分析文章。 优点 有序,可以支持范围查找。对于等值查找时间复杂度最优是O(lgN) 最差是O(N)。 缺点 对于极端情况下如下图，层数就过于高了，所以就需要下面的平衡二叉树 适用场景：范围查询支持度不是很好，一般场景都是用二叉排序树数的优化版本。 平衡二叉树平衡二叉树简单讲就是讲二叉树极端lg(N)情况消除掉了 优点 有序,可以支持范围查找。对于等值查找时间复杂度稳定为O(lgN)。 缺点 因为是二叉树，如果数据节点过多，那么树就会特别高。如果有N个节点，那么层高就是lg2(N+1). 因为索引不一定是在内存中存储的，所以树越深，磁盘io越多，那么查询时间就长。 适用场景：平衡二叉树已经是一个很好的数据结构了。对于范围和等值查询等支持的都是很好。所以如果是数量量较少，使用内存就可以使用，建议是使用平衡二叉树。 B树B树是平衡二叉树的进化版。主要是解决树过于深，导致磁盘io过多。简单理解B树就是平衡多叉树。B树中的非页节点保存数据。 优点 有序，在平衡二叉树的基础上，扩展为并不仅仅是二叉。从一定程度上降低了树的深度，减少io查询次数. 缺点 其实B树已经是很好了。如果硬要说缺点，就是查询效率没有B+树高. 适用场景: 大数据量，想要优化性能。 MongoDB索引使用的是B树。 B+树B+树就是在B树的基础上，冗余了在非叶子节点冗余了索引数据，提高范围查询效率。 优点: 有序，在列举的数据结构中，查询效率较高，以及对磁盘io的次数较低。 缺点: 实现复杂。增删改查都需要很复杂的操作。大佬可以手撸代码。 B+树的节点中存储多少个元素最合适 为一页或者是页的倍数。因为不是页的倍数，磁盘io都是会造成资源的浪费。 页的概念 数据页之间是双向链表 数据页内的数据记录之间是单向链表 每个数据页都会在有一部分空间用来存储页目录。通过主键查找记录的时候，可以在页目录中使用二分快速定位对应的记录槽，然后在槽里面找到对应的记录。 一次查询过程 定位到记录所在页 遍历双向链表找到所在页 在业内找到对应的记录 如果不是主键查询，就只能遍历所在页的所有记录(单链表)回表其实就是根据某个索引找到对应的主键。因为主键肯定是唯一的，所以会找的更快些。 覆盖索引其实就是某个索引已经包含了要查 的数据，所以就没有必要找到实际的记录。比如根据索引name 查找主键id。那么索引那么已经包含了id，就没有必要再继续查询了。 最左匹配原则 索引可以指定1列(a), 也可以指定多个列(a,b,c,d)即联合索引 如果是联合索引，索引只能用于查找key是否存在(相等)，遇到范围查询(&gt; &lt; between like)等就不能进一步匹配，会后退为线性查找。 例子: 如果有索引(a,b,c) 查询SQL select * from tabl a=1 and b&gt;2 and c &gt; 3. 则会在每个节点依次命中a,b 无法命中c. 因为b已经是范围查询了, c就更不会排序查找了。 总结 索引是为了查找速度快而出来的。如果快速定位到对应的记录，或者是根据索引能够筛选出一大部分非目标记录，这就是优化查询的本质。 参考大佬《爱上面试官》系列-数据库索引]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊MySQL[基本概念]]]></title>
    <url>%2F2020%2F08%2F05%2FMysql-1%2F</url>
    <content type="text"><![CDATA[本篇聊下Mysql一些基础内容 MySQL基本架构图 连接器 负责跟数据库连接,获取权限，维护和管理连接。 连接后我们没有交互，会处于空闲Sleep状态 show processlist 可以查询当前连接的状态 空闲久了，连接会自动断开。由wait_timeout空值，默认是8小时 如果保证数据库连接在使用时没有被、断开 1 断开后，直接判断下是否需要重新连接。即随用随连 2 使用长连接(但是因为MySQL临时使用的内存是在连接对象里面的。就是会导致OOM,导致MySQL重启，或者是JVM频繁GC) 查询缓存 就是提供缓存，如果没有命中就重新查询。 不使用缓存可以在查询的时候增加SQL_NO_CACHE 例如select SQL_NO_CACHE from table 分析器 先进行词法分析器 再进行语法分析 优化器 如果有索引，判断使用哪一个索引 执行顺序会优化。先做什么，再做什么，顺序不一样，查询的效率可能就不同 常用的两种MySQL引擎对比 顺便扯一下数据库三大范式 第一范式: 每个特征都要保持原子性 第二范式: 表中每列都跟主键相关。 记录的唯一性 第三范式: 任何列不能由其他列派生出来。就是不能冗余 参考大佬MySQL 常用数据存储引擎区别《吊打面试官》系列-数据库基础知识]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊Mybatis[StatementHandler核心原理]]]></title>
    <url>%2F2020%2F08%2F04%2FMybatis-5%2F</url>
    <content type="text"><![CDATA[我们前面将SqlSession将SQL执行委托给Executor,Executor又最终委托给了StatementHandler. 本篇我们来剖析下StatementHandler是如何做到实质性的SQL执行。 一些概念JDBC 中的Statement/PrepareStatement/CallableStatement接口是啥简单讲：*Statement是在我们获取到数据库连接conn之后，可以让我们发送SQL命令或者PL/SQL(过程化SQL)命令到数据库，并可以从数据库获取到数据。就是一个中介，我们只需要通过*Statement执行SQL,获取结果，其他的我们就可以不用关心了。 三种Statement接口功能表 一次Query的时序图我们通过一次Query的时序图来大致看下SqlSession,Executor,StatementHandler, *Statement之间的关系. 观看上图，其实StatementHandler也不是最终的执行者，而是委托给了*Statement.但是由于*Statement是JDBC的东西(Mybatis本身就是针对jdbc-connector的二次封装)，所以对于Mybatis来讲，StatementHandler就是SQL执行前的最后一棒。 StatementHandler 部分源码分析先来一个类关系图 BaseStatementHandler 抽象基类。类似BaseExecutor. 提供通用方法支持，需要定制化，使用模板模式由子类实现. SimpleStatementHandler 继承BaseStatementHandler. 操作JDBC.Statement接口。 PreparedStatementHandler 继承BaseStatementHandler. 操作JDBC.PreParedStatement接口。 CallableStatementHandler 继承BaseStatementHandler. 操作JDBC.CallableStatement接口。 RoutingStatementHandler 策略类，根据MappedStatement类型创建上面三种StatementHandler. BaseStetementHandler主要是对prepare封装了一层，实际实现还是在子类的instantiateStatement 12345678910111213141516171819@Override public Statement prepare(Connection connection, Integer transactionTimeout) throws SQLException &#123; ErrorContext.instance().sql(boundSql.getSql()); Statement statement = null; try &#123; statement = instantiateStatement(connection); setStatementTimeout(statement, transactionTimeout); setFetchSize(statement); return statement; &#125; catch (SQLException e) &#123; closeStatement(statement); throw e; &#125; catch (Exception e) &#123; closeStatement(statement); throw new ExecutorException(&quot;Error preparing statement. Cause: &quot; + e, e); &#125; &#125; protected abstract Statement instantiateStatement(Connection connection) throws SQLException; SimpleStatementHandler简单不解释 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556@Override public int update(Statement statement) throws SQLException &#123; String sql = boundSql.getSql(); Object parameterObject = boundSql.getParameterObject(); KeyGenerator keyGenerator = mappedStatement.getKeyGenerator(); int rows; if (keyGenerator instanceof Jdbc3KeyGenerator) &#123; statement.execute(sql, Statement.RETURN_GENERATED_KEYS); rows = statement.getUpdateCount(); keyGenerator.processAfter(executor, mappedStatement, statement, parameterObject); &#125; else if (keyGenerator instanceof SelectKeyGenerator) &#123; statement.execute(sql); rows = statement.getUpdateCount(); keyGenerator.processAfter(executor, mappedStatement, statement, parameterObject); &#125; else &#123; statement.execute(sql); rows = statement.getUpdateCount(); &#125; return rows; &#125; @Override public void batch(Statement statement) throws SQLException &#123; String sql = boundSql.getSql(); statement.addBatch(sql); &#125; @Override public &lt;E&gt; List&lt;E&gt; query(Statement statement, ResultHandler resultHandler) throws SQLException &#123; String sql = boundSql.getSql(); statement.execute(sql); return resultSetHandler.&lt;E&gt;handleResultSets(statement); &#125; @Override public &lt;E&gt; Cursor&lt;E&gt; queryCursor(Statement statement) throws SQLException &#123; String sql = boundSql.getSql(); statement.execute(sql); return resultSetHandler.&lt;E&gt;handleCursorResultSets(statement); &#125;// 这里就是创建Statement. @Override protected Statement instantiateStatement(Connection connection) throws SQLException &#123; if (mappedStatement.getResultSetType() != null) &#123; return connection.createStatement(mappedStatement.getResultSetType().getValue(), ResultSet.CONCUR_READ_ONLY); &#125; else &#123; return connection.createStatement(); &#125; &#125;// Statement不支持传参 @Override public void parameterize(Statement statement) throws SQLException &#123; // N/A &#125; CallableStatementHandler创建CallableStatement。使用ParameterHandler.setParameters 设置传参. 12345678910111213141516@Override protected Statement instantiateStatement(Connection connection) throws SQLException &#123; String sql = boundSql.getSql(); if (mappedStatement.getResultSetType() != null) &#123; return connection.prepareCall(sql, mappedStatement.getResultSetType().getValue(), ResultSet.CONCUR_READ_ONLY); &#125; else &#123; return connection.prepareCall(sql); &#125; &#125; @Override public void parameterize(Statement statement) throws SQLException &#123; // 这里特别的对于ReturnOutType 做了一次转换 registerOutputParameters((CallableStatement) statement); parameterHandler.setParameters((CallableStatement) statement); &#125; #####PreParedStatementHandler创建PreParedStatement。使用ParameterHandler.setParameters 设置传参. 123456789101112131415161718192021@Override protected Statement instantiateStatement(Connection connection) throws SQLException &#123; String sql = boundSql.getSql(); if (mappedStatement.getKeyGenerator() instanceof Jdbc3KeyGenerator) &#123; String[] keyColumnNames = mappedStatement.getKeyColumns(); if (keyColumnNames == null) &#123; return connection.prepareStatement(sql, PreparedStatement.RETURN_GENERATED_KEYS); &#125; else &#123; return connection.prepareStatement(sql, keyColumnNames); &#125; &#125; else if (mappedStatement.getResultSetType() != null) &#123; return connection.prepareStatement(sql, mappedStatement.getResultSetType().getValue(), ResultSet.CONCUR_READ_ONLY); &#125; else &#123; return connection.prepareStatement(sql); &#125; &#125; @Override public void parameterize(Statement statement) throws SQLException &#123; parameterHandler.setParameters((PreparedStatement) statement); &#125; ParameterHandlermybatis里面只有一种实现.DefaultParameterHandler 1234567891011121314151617181920212223242526272829303132333435363738// 入参是PreparedStatement， 是因为CallableStatment是继承PreparedStatement接口的@Override public void setParameters(PreparedStatement ps) &#123; ErrorContext.instance().activity(&quot;setting parameters&quot;).object(mappedStatement.getParameterMap().getId()); List&lt;ParameterMapping&gt; parameterMappings = boundSql.getParameterMappings(); if (parameterMappings != null) &#123; for (int i = 0; i &lt; parameterMappings.size(); i++) &#123; ParameterMapping parameterMapping = parameterMappings.get(i); if (parameterMapping.getMode() != ParameterMode.OUT) &#123; Object value; String propertyName = parameterMapping.getProperty(); if (boundSql.hasAdditionalParameter(propertyName)) &#123; // issue #448 ask first for additional params value = boundSql.getAdditionalParameter(propertyName); &#125; else if (parameterObject == null) &#123; value = null; &#125; else if (typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) &#123; value = parameterObject; &#125; else &#123; MetaObject metaObject = configuration.newMetaObject(parameterObject); value = metaObject.getValue(propertyName); &#125; // 这里是指定的typeHandler TypeHandler typeHandler = parameterMapping.getTypeHandler(); JdbcType jdbcType = parameterMapping.getJdbcType(); if (value == null &amp;&amp; jdbcType == null) &#123; jdbcType = configuration.getJdbcTypeForNull(); &#125; try &#123; typeHandler.setParameter(ps, i + 1, value, jdbcType); &#125; catch (TypeException e) &#123; throw new TypeException(&quot;Could not set parameters for mapping: &quot; + parameterMapping + &quot;. Cause: &quot; + e, e); &#125; catch (SQLException e) &#123; throw new TypeException(&quot;Could not set parameters for mapping: &quot; + parameterMapping + &quot;. Cause: &quot; + e, e); &#125; &#125; &#125; &#125; &#125; StatementHandler的创建时机和创建策略控制Executor每次执行update或者是query都是会创建一个新的StatementHandler 123456789101112131415161718192021222324252627@Override public int doUpdate(MappedStatement ms, Object parameter) throws SQLException &#123; Statement stmt = null; try &#123; Configuration configuration = ms.getConfiguration(); // 这里new StatementHandler handler = configuration.newStatementHandler(this, ms, parameter, RowBounds.DEFAULT, null, null); stmt = prepareStatement(handler, ms.getStatementLog()); return handler.update(stmt); &#125; finally &#123; closeStatement(stmt); &#125; &#125; @Override public &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException &#123; Statement stmt = null; try &#123; Configuration configuration = ms.getConfiguration(); // 这里new StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); stmt = prepareStatement(handler, ms.getStatementLog()); return handler.&lt;E&gt;query(stmt, resultHandler); &#125; finally &#123; closeStatement(stmt); &#125; &#125; 创建策略有三种. 默认为PREPARED. 123public enum StatementType &#123; STATEMENT, PREPARED, CALLABLE&#125; 需要指定的话，可以在mapper里面跟随sql来指定 12345678&lt;select id=&quot;findOne&quot; resultMap=&quot;articleResult&quot; statementType=&quot;PREPARED&quot;&gt; // 这里指定 SELECT id, author_id, title, content, create_time FROM article WHERE id = #&#123;id&#125;&lt;/select&gt; 参考大佬Mybatis3.3.x技术内幕（六）：StatementHandler（Box stop here）祖大俊]]></content>
      <tags>
        <tag>java</tag>
        <tag>mysql</tag>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊Mybatis[Exector核心原理]]]></title>
    <url>%2F2020%2F08%2F03%2FMybatis-2%2F</url>
    <content type="text"><![CDATA[本文深入分析下Executor一些核心原理 SqlSession对数据库的操作都是委托给Executor.下面我们剖析下Executor的核心原理。 前述Executor 上承SqlSession 下接StatementHandler。处于Mybatis体系的核心，深入理解Executor的实现原理，对实际开发会更有帮助。 Executor接口1234567891011121314151617181920212223242526272829303132333435public interface Executor &#123; ResultHandler NO_RESULT_HANDLER = null; int update(MappedStatement ms, Object parameter) throws SQLException; &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey cacheKey, BoundSql boundSql) throws SQLException; &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException; &lt;E&gt; Cursor&lt;E&gt; queryCursor(MappedStatement ms, Object parameter, RowBounds rowBounds) throws SQLException; // 这个是为了批量查询 List&lt;BatchResult&gt; flushStatements() throws SQLException; void commit(boolean required) throws SQLException; void rollback(boolean required) throws SQLException; CacheKey createCacheKey(MappedStatement ms, Object parameterObject, RowBounds rowBounds, BoundSql boundSql); boolean isCached(MappedStatement ms, CacheKey key); void clearLocalCache(); void deferLoad(MappedStatement ms, MetaObject resultObject, String property, CacheKey key, Class&lt;?&gt; targetType); Transaction getTransaction(); void close(boolean forceRollback); boolean isClosed(); // 这个wrapper实际是只会用到CacheExecutor. 用到SelectKeyGenerator.processGeneratedKeys()函数 提供对应的事务。我理解为了保证同一个Session的事务都是一个事务管理器。 void setExecutorWrapper(Executor executor);&#125; 类关系图实际只有五种: SimpleExecutor ReuseExecutor ClosedExecutor CachingExecutor BatchExecutor 注意:以上执行器的生命周期都是在SqlSession生命周期内 SimpleExecutor执行update/select 每次都创建一个StatementHandler,使用完就关闭。 CloseExecutor私有类，没有什么实质实现. ReuseExecutor执行update/select 创建了StatementHandler之后，使用完，不关闭，缓存起来。 BatchExecutor执行update. 不支持批量select. 所有的sql都会调用StatementHandler.addBatch()，等待executeBatch().这里特别要注意下: 每个statement都可能是一批sql. BatchExecutor是维护了多个statement。借用大佬的解释BatchExecutor 维护了多个桶，每个桶里面有多个自己的SQL，就像苹果蓝里装了很多苹果，番茄蓝里装了很多番茄，最后，再统一倒进仓库(统一执行)。 CacheExecutor基于装饰器模式,如果有缓存就直接返回缓存，如果没有缓存就委托给SimpleExecutor|ReuseExecutor|BatchExecutor.这三种执行器执行。 部分源码分析BaseExecutor 抽象类部分代码 1234567891011121314151617181920@Override public int update(MappedStatement ms, Object parameter) throws SQLException &#123; ErrorContext.instance().resource(ms.getResource()).activity(&quot;executing an update&quot;).object(ms.getId()); if (closed) &#123; throw new ExecutorException(&quot;Executor was closed.&quot;); &#125; clearLocalCache(); return doUpdate(ms, parameter); &#125; protected abstract int doUpdate(MappedStatement ms, Object parameter) throws SQLException; protected abstract List&lt;BatchResult&gt; doFlushStatements(boolean isRollback) throws SQLException; protected abstract &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException; protected abstract &lt;E&gt; Cursor&lt;E&gt; doQueryCursor(MappedStatement ms, Object parameter, RowBounds rowBounds, BoundSql boundSql) throws SQLException; 典型的模板模式，具体的实现交给下面的子类来实现. SimpleExecutor很简单，就是创建Statement,然后执行完后，就关闭掉。 其他方法可以看下具体实现，原理都一样. 123456789101112@Override public int doUpdate(MappedStatement ms, Object parameter) throws SQLException &#123; Statement stmt = null; try &#123; Configuration configuration = ms.getConfiguration(); StatementHandler handler = configuration.newStatementHandler(this, ms, parameter, RowBounds.DEFAULT, null, null); stmt = prepareStatement(handler, ms.getStatementLog()); return handler.update(stmt); &#125; finally &#123; closeStatement(stmt); &#125; &#125; 注意：SimpleExecutor不支持doFlushStatements(批量刷新statement),所以是直接返回的一个空列表. 1234@Overridepublic List&lt;BatchResult&gt; doFlushStatements(boolean isRollback) throws SQLException &#123; return Collections.emptyList();&#125; ReuseExecutor12345678910111213141516171819202122@Override public int doUpdate(MappedStatement ms, Object parameter) throws SQLException &#123; Configuration configuration = ms.getConfiguration(); StatementHandler handler = configuration.newStatementHandler(this, ms, parameter, RowBounds.DEFAULT, null, null); // 这里做缓存，如果存在就直接返回，不存在直接创建，再返回 Statement stmt = prepareStatement(handler, ms.getStatementLog()); return handler.update(stmt); &#125; private Statement prepareStatement(StatementHandler handler, Log statementLog) throws SQLException &#123; Statement stmt; BoundSql boundSql = handler.getBoundSql(); String sql = boundSql.getSql(); if (hasStatementFor(sql)) &#123; stmt = getStatement(sql); applyTransactionTimeout(stmt); &#125; else &#123; Connection connection = getConnection(statementLog); stmt = handler.prepare(connection, transaction.getTimeout()); putStatement(sql, stmt); &#125; handler.parameterize(stmt); return stmt; 注意: 因为ReuseExecutor 缓存了StatementHandler，所以doFlushStatements, 会关闭之前缓存的StatementHandler，然后返回一个空列表 12345678@Overridepublic List&lt;BatchResult&gt; doFlushStatements(boolean isRollback) throws SQLException &#123; for (Statement stmt : statementMap.values()) &#123; closeStatement(stmt); &#125; statementMap.clear(); return Collections.emptyList();&#125; BatchExecutor1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798// 保存需要执行的statementList, 为之后批次执行做准备 private final List&lt;Statement&gt; statementList = new ArrayList&lt;Statement&gt;(); // 结果 private final List&lt;BatchResult&gt; batchResultList = new ArrayList&lt;BatchResult&gt;(); // 当前编译过的Sql private String currentSql; // 当前的statement private MappedStatement currentStatement;@Override public int doUpdate(MappedStatement ms, Object parameterObject) throws SQLException &#123; final Configuration configuration = ms.getConfiguration(); final StatementHandler handler = configuration.newStatementHandler(this, ms, parameterObject, RowBounds.DEFAULT, null, null); final BoundSql boundSql = handler.getBoundSql(); final String sql = boundSql.getSql(); final Statement stmt; // 如果当前SQL与之前SQL不一致，那么久需要重新编译SQL if (sql.equals(currentSql) &amp;&amp; ms.equals(currentStatement)) &#123; int last = statementList.size() - 1; stmt = statementList.get(last); applyTransactionTimeout(stmt); handler.parameterize(stmt);//fix Issues 322 BatchResult batchResult = batchResultList.get(last); batchResult.addParameterObject(parameterObject); &#125; else &#123; Connection connection = getConnection(ms.getStatementLog()); stmt = handler.prepare(connection, transaction.getTimeout()); handler.parameterize(stmt); //fix Issues 322 currentSql = sql; currentStatement = ms; // 增加进待执行list statementList.add(stmt); batchResultList.add(new BatchResult(ms, sql, parameterObject)); &#125; // 将sql添加进statement. 由statementhandler 内部执行.（jdbc.xxstatementHandler） handler.batch(stmt); return BATCH_UPDATE_RETURN_VALUE; &#125; // commit/rollback/close-》 都会调用doFlushSatements,然后会执行stmt.executeBatch()。 @Override public List&lt;BatchResult&gt; doFlushStatements(boolean isRollback) throws SQLException &#123; try &#123; List&lt;BatchResult&gt; results = new ArrayList&lt;BatchResult&gt;(); if (isRollback) &#123; return Collections.emptyList(); &#125; // 多个桶，一次执行每个桶 for (int i = 0, n = statementList.size(); i &lt; n; i++) &#123; Statement stmt = statementList.get(i); applyTransactionTimeout(stmt); BatchResult batchResult = batchResultList.get(i); try &#123; // 这里是会实际执行 batchResult.setUpdateCounts(stmt.executeBatch()); MappedStatement ms = batchResult.getMappedStatement(); List&lt;Object&gt; parameterObjects = batchResult.getParameterObjects(); // 主键 KeyGenerator keyGenerator = ms.getKeyGenerator(); if (Jdbc3KeyGenerator.class.equals(keyGenerator.getClass())) &#123; Jdbc3KeyGenerator jdbc3KeyGenerator = (Jdbc3KeyGenerator) keyGenerator; jdbc3KeyGenerator.processBatch(ms, stmt, parameterObjects); &#125; else if (!NoKeyGenerator.class.equals(keyGenerator.getClass())) &#123; //issue #141 for (Object parameter : parameterObjects) &#123; keyGenerator.processAfter(this, ms, stmt, parameter); &#125; &#125; // Close statement to close cursor #1109 closeStatement(stmt); &#125; catch (BatchUpdateException e) &#123; StringBuilder message = new StringBuilder(); message.append(batchResult.getMappedStatement().getId()) .append(&quot; (batch index #&quot;) .append(i + 1) .append(&quot;)&quot;) .append(&quot; failed.&quot;); if (i &gt; 0) &#123; message.append(&quot; &quot;) .append(i) .append(&quot; prior sub executor(s) completed successfully, but will be rolled back.&quot;); &#125; throw new BatchExecutorException(message.toString(), e, results, batchResult); &#125; // 结果 results.add(batchResult); &#125; return results; &#125; finally &#123; for (Statement stmt : statementList) &#123; closeStatement(stmt); &#125; // 初始化掉成员变量 currentSql = null; statementList.clear(); batchResultList.clear(); &#125; &#125; 需要注意的是: 如果SQL是AABBAA-&gt;那么就会有三个statement.调用时序图 CachingExecutor装饰模式，实际是使用的SimpleExecutor, ReusedExecutor, BatchExecutor 三种之一。 tips Executor什么时候生成 在创建SqlSession的时候，随之生成。 Executor 默认方式是什么？ 可否指定 默认是SimpleExecutor 可以指定，有下面两种方式 通过SqlSessionFactory.openSession() 传入ExecutorType 通过xml 来指定 参考大佬Mybatis3.3.x技术内幕（四）：五鼠闹东京之执行器Executor设计原本]]></content>
      <tags>
        <tag>java</tag>
        <tag>mysql</tag>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊Mybatis[事务管理]]]></title>
    <url>%2F2020%2F08%2F01%2FMybatis-4%2F</url>
    <content type="text"><![CDATA[本篇我们来解密下Mybatis的事务管理 事务基本概念 Transaction接口1234567891011public interface Transaction &#123; Connection getConnection() throws SQLException; void commit() throws SQLException; void rollback() throws SQLException; void close() throws SQLException; Integer getTimeout() throws SQLException;&#125; 核心也就是三个方法 commit 提交事务 rollback 回滚事务 close 关闭一个连接，或者是把conn连接放回连接池中。类关系图Mybatis中的Transaction是由工厂类生成的，具体可以在mybatis-config 配置transactionManager标签具体的类关系图见下图: JdbcTransaction单独使用Mybatis时，是默认的实现，其代码就是JDBC事务的极简单封装。 需要注意: 对于commit 和rollback 都是直接用的connection的方法，但是JdbcTransaction.close函数，在close之前多了个resetActoCommit(). 如下 123456789public void close() throws SQLException &#123; if (connection != null) &#123; resetAutoCommit(); if (log.isDebugEnabled()) &#123; log.debug(&quot;Closing JDBC Connection [&quot; + connection + &quot;]&quot;); &#125; connection.close(); &#125; &#125; close()本身就是就是销毁conn. 但是销毁前，又多做了一步，岂不是多此一举。答案当然不是,close并不是一定是销毁，可能还是会被放回连接池。既然是放回连接池，那么reset下就自然而然就是恢复默认值，也就可以理解为什么会多此一举。 ManagedTransaction功能是托管服务，空壳事务管理器，主要是提醒用户，在不通的环境将事务托管为其他的框架。部分代码 12345678910111213141516171819@Override public void commit() throws SQLException &#123; // Does nothing &#125; @Override public void rollback() throws SQLException &#123; // Does nothing &#125; @Override public void close() throws SQLException &#123; if (this.closeConnection &amp;&amp; this.connection != null) &#123; if (log.isDebugEnabled()) &#123; log.debug(&quot;Closing JDBC Connection [&quot; + this.connection + &quot;]&quot;); &#125; this.connection.close(); &#125; &#125; Transaction使用先给结论: 无论是SqlSession 还是Executor的事务方法，最终都是指向了Transaction接口的事务方法. 无参openSession(),默认是autocommit=false 调用时序图见下图 代码分析Transaction 创建 在SqlSessionFactory创建SqlSession的时候，会调用TransactionFactory创建Transaction.12345678910111213141516171819202122 @Override public SqlSession openSession() &#123; return openSessionFromDataSource(configuration.getDefaultExecutorType(), null, false); &#125; private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) &#123; Transaction tx = null; try &#123; final Environment environment = configuration.getEnvironment(); // 创建事务 final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment); tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); // 创建Executor 实际是Exector里面会存在Transaction 成员变量 final Executor executor = configuration.newExecutor(tx, execType); return new DefaultSqlSession(configuration, executor, autoCommit); &#125; catch (Exception e) &#123; closeTransaction(tx); // may have fetched a connection so lets call close() throw ExceptionFactory.wrapException(&quot;Error opening session. Cause: &quot; + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125;&#125; 调用SqlSession.commit-&gt;Executor.commit-&gt;Transaction.commit 下面是SqlSession的调用 1234567891011@Override public void commit(boolean force) &#123; try &#123; executor.commit(isCommitOrRollbackRequired(force)); dirty = false; &#125; catch (Exception e) &#123; throw ExceptionFactory.wrapException(&quot;Error committing transaction. Cause: &quot; + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; 下面是BaseExecutor调用 1234567891011@Override public void commit(boolean required) throws SQLException &#123; if (closed) &#123; throw new ExecutorException(&quot;Cannot commit, transaction is already closed&quot;); &#125; clearLocalCache(); flushStatements(); if (required) &#123; transaction.commit(); &#125; &#125; 注意点 一个Conn生命周期中，会有多个事务，但是rollback只能回滚未提交的事务 autoCommit=false,没有执行close(),会发生什么? 结论: sqlSession关闭的时候，如果是insert/update/delete操作，会rollback()。 源码分析 123456789101112131415 // SqlSession.close()@Override public void close() &#123; try &#123; executor.close(isCommitOrRollbackRequired(false)); closeCursors(); dirty = false; &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; private boolean isCommitOrRollbackRequired(boolean force) &#123; // 这里的dirty 在insert/update/delete的时候是true return (!autoCommit &amp;&amp; dirty) || force; &#125; autoCommit=false, 不commit 也不close. 如果隔离级别是Read Uncommitted,那么在jvm生命周期内，可以读取到。jvm结束后会rollback 总结Mybatis的事务其实就是JDBC的事务管理，只是扩展了支持连接池的conn. 只要对数据库进行操作(增删改)都是在事务里面的。 参考大佬 Mybatis3.4.x技术内幕]]></content>
      <tags>
        <tag>java</tag>
        <tag>mysql</tag>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊Mybatis[一次SQL查询的过程]]]></title>
    <url>%2F2020%2F08%2F01%2FMybatis-3%2F</url>
    <content type="text"><![CDATA[通过本篇文章我们聊一下一次SQL执行的步骤都有哪些 总体执行图，本篇文章的核心 部分核心代码分析demo123456789101112131415SqlSession session = sqlSessionFactory.openSession();try &#123; ArticleDao articleDao = session.getMapper(ArticleDao.class); Article article = articleDao.findOne(1); Author author = article.getAuthor(); article.setAuthor(null); System.out.println(&quot;\nauthor info:&quot;); System.out.println(author); System.out.println(&quot;\narticles info:&quot;); System.out.println(article);&#125; finally &#123; session.close();&#125; session.getMapper 获取到MapperProxy就是上文中的ArticleDao articleDao = session.getMapper(ArticleDao.class);因为Mapper是接口不能直接实例化，所以MapperProxy就是使用JDK动态代理功能，间接实例化Mapper。 使用MapperProxy.invoker方法-&gt; 获取到MapperMethoddemo中的articleDao.findOne(1);就是调用mapperProxy.invoker方法这部分功能就是，从SqlSession-&gt;Executor过程部分源码 123456789101112131415161718192021222324@Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; try &#123; if (Object.class.equals(method.getDeclaringClass())) &#123; return method.invoke(this, args); &#125; else if (isDefaultMethod(method)) &#123; return invokeDefaultMethod(proxy, method, args); &#125; &#125; catch (Throwable t) &#123; throw ExceptionUtil.unwrapThrowable(t); &#125; final MapperMethod mapperMethod = cachedMapperMethod(method); // 实际的执行 return mapperMethod.execute(sqlSession, args); &#125; // 缓存MapperMethod对象 private MapperMethod cachedMapperMethod(Method method) &#123; MapperMethod mapperMethod = methodCache.get(method); if (mapperMethod == null) &#123; mapperMethod = new MapperMethod(mapperInterface, method, sqlSession.getConfiguration()); methodCache.put(method, mapperMethod); &#125; return mapperMethod; &#125; MapperMethodMapperMethod 代码结构图 可以看出来实际上就是只有两个public的方法，一个是构造函数，一个就是execute.所有就是有两个功能 解析Mapper接口方法,封装成MapperMethod对象。这里要注意下，有两个类成员 SqlCommand,这个类包含了执行的方法是属于那种类型。 MethodSignature 执行方法的一些属性，返回值的类型(单个，还是批量，还是其他) 将SqlCommand 路由到SqlSession对应的方法上MapperMethod.execute根据入参，路由到SqlSession提供的方法中.123456789101112131415161718192021222324252627282930313233343536373839404142434445public Object execute(SqlSession sqlSession, Object[] args) &#123; Object result; switch (command.getType()) &#123; case INSERT: &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.insert(command.getName(), param)); break; &#125; case UPDATE: &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.update(command.getName(), param)); break; &#125; case DELETE: &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.delete(command.getName(), param)); break; &#125; case SELECT: if (method.returnsVoid() &amp;&amp; method.hasResultHandler()) &#123; executeWithResultHandler(sqlSession, args); result = null; &#125; else if (method.returnsMany()) &#123; result = executeForMany(sqlSession, args); &#125; else if (method.returnsMap()) &#123; result = executeForMap(sqlSession, args); &#125; else if (method.returnsCursor()) &#123; result = executeForCursor(sqlSession, args); &#125; else &#123; Object param = method.convertArgsToSqlCommandParam(args); result = sqlSession.selectOne(command.getName(), param); &#125; break; case FLUSH: result = sqlSession.flushStatements(); break; default: throw new BindingException(&quot;Unknown execution method for: &quot; + command.getName()); &#125; if (result == null &amp;&amp; method.getReturnType().isPrimitive() &amp;&amp; !method.returnsVoid()) &#123; throw new BindingException(&quot;Mapper method &apos;&quot; + command.getName() + &quot; attempted to return null from a method with a primitive return type (&quot; + method.getReturnType() + &quot;).&quot;); &#125; return result; &#125; 在之后就是SqlSession-&gt;Executor-&gt;StatementHandler 这条链路了。我会在其他的文章中详解 参考大佬 Mybatis3.4.x技术内幕]]></content>
      <tags>
        <tag>java</tag>
        <tag>mysql</tag>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊Mybatis[整体概览]]]></title>
    <url>%2F2020%2F08%2F01%2FMybatis-1%2F</url>
    <content type="text"><![CDATA[本篇文章从上层聊下Mybatis的功能模块，架构等。 整体概览功能模块 核心模块流转关系 整体处理流程 Mybatis操作数据库步骤 核心模块(类)SqlSessionFactoryBuilder 功能: 如题 描述: 每个Mybatis的程序的入口都是SqlSessionFactoryBuilder. 读取相关的配置，并且创建SqlSessionFactory. SqlSessionFactory 功能: 如题，SqlSession工厂方法 描述: 就是创建SqlSession. 同SqlSessionFactoryBuilder一样，在同一个服务中维持单例模式即可。 部分接口 123456789101112131415public interface SqlSessionFactory &#123; SqlSession openSession(); SqlSession openSession(boolean autoCommit); SqlSession openSession(Connection connection); SqlSession openSession(TransactionIsolationLevel level); SqlSession openSession(ExecutorType execType); SqlSession openSession(ExecutorType execType, boolean autoCommit); SqlSession openSession(ExecutorType execType, TransactionIsolationLevel level); SqlSession openSession(ExecutorType execType, Connection connection); Configuration getConfiguration();&#125; SqlSession 功能: 对数据库进行一次访问，包括SQL的动态拼装，以及结果的映射。 描述: 线程不安全，所以每次都是由SqlSessionFactory创建一个新的SqlSession实例。 注意点: 两个核心属性: Configuration(配置)以及Executor(执行器) 默认是DefaultSqlSession 并开启一级缓存，创建Executor 以及赋值 Executor 功能: 调用StatementHandler 访问数据库。如果开启缓存，会将结果存入缓存中 描述: 实际运行的单位。在创建SqlSession的时候，随之创建。 类图: StatementHandler 功能: 真正访问数据库的地方，调用其他三种handler(ParameterHandler,ResultSetHandler,TypeHandler) ParameterHandler 功能: 解析sql中的参数 TypeHandler 功能: 负责将参数，或者是结果类型转换。 ResultSetHandler 功能: 负责将访问数据库的结果做映射 MappedStatement 功能: 管理SqlSoure 参数等 SqlSource 功能: 根据用户传递的ParameterObject，动态生成SQL，将信息封装到BoundSql中 BoundSql 功能: 提供实际的SQL以及对应的参数信息 Configuration 功能: 保存所有的配置信息 参考大佬 Mybatis架构与原理 原理分析之二：框架整体设计]]></content>
      <tags>
        <tag>java</tag>
        <tag>mysql</tag>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊java并发编程[汇总篇]]]></title>
    <url>%2F2020%2F07%2F07%2FJUC-SUMARRY%2F</url>
    <content type="text"><![CDATA[java并发文章汇总篇，从原理到应用层梳理。 概念篇 并发编程 什么是并发编程 并发编程有哪些挑战 怎么解决这些挑战 聊聊java并发编程 [核心问题以及java解决方案] 并发编程核心问题(线程间的通信与同步) 主要涉及到三个点 原子性 有序性 内存可见性。 java采用的解决方案(共享内存，另外一种方式是消息传递) 聊聊java并发编程[java实现之JMM] 对上面java通过共享内存方式，进行的补充(解决思想) 主要是介绍了什么是JMM，JMM又是为什么能够解决并发带来的问题 聊聊java并发编程 [java实现的基石] java并发体系是由哪些构建起来的 原理篇 聊聊java并发编程[synchronized vs volatile] 介绍synchronized和volatile 是如何解决原子性，有序性，内存可见性。 synchronized 和volatile关键字的原理 聊聊java并发编程[JAVA-AQS] JUC核心部分，锁，同步队列，都是基于此 这篇文章介绍了什么是AQS, AQS的原理，独占式以及共享式状态如何获取与释放 聊聊java并发编程[JUC中的原子操作类] 介绍了JUC中的原子类为什么是线程安全的以及其原理 聊聊java并发编程[JUC中的锁] 介绍了常见的锁，以及部分锁的实现 聊聊java并发编程[JUC中的Condition] 介绍了java并发Condition的原理以及源码剖析 等待/通知模型的一种实现 应用篇 聊聊java并发编程[HashMap &amp;&amp; ConcurrenctHashMap] 源码分析了jdk8的中的HashMap与ConcurrentHashMap的实现原理 聊聊java并发编程[JUC中的Executor] 源码分析了Executor的架构，核心源码剖析 ….持续更新中]]></content>
      <tags>
        <tag>java</tag>
        <tag>并发编程</tag>
        <tag>juc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊Netty[粘包与半包问题]]]></title>
    <url>%2F2020%2F07%2F02%2FNetty-1%2F</url>
    <content type="text"><![CDATA[通过本篇文章，你可以了解到 什么是粘包与半包 解决粘包与半包的基本思路与策略 Netty 是如何解决粘包与半包问题(解码器) 什么是粘包与半包TCP是一个流式传输协议，其数据是没有边界的，对于发送方来讲就是讲一个一个数据发送到接收端，接收端读取io缓冲区，根据不同的解析协议来解析实际的数据 粘包见下图，比如下图的一个tcp包中的内容就是我们要发送的一个数据。我们一共发送了两个数据，但是接收端解析处理之后把两个数据合并了。这就是粘包。 ####### 粘包的本质原因 发送方写入的数据 &lt; 套接字缓冲区大小 接收方读取套接字缓存区不够及时 半包半包简单讲，就是我们发送了一个AB，但是接收读取的时候，只拿到了一部分数据（就是一半）。 半包 发送方写入数据 &gt; 套接字缓冲区大小 发送的数据大于协议的MTU(Maximum Tranmission Unit) 最大传输单元 解决粘包与半包的基本思路有策略思路其实从分析本质原因的时候，就可以留意到实际的问题本质是:接受端在解析数据的时候如何识别一条数据的边界。 实际的解决策略见下图[图片来源于见参考] Netty 是如何解决粘包与半包问题(解码器)Netty 根据上面的封装成帧的方案提供了三种实现方式 FixedLengthFrameDecoder(固定长度) DelimiterBasedFrameDecoder(分隔符) LengthFieldBasedFrameDecoder(固定长度存储内容的长度信息) 因为其比较复杂，响应的Netty有其对应的Decoder(解码器) 参考 《Netty实战》 Netty源码剖析与实战]]></content>
      <tags>
        <tag>java</tag>
        <tag>netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊线上异常[Redis:Too many open files]]]></title>
    <url>%2F2020%2F06%2F22%2FBug-1%2F</url>
    <content type="text"><![CDATA[记录一次生产环境的bug 发生现象 1234567Caused by: redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool at redis.clients.util.Pool.getResource(Pool.java:53) at redis.clients.jedis.JedisPool.getResource(JedisPool.java:226) at redis.clients.jedis.JedisPool.getResource(JedisPool.java:16) at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.fetchJedisConnector(JedisConnectionFactory.java:194) ... 23 common frames omittedCaused by: redis.clients.jedis.exceptions.JedisConnectionException: java.net.SocketException: Too many open files 开始追踪&amp;&amp;定位问题根据Redis Too many open files 关键字 搜索到这篇文章 然后就发现对应的java进程使用lsof -p pid 有很多文件夹目录的句柄并没有被释放，如下图 定位代码在上面的定位到问题之后，开始找项目的代码里面有哪些代码使用到了这些目录，最后就发现类似如下的代码 123DirectoryStream&lt;Path&gt; paths = Files.newDirectoryStream(Paths.get(path));...并没有手动close. 看下源码123456public static DirectoryStream&lt;Path&gt; newDirectoryStream(Path dir, DirectoryStream.Filter&lt;? super Path&gt; filter) throws IOException&#123; return provider(dir).newDirectoryStream(dir, filter);&#125; 特别地，注意下面的注释 1234* &lt;p&gt; When not using the try-with-resources construct, then directory * stream&apos;s &#123;@code close&#125; method should be invoked after iteration is * completed so as to free any resources held for the open directory. * 当没有使用try-with-resources 结构的时候，使用stream的地方必须手动invoke(手动close)，用来释放资源. 解决既然是需要手动close,手动close即可。 手动复现代码1234567891011 @Test public void testIO() throws IOException, InterruptedException &#123; for (int i = 0; i &lt; 1000; i++) &#123; DirectoryStream&lt;Path&gt; paths = Files.newDirectoryStream(Paths.get(&quot;/tmp&quot;));// paths.close(); //如果不显示调用close,使用lsof -p pid 就可以看到很多目录占用了句柄，并没有被释放 &#125; Thread.sleep(300000); &#125; 总结大致翻了了java.nio.file.Files的里面的函数newDirectoryStream 都是需要手动close, 另外还有个函数也是需要手动close的 Files.lines。 所以使用工具函数是可以的，但是也要知其内部实现原理，否则搞不好就是一个定时炸弹]]></content>
      <tags>
        <tag>java</tag>
        <tag>bug</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊Spring[Spring IOC 源码剖析]]]></title>
    <url>%2F2020%2F06%2F02%2FSpring-1%2F</url>
    <content type="text"><![CDATA[本篇文章从下面几点聊聊spring核心值IOC 什么是Spring IOC Spring IOC 能够帮助我们做什么事情 源码分析 总结 概览 什么是Spring IOC Spring IOC 能够帮助我们做什么事情 源码分析 总结 参考 什么是Spring IOCIOC （Inverse Of Control） 控制反转/反转控制 主要是涉及到 java开发领域对象的创建以及管理 是一种思想 控制：对象的创建以及管理 翻转：控制权交给其他的IOC容器 实际对比 举个例子 场景 有A，B两个类。A依赖于B 解决办法1. 传统思想解决：在A中实例一个B对象。 2. 使用IOC思想开发: 不通过new 关键字来创建对象，而是通过IOC容器(例如Spring IOC) 来帮助我们实例化对象。 解决了什么问题 对象之间的耦合度会变得很低 例如如果Model 接口的实现是ModelImplA. 如果使用传统服务，那么所有使用到Model接口的实现都需要实例化一个ModelImplA. 当有一天需要更换其他的实现ModelImplA，那么就需要更改所有new ModelImplA-&gt;new ModelImplB. 如果使用IOC， 只需要将Model 的实现指向ModelImplB, 其他的就不需要更改了 资源更容易管理。只需要负责定义，实际使用直接用就可以了。 IOC VS DI(Dependency Injection) 傻傻分不清楚 IOC 是一种思想 DI 是最常见的实现方式 源码分析带着下面两个问题看源码： IOC 是如何创建Bean 容器 IOC 是如何初始化Bean ClassPathXmlApplicationContext 构造函数12345678910111213141516public ClassPathXmlApplicationContext(String configLocation) throws BeansException &#123; this(new String[] &#123;configLocation&#125;, true, null); &#125;public ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, ApplicationContext parent) throws BeansException &#123; // 创建父类的applicationContext super(parent); // 设置配置路径 setConfigLocations(configLocations); if (refresh) &#123; // 核心 refresh(); &#125; &#125; ClassPathXmlApplicationContext.refresh 提供功能 找到所有的BeanDefinition 加载额外的FactoryBean 生成非lazy-init 的singletonsInstance. 运行图 源码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768@Override public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. // 初始化开始时间，以及标记`active=true`已启动 // 校验前置的需要的参数 prepareRefresh(); // 核心之一 // 初始化BeanFactory,加载Bean，注册Bean。 但是Bean并没有初始化。 ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // 设置 BeanFactory 的类加载器，添加几个BeanPostProcessor, 手动注册几个特殊的Bean prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(&quot;Exception encountered during context initialization - &quot; + &quot;cancelling refresh attempt: &quot; + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset &apos;active&apos; flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring&apos;s core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125; &#125; AbstractApplicationContext.obtainFreshBeanFactory 主要功能: 创建新的BeanFactory 刷新当前的BeanFactory中的配置信息(BeanDefinition) 重新加载Bean 注册配置信息 注意： 并没有实例化 123456789protected ConfigurableListableBeanFactory obtainFreshBeanFactory() &#123; // 核心逻辑在这里，刷新了会放在内置的属性beanFactory里面 refreshBeanFactory(); ConfigurableListableBeanFactory beanFactory = getBeanFactory(); if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Bean factory for &quot; + getDisplayName() + &quot;: &quot; + beanFactory); &#125; return beanFactory; &#125; AbstractRefreshableApplicationContext.refreshBeanFactory 功能： 如果存在beanFactory 销毁并关闭 创建新的 beanFactory 加载bean配置信息123456789101112131415161718192021@Override protected final void refreshBeanFactory() throws BeansException &#123; if (hasBeanFactory()) &#123; destroyBeans(); closeBeanFactory(); &#125; try &#123; DefaultListableBeanFactory beanFactory = createBeanFactory(); beanFactory.setSerializationId(getId()); // 这里是对beanFactory 配置下（是否允许重载覆盖，是否允许循环依赖(默认允许)） customizeBeanFactory(beanFactory); // 加载bean的配置信息 具体的加载逻辑可以自行查看下源码，本质上对于xml就是解析bean标签中的内容，封装进BeanDefinition里面 loadBeanDefinitions(beanFactory); synchronized (this.beanFactoryMonitor) &#123; this.beanFactory = beanFactory; &#125; &#125; catch (IOException ex) &#123; throw new ApplicationContextException(&quot;I/O error parsing bean definition source for &quot; + getDisplayName(), ex); &#125; &#125; DefaultListableBeanFactory 先看下继承关系 红框就是AbstractApplicationContext.obtainFreshBeanFactory() 出参的类型 再看下里面的核心属性 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455 /** Map from serialized id to factory instance */ // beanFactory Mapprivate static final Map&lt;String, Reference&lt;DefaultListableBeanFactory&gt;&gt; serializableFactories = new ConcurrentHashMap&lt;String, Reference&lt;DefaultListableBeanFactory&gt;&gt;(8);/** Optional id for this factory, for serialization purposes */private String serializationId;/** Whether to allow re-registration of a different definition with the same name */// 是否允许覆盖，默认是允许的private boolean allowBeanDefinitionOverriding = true;/** Whether to allow eager class loading even for lazy-init beans */// 是否允许以饥饿模式加载private boolean allowEagerClassLoading = true;/** Optional OrderComparator for dependency Lists and arrays */// 对于依赖项列表和数组 可选的OrderComparatorprivate Comparator&lt;Object&gt; dependencyComparator;/** Resolver to use for checking if a bean definition is an autowire candidate */// 自动注入的resolverprivate AutowireCandidateResolver autowireCandidateResolver = new SimpleAutowireCandidateResolver();/** Map from dependency type to corresponding autowired value */// 处理注入依赖的mapprivate final Map&lt;Class&lt;?&gt;, Object&gt; resolvableDependencies = new ConcurrentHashMap&lt;Class&lt;?&gt;, Object&gt;(16);/** Map of bean definition objects, keyed by bean name */// beanName map definitionprivate final Map&lt;String, BeanDefinition&gt; beanDefinitionMap = new ConcurrentHashMap&lt;String, BeanDefinition&gt;(256);/** Map of singleton and non-singleton bean names, keyed by dependency type */// 单例或者是非单例的beanprivate final Map&lt;Class&lt;?&gt;, String[]&gt; allBeanNamesByType = new ConcurrentHashMap&lt;Class&lt;?&gt;, String[]&gt;(64);/** Map of singleton-only bean names, keyed by dependency type */// 单例的bean信息private final Map&lt;Class&lt;?&gt;, String[]&gt; singletonBeanNamesByType = new ConcurrentHashMap&lt;Class&lt;?&gt;, String[]&gt;(64);/** List of bean definition names, in registration order */// 类加载进来的顺序private volatile List&lt;String&gt; beanDefinitionNames = new ArrayList&lt;String&gt;(256);/** List of names of manually registered singletons, in registration order */// 手动注入的单例private volatile Set&lt;String&gt; manualSingletonNames = new LinkedHashSet&lt;String&gt;(16);/** Cached array of bean definition names in case of frozen configuration */// 缓存bean信息，以防某一时候不允许修改配置private volatile String[] frozenBeanDefinitionNames;/** Whether bean definition metadata may be cached for all beans */// 是否需要缓存所有的definition metadata 默认为falseprivate volatile boolean configurationFrozen = false; BeanDefinition （bean 的信息） 记录Bean的信息 Depends-on 依赖关系 是否可以注入 是否是由FactoryBean 生成 是否是primary 构造器参数 …等等 BeanDefinition 继承关系 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160public interface BeanDefinition extends AttributeAccessor, BeanMetadataElement &#123; /** * 支持的类型 单例 */ String SCOPE_SINGLETON = ConfigurableBeanFactory.SCOPE_SINGLETON; /** * 支持的类型 原型 */ String SCOPE_PROTOTYPE = ConfigurableBeanFactory.SCOPE_PROTOTYPE; /** * Role hint indicating that a &#123;@code BeanDefinition&#125; is a major part * of the application. Typically corresponds to a user-defined bean. */ int ROLE_APPLICATION = 0; /** * Role hint indicating that a &#123;@code BeanDefinition&#125; is a supporting * part of some larger configuration, typically an outer * &#123;@link org.springframework.beans.factory.parsing.ComponentDefinition&#125;. * &#123;@code SUPPORT&#125; beans are considered important enough to be aware * of when looking more closely at a particular * &#123;@link org.springframework.beans.factory.parsing.ComponentDefinition&#125;, * but not when looking at the overall configuration of an application. */ int ROLE_SUPPORT = 1; /** * Role hint indicating that a &#123;@code BeanDefinition&#125; is providing an * entirely background role and has no relevance to the end-user. This hint is * used when registering beans that are completely part of the internal workings * of a &#123;@link org.springframework.beans.factory.parsing.ComponentDefinition&#125;. */ int ROLE_INFRASTRUCTURE = 2; // Modifiable attributes /** * 设置父BeanDefinition. bean继承，会继承父bean的信息（Class信息）。 */ void setParentName(String parentName); /** * get. */ String getParentName(); /** * 设置bean的类名 */ void setBeanClassName(String beanClassName); /** * 获取bean的类型，英文注释中表示这个运行中并不一定是实际bean类型（factoryBean之类的） */ String getBeanClassName(); /** */ void setScope(String scope); /** */ String getScope(); /** * 是否需要lazeinit */ void setLazyInit(boolean lazyInit); boolean isLazyInit(); /** * bean依赖的所有bean。注意点并不是属性依赖@Autowire标记的，而是depends-on=&quot;&quot; 属性设置的值 */ void setDependsOn(String... dependsOn); String[] getDependsOn(); // 是否可以注入到其他的bean void setAutowireCandidate(boolean autowireCandidate); boolean isAutowireCandidate(); /** * 是否是主要的。多个实现类，会有一个主要的实现。@Primary */ void setPrimary(boolean primary); boolean isPrimary(); /** 指定factoryBean. 通过factoryBean 生成 */ void setFactoryBeanName(String factoryBeanName); String getFactoryBeanName(); /** 指定factoryBean中的方法 */ void setFactoryMethodName(String factoryMethodName); String getFactoryMethodName(); // 构造器参数 ConstructorArgumentValues getConstructorArgumentValues(); // bean中的属性值 MutablePropertyValues getPropertyValues(); // Read-only attributes //是否singleton boolean isSingleton(); // 是否 prototype boolean isPrototype(); // 是否是抽象基类 boolean isAbstract(); /** * Get the role hint for this &#123;@code BeanDefinition&#125;. The role hint * provides the frameworks as well as tools with an indication of * the role and importance of a particular &#123;@code BeanDefinition&#125;. * @see #ROLE_APPLICATION * @see #ROLE_SUPPORT * @see #ROLE_INFRASTRUCTURE */ int getRole(); /** * Return a human-readable description of this bean definition. */ String getDescription(); /** * Return a description of the resource that this bean definition * came from (for the purpose of showing context in case of errors). */ String getResourceDescription(); /** * Return the originating BeanDefinition, or &#123;@code null&#125; if none. * Allows for retrieving the decorated bean definition, if any. * &lt;p&gt;Note that this method returns the immediate originator. Iterate through the * originator chain to find the original BeanDefinition as defined by the user. */ BeanDefinition getOriginatingBeanDefinition();&#125; AbstractApplicationContext.finishBeanFactoryInitialization 实例化所有非lazy-init的singletons 具体流转图如下 后面具体的逻辑可以参见文章最下面的参考，这里就不在赘述了。 需要注意的： 实例化类是根据反射来实例化的。 对于实例类中的属性，是使用populateBean方法进行属性赋值的 对于autowire的属性，会先查找/创建对应的实例，然后再进行赋值 123456789101112131415161718192021222324252627282930313233343536protected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) &#123; // Initialize conversion service for this context. // 加载conversionService if (beanFactory.containsBean(CONVERSION_SERVICE_BEAN_NAME) &amp;&amp; beanFactory.isTypeMatch(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)) &#123; beanFactory.setConversionService( beanFactory.getBean(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)); &#125; // Register a default embedded value resolver if no bean post-processor // (such as a PropertyPlaceholderConfigurer bean) registered any before: // at this point, primarily for resolution in annotation attribute values. if (!beanFactory.hasEmbeddedValueResolver()) &#123; beanFactory.addEmbeddedValueResolver(new StringValueResolver() &#123; @Override public String resolveStringValue(String strVal) &#123; return getEnvironment().resolvePlaceholders(strVal); &#125; &#125;); &#125; // Initialize LoadTimeWeaverAware beans early to allow for registering their transformers early. String[] weaverAwareNames = beanFactory.getBeanNamesForType(LoadTimeWeaverAware.class, false, false); for (String weaverAwareName : weaverAwareNames) &#123; getBean(weaverAwareName); &#125; // Stop using the temporary ClassLoader for type matching. beanFactory.setTempClassLoader(null); // Allow for caching all bean definition metadata, not expecting further changes. beanFactory.freezeConfiguration(); // Instantiate all remaining (non-lazy-init) singletons. // 实际加载所有的singtons beanFactory.preInstantiateSingletons() 总结 IOC实际是为了更好的对实例，依赖更好的管理 IOC是一种思想，DI是常用的实现，springIOC就是DI的一种 Spring IOC 实现的思路大致可以分为 先找到所有的bean，记录所有的bean信息（包含，父类信息，是否需要override，是否允许循环依赖） 等 然后再实例化所有非lazy-init的是单例 最后通过对外getBean函数来实例需要的实例 参考大佬 面试被问了几百遍的 IoC 和 AOP ，还在傻傻搞不清楚？ Spring IOC 容器源码分析]]></content>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>ioc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊java并发编程[JUC中的Executor]]]></title>
    <url>%2F2020%2F05%2F15%2FJUC-8%2F</url>
    <content type="text"><![CDATA[本文主要深入了解下 线程池，并剖析下JUC中的ThreadPoolExecutor 源码 demo 创建一个线程池, 然后执行size个任务123456789101112131415161718192021222324252627282930313233public class ExecutorTest &#123; final ExecutorService executorService = new ThreadPoolExecutor(4, 50, 3, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;()); @Test public void testEx() throws InterruptedException &#123; int size = 10; for (int i = 0; i &lt; size; i++) &#123; executorService.submit(new Job()); &#125; executorService.awaitTermination(30, TimeUnit.HOURS); &#125; class Job implements Runnable &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName() + &quot; start&quot;); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + &quot; end&quot;); &#125; &#125;&#125; Executors 整体结构 分为三部分 任务(Thread) 执行任务(ExecuteService) 任务结果(Future) 从上面的图我们可以观察到，核心还是ThreadPoolExecutor 以及其子类 ScheduledThreadPoolExecutor. 我们主要从ThreadPoolExecutor 执行流程剖析下 ThreadPoolExecutor核心源码剖析 从下面几个点读源码 ThreadPoolExecutor 关键性属性 ThreadPoolExecutor 构造方法 ThreadPoolExecutor 的submit 方法 ThreadPoolExecutor 的 execute方法 ThreadPoolExecutor 关键性属性123456789101112131415161718192021222324252627// 核心状态控制字段。 线程安全。 高三位表示线程状态，后29位表示工作的线程数。 private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));// 保存等待执行的阻塞队列. private final BlockingQueue&lt;Runnable&gt; workQueue;// 锁 保证操作安全 private final ReentrantLock mainLock = new ReentrantLock();// 存储线程池中的Worker。只有持有mainLock 才可以操作 private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;();// 线程工厂，线程池创建一个线程时，调用线程工厂创建 private volatile ThreadFactory threadFactory;// 线程池的拒绝策略 private volatile RejectedExecutionHandler handler;// 核心线程池 private volatile int corePoolSize;// 最大线程池数目 private volatile int maximumPoolSize;// 默认线程池拒绝策略 private static final RejectedExecutionHandler defaultHandler = new AbortPolicy(); ctl 原理解析 ctl int 32位。高三位表示线程状态，后29位表示工作的线程数。 涉及状态计算如下 RUNNING: ob11100000_00000000_00000000_00000000 // 只有这个最高位为1，所以只需要判断是否小于0 即可判断是否在运行 线程池在运行中，可接受也可执行队列中的任务 SHUTDOWN: ob00000000_00000000_00000000_00000000 关闭状态。不再接受新任务，但是可以继续处理阻塞队列中的任务。线程池在RUNNING时调用shutdown() 就会进入此状态 STOP: 0b00100000_00000000_00000000_00000000 停止状态，不接受任务，也不执行队列中的任务。调用shutdownNow 会进入此状态 TIDYING: 0b01000000_00000000_00000000_00000000 如果所有任务都已经终止了，workCount(有效线程数)为0，线程池会调用terminated() 进入TERMINATED 状态 TERMINATED: 0b01100000_00000000_00000000_00000000 在terminated() 方法执行完后进入该状态，默认terminated()方法中什么也没有做 下面是状态流转图 下面是任务执行流程图 ThreadPoolExecutor 构造方法 主要的都是调用下面的构造方法 123456789101112131415161718192021222324public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; &#125; 核心参数解释 corePoolSize 核心线程数。默认情况下创建线程池后，线程池并没有线程。直到后面有任务才会创建线程。可以通过prestartCoreThread()或prestartAllCoreThread()进行初始化。 maximumPoolSize 线程池中最大的线程数。 keepAliveTime 存活时间。默认情况下，线程池中线程数大于corePoolSize,线程空闲达到keepAliveTime就会被终止掉，直到线程池中的线程数不超过corePoolSize。如果设置了allowCoreThreaTimeOut,线程池中空闲时间达到keepAliveTime就会被终止掉，直到线程池中的线程数为0. unit keepAliveTime 的时间单位 workQueue: 保存等待执行的任务阻塞队列。当线程池中的线程数大于corePoolSizde时，会把待执行的任务封装成Work对象放进队列。不同的BlockingQueue有不同的线程池排队策略。 LinkedBlockingQueue 基于链表的FIFO的队列。默认队列大小为Integer.MAX_VALUE.所以是无界队列。当活跃线程等于 corePoolSize时，新建的任务都会被放进队列中等待。因为maximumPoolSize就是无效的。所以无界队列适用于某一时间端的高并发(就是核心线程不变，所有任务排队执行) ArrayBlockingQueue： 有界队列。适用于防止资源耗尽 SynchronousQueue： 无界缓存值为1的等待队列。其特性就是每次添加一个元素后，必须等待其他线程取走后才需要添加。如果添加后没有线程在等待，并且线程池中的线程数不大于maximumPoolSize,就会创建一个新的线程。否则则会根据饱和策略拒绝掉这个任务。 threadFactory 线程工厂。线程池每需要创建一个线程时，都会调用线程工厂来完成。默认的线程工厂DefaultThreadFactory 会创建一个新的，非守护的仙鹤草呢个，不包含任何的配置信息。通常情况下都是要自己定义线程工厂方法,便于排查问题： 新建线程提供名字，后续排查方便 为线程指定UncaughtExceptionHandler来处理线程执行过程中未被捕获的异常。 修改线程优先级等 handler: RejectedExecutionHandler 线程池的拒绝策略.如果阻塞队列满了且线程数达到了maximum，此时继续提交任务就会触发拒绝策略。JUC默认提供了四种不同的策略： CallerRunPolicy 由调用方线程执行(阻塞主线程) AbortPolicy 直接丢出RejectedExecutionException. 默认 DiscardPolicy 直接丢弃任务。 DiscardOldPolicy 利用FIFO 丢弃队列中最靠前的任务，并尝试再次执行。 源码 具体逻辑见源码注释。 需要注意： 一个Worker 就是线程池中的一个线程. Worker 集成了AQS, 其内部是独占锁的实现 创建新Worker 可以使用new Worker(null) worker.thread.start 会调用worker.run() 实际是runWorker()方法 worker 轮询队列执行 执行完之后删除worker，并根据实际的最小线程池数，创建新worker ThreadPoolExecutor.execute 方法 submit 本质上也是调用的这个方法 1234567891011121314151617181920212223242526272829public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); // 判断是否小于核心线程数。注意 如果是非运行中的其他状态，都是大于corePoolSize 的。具体可以看下ctl 的构成，以及设计原理。 if (workerCountOf(c) &lt; corePoolSize) &#123; // 如果添加，运行成功，返回 if (addWorker(command, true)) return; // 到这里肯定是没有添加成功 c = ctl.get(); &#125; // 判断是否在运行，以及能否入队 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; // 这里double check 是因为中间线程池可能会 被关闭 int recheck = ctl.get(); // 如果没有运行 并且从队列中移除了job if (! isRunning(recheck) &amp;&amp; remove(command)) // 调用拒绝策略 reject(command); // 运行中的数量为0 else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; // 前置就表示队列已经满了 尝试直接添加进线程池中。 注意addWorker 就是一个CAS。所以在SynchronizedQueue 情况下，如果所有线程池中的线程都运行很久，就会导致主线程卡在第一个阻塞的代码块处。 else if (!addWorker(command, false)) reject(command); &#125; ThreadPoolExecutor.addWorker方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081// 添加一个Worker (一个worker就是一个线程池中可执行的线程) private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // &gt;= SHUTDOWN 表示不是在运行, 不接受任何新增任务 if (rs &gt;= SHUTDOWN &amp;&amp; ! (SHUTDOWN状态，并且(task 是null 并且队列非空)) ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); // 超过最大线程池数了 if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; // CAS 添加WorkerCount. 成功 跳出双重死循环 if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl // 如果运行的数量跟实际读取的不一致，重新计算下数量。调到第一层死循环 if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; // 到这里 肯定是标识新增workerCount 成功。 （还没有真正创建worker） boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; // new Worker 会在内存使用线程工厂创建一个Thread w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); // rs &lt; SHUTDOWN 标识在运行 if (rs &lt; SHUTDOWN || // 下面这个条件标识可以新建一个新的线程 (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; // 如果新建的线程在运行，肯定是不对的 if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); // 添加worker 成功 workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; // 运行线程 t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) // 失败处理 addWorkerFailed(w); &#125; return workerStarted; &#125; ThreadPoolExecutor.runWorker 方法 while 一直从队列中获取任务. 使用getTask() 方法获取 如果线程池正在停止，保证该线程是中断状态，否则就保证是非中断状态。 beforeExecute &amp;&amp; afterExecute 是扩展方法 队列执行完之后调用processWorkerExit 对该Worker 进行销毁等其他操作 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; while (task != null || (task = getTask()) != null) &#123; w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt // 如果线程池正在停止，保证该线程是中断状态。否则就保证是非中断状态。 if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; // before 扩展函数 beforeExecute(wt, task); Throwable thrown = null; try &#123; task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; // after 扩展函数 afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; // 到这里就表示阻塞队列全空了，需要做其他的策略 processWorkerExit(w, completedAbruptly); &#125; &#125; ThreadPoolExecutor.getTask() 主要目的是为了获取队列中的任务12345678910111213141516171819202122232425262728293031323334353637383940private Runnable getTask() &#123; boolean timedOut = false; // Did the last poll() time out? for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // 队列空了就减少个worker if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; int wc = workerCountOf(c); // Are workers subject to culling? boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; // 如果运行的worker 数目大于最大值，或者是超时了 if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; // 不同的策略，如果允许获取超时，就是使用poll 超时获取，否则就是通过take 方法获取阻塞队列数据 Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; // 到这里就表示超时了 timedOut = true; &#125; catch (InterruptedException retry) &#123; timedOut = false; &#125; &#125; &#125; ThreadPoolExecutor.processWorkerExit 销毁当前线程 如果当前线程池数目小于allowCoreThreadTimeOut ? 0(允许corePoolThread 超时) : corePoolSize。则新创建一个线程。123456789101112131415161718192021222324252627private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; if (completedAbruptly) // If abrupt, then workerCount wasn&apos;t adjusted decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; completedTaskCount += w.completedTasks; workers.remove(w); &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate(); int c = ctl.get(); if (runStateLessThan(c, STOP)) &#123; if (!completedAbruptly) &#123; int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; if (workerCountOf(c) &gt;= min) return; // replacement not needed &#125; addWorker(null, false); &#125; &#125; 总结 一个线上案例 线上现状 线上疯狂FullGc 原因 原来定义的代码是下面的 12private ThreadPoolExecutor executorService = new ThreadPoolExecutor(0, 10, 60, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;()); corePoolSize 设置为0 就会创建一个线程池。后续任务会放进到队列 但是LinkedBlockingQueue 是一个无界的阻塞队列。就导致后续的队列都是直接放进队列，并没有创建新的线程，所以就把内存撑爆了。 解决 将无界队列改为有界队列 new ArrayBlockingQueue corePoolSize 设置大一点 参考《java并发编程的艺术》方腾飞 魏鹏 程晓明 著]]></content>
      <tags>
        <tag>java</tag>
        <tag>executor</tag>
        <tag>ThreadPoolExecutor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊java并发编程[HashMap && ConcurrentHashMap]]]></title>
    <url>%2F2020%2F05%2F12%2FJUC-7%2F</url>
    <content type="text"><![CDATA[本篇我们聊聊HashMap &amp;&amp; ConcurrentHashMap. HashMap我们从下面几个角度来剖析下jdk1.8的HashMap HashMap 的存储结构 HashMap的构造器 HashMap的put方法 HashMap的get方法 HashMap 的存储结构 如果冲突数是小于阈值(默认是8) 则是数组+链表 如果冲突数是大于阈值(默认是8) 则是数组+红黑树 具体见下图 HashMap的构造器1234567891011121314151617181920212223242526272829// 初始化size. 并且制定需要resize的阈值public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); &#125; // 制定数组的长度(注意这里实际是threshold. threshold是最小的2^n并且大于等于initialCapacity ) public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; // resize 的阈值 public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted &#125; // 其他的Map public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false); &#125; HashMap的put方法 需要注意的是jdk1.8中引入了红黑树，本篇对红黑树不多讲，如果需要知道详细的请自行google123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158// 对外public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125; // 这个方法是优化 // 1 h&gt;&gt;&gt; 16 表示高位也参与了计算，减小碰撞率 // 2 (n-1)&amp;hash == hash%n &amp;比%计算的快 static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; // 插入新节点，replace 原有的value,resize, 链表转红黑树 final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 如果table 为null, 或者是tab的长度为0，就需要进行扩容 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 扩容 resize // 如果对应的节点值为Null 则表示没有碰撞，直接创建一个新的node if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; // 表示有碰撞了 Node&lt;K,V&gt; e; K k; // 这个表示 key是一样的 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 如果key 不一样 并且是TreeNode 就需要红黑树插入 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; // key不一样，并且不是树节点，就表示是链表了。需要将节点追加到链表的尾部(如果超过阈值(默认8)，就需要转成红黑树) for (int binCount = 0; ; ++binCount) &#123; // 如果同样key 的Node 没有下一个Node. 则直接追加一个新的Node if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); // 是否超过红黑树的阈值 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; // 这里表示下一个节点的key与要插入的key是一样的 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; // 继续下一个Node p = e; &#125; &#125; // e不为null 则表示有同样key的Node存在 if (e != null) &#123; // existing mapping for key V oldValue = e.value; // onlyIfAbsent-&gt;为false 或者原来的value为null. 则表示需要替换掉原来的值 if (!onlyIfAbsent || oldValue == null) e.value = value; // 额外的接口，访问完之后回调 afterNodeAccess(e); return oldValue; &#125; &#125; // 到这里 就表示没有key一样，并且已经Put了 ++modCount; // 更新size if (++size &gt; threshold) resize(); // 插入成功之后回调 afterNodeInsertion(evict); return null; &#125; // 扩容 final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; // 如果原有table不为空 if (oldCap &gt; 0) &#123; // 原有table 大于最大的数组，不用扩容了 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 这里就是扩容一倍， 设置新的上限 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; // 原有为空，则查看阈值是否大于0 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; // 默认值，或者是指定的值 else &#123; // 到这里 其实就是 原来数组没有值，并且threshold也小于等于0，就直接给默认值 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // newThr(前面初始化为0) 为0,则需要重新计算下上限 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; // 截止到这里，扩容已经完成了，下面就是讲原来的数据全部重新计算下hash @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; // if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; // 如果没有下一个节点，直接赋值 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; // 如果下一个节点是红黑树，进行红黑树的操作 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); // 链表 // 下面操作的逻辑是，因为是扩容了2倍，所以将原来链表上的数据根据新的hash值，拆分成高位的(j+oldCap)&amp;低位的(j) 两个链表 else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; // 返回扩容后的先的tab return newTab; &#125; HashMap的get方法1234567891011121314151617181920212223242526272829public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; // 如果tab 不为空，且length不大于等于0 且命中hash if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // 如果第一个节点的key与key是一样的，直接返回 ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; // 如果第一个没有命中，且有子节点 if ((e = first.next) != null) &#123; // 如果是红黑树 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 链表 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; // 没有命中 return null; &#125; HashMap 线程不安全问题 jdk1.7 是存在多线程操作resize 死循环(这里简单提一下死循环的原因: resize的是时候链表会倒序。多个线程就会导致A-&gt;B-&gt;A.) jdk1.8虽然已经修复了死循环问题,但是没有加任何额外的同步操作，还是存在线程不安全。 存在数据丢失。 多线程时，如果线程A resize 了, hash结果为AHash， 线程B持有原有的threshold, 并且计算出来的hash也是AHash, 则直接覆盖掉对应的链表头。就会导致数据丢失。 线程安全的Map 前面聊到HashMap 不是线程安全的，在java中线程安全的Map有下面几个 Hashtable &amp; SynchronizedMap 方法使用synchronized 修饰。 效率偏低 ConcurrentHashMap 采用分段锁的概念，效率比Hashtable 高很多 ConcurrentHashMap我们从下面几个角度来剖析下jdk1.8的HashMap ConcurrentHashMap 的存储结构 ConcurrentHashMap的构造器 ConcurrentHashMap的put方法 ConcurrentHashMap的get方法前言 ConcurrentHashMap jdk1.5-jdk1.7 都是使用的分段锁的概念来保证线程安全，以及性能。 jdk1.8不一样的点在于 抛弃了原来分段锁的概念，使用CAS+synchronized 进行更细粒度的扩容与更新。 增加ForwardNode 来标识Node已经被移动，多线程并发 使用3个CAS保证的更新查找的原子性 sizeCtl不同值代表不同的操作 使用synchronized 替换ReentrantLock ConcurrentHashMap 的存储结构 存储结构与HashMap是一样的，不过是采用CAS+Synchronized 保证线程安全ConcurrentHashMap的构造器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105// 下面是一些关键性的属性/* ---------------- Fields -------------- */ /** * table Hash表 */ transient volatile Node&lt;K,V&gt;[] table; /** * 扩容的时候使用。只有在扩容的时候是非空的 */ private transient volatile Node&lt;K,V&gt;[] nextTable; /** * 保存的是hashmap 中的数目，使用CAS更新。 */ private transient volatile long baseCount; /** * 有下面几个作用： * 1 sizeCtl 为负数时，-1标识正在初始化。-N标识正在有N-1个线程在进行扩容操作 * 2 sizeCtl 为正数是。 * - 如果数组为Null 则表示是在初始化过程中，sizeCtl 为新建数组的长度。 * - 如果已经初始化了，则表示当前数据容器(table数组)的临界值. （临界值=数组的长度*loadFactor） * 3 sizeCtl为0 则表示数组长度为默认值(16) */ private transient volatile int sizeCtl; /** * The next table index (plus one) to split while resizing. * 扩容中下一个需要操作的节点。 */ private transient volatile int transferIndex; /** * Spinlock (locked via CAS) used when resizing and/or creating CounterCells. */ private transient volatile int cellsBusy; /** * Table of counter cells. When non-null, size is a power of 2. */ private transient volatile CounterCell[] counterCells; // views private transient KeySetView&lt;K,V&gt; keySet; private transient ValuesView&lt;K,V&gt; values; private transient EntrySetView&lt;K,V&gt; entrySet;/** * * 默认table size = DEFAULT_CAPACITY(16) */ public ConcurrentHashMap() &#123; &#125; /** 初始化 table size. 注意这里的sizeCtl */ public ConcurrentHashMap(int initialCapacity) &#123; // 如果初始化的长度小于0 if (initialCapacity &lt; 0) throw new IllegalArgumentException(); // 超过了最大值就是最大值，否则就是最近的2次幂(具体可看hashmap) int cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1)); // 只是长度，还没有开始构建table. put的时候才会构建 this.sizeCtl = cap; &#125; /** * Creates a new map with the same mappings as the given map. * * @param m the map */ public ConcurrentHashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.sizeCtl = DEFAULT_CAPACITY; putAll(m); &#125; /** // 具体看下面的构造方法 */ public ConcurrentHashMap(int initialCapacity, float loadFactor) &#123; this(initialCapacity, loadFactor, 1); &#125; /** 指定，初始化的table size。 以及扩容阈值。 concurrencyLevel 我理解是支持并发的节点数。 因为jdk1.8是每个Node作为一个端，所以如果初始化的节点小于并发节点数，就设置为并发的节点数 */ public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123; if (!(loadFactor &gt; 0.0f) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if (initialCapacity &lt; concurrencyLevel) // Use at least as many bins initialCapacity = concurrencyLevel; // as estimated threads long size = (long)(1.0 + (long)initialCapacity / loadFactor); int cap = (size &gt;= (long)MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int)size); this.sizeCtl = cap; &#125; ConcurrentHashMap的put方法 增加/更新数据 链表-&gt;红黑树 扩容 size更新123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174public V put(K key, V value) &#123; return putVal(key, value, false); &#125; /** Implementation for put and putIfAbsent */ final V putVal(K key, V value, boolean onlyIfAbsent) &#123; // 如果key 或者value为null 则直接报错 if (key == null || value == null) throw new NullPointerException(); // rehash 类似HashMap中的Hash int hash = spread(key.hashCode()); int binCount = 0; // 注意这里是一个死循环 // 终止的条件是put成功之后才会跳出去 for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; // 如果table 为null 那么需要初始化表 if (tab == null || (n = tab.length) == 0) tab = initTable(); // 初始化 // table 不为空， 且对应位置没有冲突 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; // 直接更新到对应的节点 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; // 如果正在扩容 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); // 多线程扩容 // table 不为 null &amp;&amp; 且不在扩容，且有冲突 else &#123; V oldVal = null; // 锁 synchronized (f) &#123; // 这里为什么还会再判断一次，是因为其他线程可能改了对应的Node if (tabAt(tab, i) == f) &#123; // fh 是Node 的节点Hash值，fh不为0 则表示是链表 if (fh &gt;= 0) &#123; binCount = 1; // 下面的操作是：1 如果存在key一样的，则根据onlyIfAbsent 更新，或者是放弃更新 2 如果不存在key一样的，则在链表尾部追加 // 注意这里的binCount.只有链表才会自增(为下面treeifyBin做数量判断) for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; // 如果是树 else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; // 则更新红黑树 if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; // binCount 标识更新了，注意这里没有synchronized 修饰。 但是里面真正调整，还是有用到synchronized 修饰的 if (binCount != 0) &#123; // binCount 如果是红黑树，则一直是2 // 如果小于TREEIFY_THRESHOLD，则需要将链表转换成红黑树 if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); // oldVal不为null 则表示有相同的key if (oldVal != null) return oldVal; break; &#125; &#125; &#125; // 修改当前的数量，并且检查是否需要扩容 addCount(1L, binCount); return null; &#125; // CAS 查询对应节点 static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) &#123; return (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE); &#125; // CAS 比较并且set static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) &#123; return U.compareAndSwapObject(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, c, v); &#125; // CAS 无比较 直接set static final &lt;K,V&gt; void setTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; v) &#123; U.putObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, v); &#125; /** * Helps transfer if a resize is in progress. */ final Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) &#123; Node&lt;K,V&gt;[] nextTab; int sc; if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp; (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != null) &#123; int rs = resizeStamp(tab.length); while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp; (sc = sizeCtl) &lt; 0) &#123; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex &lt;= 0) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) &#123; transfer(tab, nextTab); break; &#125; &#125; return nextTab; &#125; return table; &#125; /** * 修改当前的baseCount, 提供是否需要扩容标识 */ private final void addCount(long x, int check) &#123; CounterCell[] as; long b, s; if ((as = counterCells) != null || !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) &#123; CounterCell a; long v; int m; boolean uncontended = true; if (as == null || (m = as.length - 1) &lt; 0 || (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null || !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) &#123; fullAddCount(x, uncontended); return; &#125; if (check &lt;= 1) return; s = sumCount(); &#125; // 如果需要检查 if (check &gt;= 0) &#123; Node&lt;K,V&gt;[] tab, nt; int n, sc; // s &gt;= sizeCtl 则表示是需要扩容的 while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123; int rs = resizeStamp(n); // sc 小于0 则表示需要扩容或者是扩容中 if (sc &lt; 0) &#123; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) // 扩容 transfer(tab, nt); &#125; // sc 大于等于0 就表示是第一个或者唯一一个发起扩容的线程。 else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); s = sumCount(); &#125; &#125; &#125; ConcurrentHashMap的transfer方法 主要分为两部分 一个是先扩容一个nextTable 长度为2倍的当前节点 第二个部分就是讲原来tab中的数据迁移到新的Table中。 这里更新是多线程的。如何是多线程呢？ 这里注意一个ForwardNode。ForwardNode 是一个集成Node的子类，但是实际上只有next 会有值(第一部分的nextTable). 操作流程(具体可以看代码注释，这里只是简单总结下是如何做到多线程更新的) 具体来讲就是如果在扩容中，这个时候回更新整个tab 到新的nextTable. 从前到后依次调整，如果已经操作过了节点 将ForwardNode 放置在Node上，如果其他节点查询到该节点是ForwardNode，那么就会调用helpTransfer(). 这样子就是多线程帮忙迁移了 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; int n = tab.length, stride; // 这里应该是最小线程操作逻辑 if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range // 如果nextTab 为null, 则需要将其扩容到2xTab if (nextTab == null) &#123; // initiating try &#123; @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; nextTab = nt; &#125; catch (Throwable ex) &#123; // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; &#125; nextTable = nextTab; transferIndex = n; &#125; int nextn = nextTab.length; // 这个是个标识，标识正在扩容中。在扩容迁移的时候回设置在tab中 ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); // 注意，advance 这个标识，是标识上一次迁移到nextTab 成功了，需要进行下一个迁移的节点 boolean advance = true; boolean finishing = false; // to ensure sweep before committing nextTab // 这个for 循环的终止条件注意下 // 1 finishing = true // 2 (sizeCtl - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT // 这个后面会解释为什么会是这行代码 for (int i = 0, bound = 0;;) &#123; Node&lt;K,V&gt; f; int fh; while (advance) &#123; int nextIndex, nextBound; // 如果--i &gt;= bound 则表示找到了下一个需要移动的 // 或者是finishing 就表示需要结束 if (--i &gt;= bound || finishing) advance = false; // 如果下一个index &lt;= 0 则表示就需要结束了。需要移动的值 else if ((nextIndex = transferIndex) &lt;= 0) &#123; i = -1; advance = false; &#125; // 找到了下一个需要移动的 else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; bound = nextBound; i = nextIndex - 1; advance = false; &#125; &#125; // i &lt; 0 表示已经移动完了 // i &gt;= n || i + n &gt;= nextn i 理论上最大就是N，i&gt; n 表示多线程put,即现在的size 已经不是最新的了 if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; int sc; if (finishing) &#123; // 如果finishing已经结束 nextTable = null; // 释放空间 table = nextTab; sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); // 2n-0.5 = 1.5n return; &#125; // sizeCtl 会在迁移前设置为 rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2 ---&gt; 参见addCount 方法 // 每个线程参与迁移sizeCtl 都会+1 U.compareAndSwapInt(this, SIZECTL, sc, sc + 1) ---&gt; 参见addCount 方法 // 使用CAS 对SIZECTL 减1 表示自己的任务已经完成 if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; // sizeCtl 在迁移前设置 为 rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2 // 每个线程在 开始执行前 +1 U.compareAndSwapInt(this, SIZECTL, sc, sc + 1) // 每个线程执行完成之后 -1 U.compareAndSwapInt(this, SIZECTL, sc, sc - 1) // 那么最后一定有sc-2 == resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT // 即表示所有线程操作完成 if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; finishing = advance = true; // 再次循环检查一下整张表 i = n; // recheck before commit &#125; &#125; // 没有命中之后的，则需要插入fwd，则表示需要线程并发 else if ((f = tabAt(tab, i)) == null) // 则表示 advance = casTabAt(tab, i, null, fwd); // 如果线程A 操作了这个节点，那么其他节点查询到的一定是MOVED else if ((fh = f.hash) == MOVED) // 代表此节点已经完成，需要找下一个待迁移的 advance = true; // already processed // else &#123; synchronized (f) &#123; // 再次查询下 对应节点，以免其他节点已经更新了 if (tabAt(tab, i) == f) &#123; Node&lt;K,V&gt; ln, hn; // 表示是链表 if (fh &gt;= 0) &#123; int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; // 将原来节点 链上的数据，拆分为两个链(如果可以) // 生成一个反序链表 for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; &#125; &#125; if (runBit == 0) &#123; ln = lastRun; hn = null; &#125; else &#123; hn = lastRun; ln = null; &#125; for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); // 这里放入fwd 表示已经在修饰了 setTabAt(tab, i, fwd); // 找下一个需要迁移的节点 advance = true; &#125; // 红黑树 else if (f instanceof TreeBin) &#123; TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) &#123; int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) == 0) &#123; if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; &#125; else &#123; if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; &#125; &#125; ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; &#125; &#125; &#125; &#125; &#125; ConcurrentHashMap的get方法123456789101112131415161718192021222324public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; // 获取hash 值 int h = spread(key.hashCode()); // 如果命中 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; // 如果是Node if ((eh = e.hash) == h) &#123; if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; // eh&lt;0 表示是红黑树 else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; // 否则就是链表，需要遍历下链表 while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null; &#125; 参考大佬JDK1.8 HashMap源码分析并发容器之ConcurrentHashMap详解(JDK1.8版本)与源码分析【Java并发】– ConcurrentHashMap如何实现高效地线程安全（jdk1.8）]]></content>
      <tags>
        <tag>java</tag>
        <tag>HashMap</tag>
        <tag>ConcurrencyMap</tag>
        <tag>Hashtable</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊JVM[深入了解jvm各模块]]]></title>
    <url>%2F2020%2F05%2F11%2FJVM-2%2F</url>
    <content type="text"><![CDATA[本篇详细聊聊Jvm 虚拟机栈，堆，以及GC 本文基于jdk1.8 虚拟机栈 VS 堆 栈管运行，堆管内存 (这个不一定全部，但是一定程度上也说明了栈堆的区别) 虚拟机栈 (VM Stack) 先放一张结构图 虚拟机栈属于非共享区域 每个线程都有一个自己的栈空间 可以通过-Xss20m（将栈空间设置成最大为20m） 栈的主要构成就是栈帧。一个方法的调用就是一个栈帧。 栈帧的里面的内容主要包括 局部变量表 编译的时候就已经确定了，这里涉及的内容不会改变 操作栈 简单理解就是一个方法里面的代码逻辑 也是基于栈来的。(更细维度的栈) 描述的是方法的具体执行 动态链接 简单理解就是对于对象，栈帧只保存其引用。其具体所在位置在堆中。 方法返回地址 方法退出有两种： 正常退出。如果有返回结果，则会把结果压入到上一个栈帧的操作栈中 异常退出。抛异常，由上层栈帧做异常处理 额外信息 因为在栈帧内存储的是局部变量，操作栈，动态链接都是在编译是确定的，所以一个栈帧的大小是固定的。 堆 (Heap) 主要存放各种实例对象 具体抽象结构如下 分区 Young Eden + survivor0+survivor1 (默认比例8:1:1) 使用的是复制GC(minor GC)， 每次总有一块Survivor 是空闲的。 90%可使用 Old minorGC超过(15次)存活的对象，或者是超大对象 FullGC. GC(垃圾回收) Garbage Collection先聊下那些需要被回收 虚拟机栈，程序计数器，本地方法栈。这三个都是随线程而生，随线程而灭, 所以不需要考虑过多考虑回收 堆与方法区复制 (Copying) 将内存分为两块(A,B)，平时只用一块A。GC的时候，将使用的一块A中GCROOTS可以查到的对象紧密复制到另一块B，然后将之前板块A全部清空。 优点：效率高 弊端：内存只能用一半 标记整理 （Mark-Compact） 过程 标记: 先通过GCROOTS到达的对象， 整理：移动所有标记存活的对象，重新排列。然后将内存地址值之后的内存清空 优点：内存使用率高，无内存碎片 弊端：需要暂停程序, 效率交Copying慢标记清除 (Mark-Sweep) 过程 标记: 先通过GCROOTS到达的对象， 清除：清楚未被标记的对象。 优点：内存使用率高。 缺点： 会产生内存碎片，逐渐的连续的可用空间越来越小，导致gc越来越频繁 需要暂停程序 分代收集 新生代(copying) 老年代(标记整理/标记清除) 垃圾回收器 jdk8 默认的是Parallel Scavenge + ParallelOld Serial(串行收集器) 单线程 stop the world 复制算法 ParNew(Serial的多线程版本) 复制算法 Parallel Scavenge 并行多线程收集器 复制算法 有自调节 SerialOld 串行老年代版本 标记/整理算法 ParallelOld 并行老年代版本 标记/整理算法 CMS 以最短回收停顿时间为目标，使用标记-清除算法 过程： 初始标记：stop the world 标记GC Roots能直接关联到的对象 并发标记：进行GC Roots Tracing 重新标记：stop the world；修正并发标记期间因用户程序继续运作而导致标记产生变动的 那一部分对象的标记记录 并发清除：清除对象 优点：并发收集，低停顿 缺点： 对CPU资源敏感 无法处理浮动垃圾（并发清除 时，用户线程仍在运行，此时产生的垃圾为浮动垃圾） 产生大量的空间碎片 G1 并行与并发 分代收集 面向服务端应用，将整个堆分为大小相同的region JVM 一些调优参数 -Xms512m （堆初始大小） -Xmx1024m（堆最大大小） -XX:MetaspaceSize=512m -XX:MaxMetaspaceSize=1024m. 调整元空间大小(存储java类信息) -Xss128m (虚拟机栈大小) -XX:NewRatio=4 (young:old=1:4) 默认是2]]></content>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
        <tag>stack</tag>
        <tag>heap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊java并发编程[JUC中的Condition]]]></title>
    <url>%2F2020%2F05%2F03%2FJUC-6%2F</url>
    <content type="text"><![CDATA[本文聊下JUC中的Condition使用，以及源码实现 什么是Condition Condition 实际是等待/通知模型的一种实现。 聊synchronized原理的时候，我们有聊到java中每个对象都有一个monitor, 被synchronized修饰的代码块/方法，在执行的时候，会先尝试获取到对应的monitor，如果没有获取到，则使用wait阻塞(重量级锁)，待其他获取到monitor的线程释放掉monitor，调用notify再尝试重新获取signal。wait/notify方法就是所谓的等待/通知模型。 synchronized 做为隐式的，有对应的显示实现Lock。 monitor的等待/通知 ，同样有其对应的实现，即Condition接口。 Condition vs monitor 对比名称 monitor Condition 前置条件 获取到对象的锁 调用Lock.lock()获取到锁，Lock.newCondition创建Condition对象 调用方式 object.wait/notify condition.await/signal 等待队列个数 1个 多个 是否支持等待中，不响应中断 不支持 支持 是否支持等待到某个具体的时间点 不支持 支持(awaitUtile接口) demo构建一个有界队列创建两个条件:notEmpty（非空） notFull(非满)创建两个线程：一个生成，一个消费 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119public class ConditionTest &#123; class BoundedQueue&lt;T&gt; &#123; private Object[] items; private int addIndex, removeIndex, count; private Lock lock = new ReentrantLock(); private Condition notEmpty = lock.newCondition(); private Condition notFull = lock.newCondition(); public BoundedQueue(int size) &#123; this.items = new Object[size]; &#125; public void add(T t) throws InterruptedException &#123; lock.lock(); try &#123; while (count == items.length) &#123; // 表示满了 System.out.println(Thread.currentThread().getName() + &quot; is waiting empty&quot;); notFull.await(); &#125; items[addIndex] = t; if (++addIndex == items.length) &#123; addIndex = 0; &#125; ++count; // 表示非空 notEmpty.signal(); &#125; finally &#123; lock.unlock(); &#125; &#125; @SuppressWarnings(&quot;unchecked&quot;) public T pop() throws InterruptedException &#123; lock.lock(); try &#123; while (count == 0) &#123; System.out.println(Thread.currentThread().getName() + &quot; is waiting pop&quot;); notEmpty.await(); &#125; Object t = items[removeIndex]; if (++removeIndex == items.length) &#123; removeIndex = 0; &#125; --count; notFull.signal(); return (T) t; &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; @Test public void testCondition() throws InterruptedException &#123; BoundedQueue&lt;String&gt; boundedQueue = new BoundedQueue&lt;&gt;(5); ProductJob productJob = new ProductJob(boundedQueue); ConsumeJob consumeJob = new ConsumeJob(boundedQueue); productJob.start(); consumeJob.start(); productJob.join(); consumeJob.join(); &#125; class ProductJob extends Thread &#123; private BoundedQueue boundedQueue; public ProductJob(BoundedQueue boundedQueue) &#123; this.boundedQueue = boundedQueue; &#125; public void run() &#123; while (true) &#123; try &#123; boundedQueue.add(&quot;11&quot;); // 每2s 生产一个 Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; class ConsumeJob extends Thread &#123; private BoundedQueue boundedQueue; public ConsumeJob(BoundedQueue boundedQueue) &#123; this.boundedQueue = boundedQueue; &#125; public void run() &#123; while (true) &#123; try &#123; System.out.println(boundedQueue.pop()); // 每2s 生产一个 Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 原理剖析Condition 接口1234567891011121314151617public interface Condition &#123; //等待获取到锁，或者是被中断(被其他线程)。 从await返回一定是当前线程获取到锁了 void await() throws InterruptedException; // 等待 不响应中断 void awaitUninterruptibly(); // 等待/中断超时,与下面的区别是返回的是举例等待的时间有多少 long awaitNanos(long var1) throws InterruptedException; // 返回是否等待/中断超时 boolean await(long var1, TimeUnit var3) throws InterruptedException; // 等待/中断到某个确切的时间点 boolean awaitUntil(Date var1) throws InterruptedException; // 通知下一个 void signal(); // 通知所有的 void signalAll();&#125; Condition接口在JUC中的实现是AQS中的ConditionObject ConditionObjectConditionObject 实现Condition主要有三个点： 等待队列，等待，通知 等待队列 一个Condition 包含一个等待队列。 等待队列的节点是复用的AQS.Node 下面是ConditionObject 的属性 1234/** 首节点 */private transient Node firstWaiter;/** 尾节点 */private transient Node lastWaiter; 等待队列 等待队列与AQS的关系 具体见下图 等待(await) 源码 1234567891011121314151617181920public final void await() throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; // interrupt 是为了判断是中断异常，还是人为中断 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); &#125; 流程图 注意 因为wait是在获取到锁之后才被调用的，所以没有用CAS 通知(signal) 源码 123456789101112131415public final void signal() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignal(first); &#125; private void doSignal(Node first) &#123; do &#123; if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; first.nextWaiter = null; &#125; while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null); &#125; 流程图 参考大佬 《java并发编程的艺术》方腾飞 魏鹏 程晓明 著]]></content>
      <tags>
        <tag>java</tag>
        <tag>condition</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊java并发编程[JUC中的锁]]]></title>
    <url>%2F2020%2F05%2F03%2FJUC-5%2F</url>
    <content type="text"><![CDATA[早些时候找了下java中锁分类, 今天我们聊下java中的锁 场景在计算机科学中，锁是在执行多线程时用于强行限制资源访问的同步机制，即用于在并发控制中保证对互斥要求的满足。—&gt; 来自wikipedia sychronized vs Lock 类型 sychronized Lock 解决的问题 对访问资源进行限制 同sychronized 实现 内置关键字 基于AQS，实现接口 锁的获取与释放 可见性 隐式(手动加锁，隐式释放) 显式(需要手动获取与释放) 是否支持中断 不支持 支持 demo实现一个独占式锁 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159public class Mutex implements Lock &#123; private static class Sync extends AbstractQueuedSynchronizer &#123; @Override protected boolean isHeldExclusively() &#123; return getState() == 1; &#125; public boolean tryAcquire(int acquire) &#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; public boolean tryRelease(int release) &#123; if (getState() == 0) throw new IllegalMonitorStateException(); setExclusiveOwnerThread(null); setState(0); return true; &#125; Condition newCondition() &#123; return new ConditionObject(); &#125; &#125; private final Sync sync = new Sync(); @Override public void lock() &#123; sync.acquire(1); &#125; @Override public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1); &#125; @Override public boolean tryLock() &#123; return sync.tryAcquire(1); &#125; @Override public boolean tryLock(long time, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(time)); &#125; @Override public void unlock() &#123; sync.release(1); &#125; @Override public Condition newCondition() &#123; return sync.newCondition(); &#125; public static void main(String[] args) throws InstantiationException, IllegalAccessException, InterruptedException &#123; Mutex mutex = new Mutex(); Thread x = ObjectLock.class.newInstance(); x.start(); Thread t1 = mutex.new FuncLock2(false, mutex); Thread t2 = mutex.new FuncLock2(true, mutex); Thread t3 = mutex.new FuncLock2(true, mutex); t1.start(); t2.start(); t3.start(); t1.join(); t2.join(); t3.join(); System.out.println(mutex.testFinally()); &#125; public boolean testFinally()&#123; try&#123; return true; &#125; finally &#123; System.out.println(&quot;dsadsa&quot;); &#125; &#125; public class FuncLock2 extends Thread &#123; private Mutex mutex; private boolean boo; public FuncLock2(boolean b, Mutex mutex) &#123; this.boo = b; this.mutex = mutex; &#125; @Override public synchronized void run() &#123; if (this.boo) &#123; this.read(); &#125; else &#123; this.write(); &#125; &#125; private void read() &#123; mutex.lock(); try &#123; System.out.println(Thread.currentThread().getName() + &quot; read lock ing...&quot;); for (int i = 0; i &lt; 5; i++) &#123; System.out.println(mutex.sync.getQueuedThreads()); Thread.sleep(1000); &#125; &#125; catch (Exception e) &#123; &#125; finally &#123; System.out.println(Thread.currentThread().getName() + &quot; read lock end...&quot;); mutex.unlock(); &#125; &#125; private void write() &#123; mutex.lock(); try &#123; System.out.println(Thread.currentThread().getName() + &quot; write lock ing..&quot;); for (int i = 0; i &lt; 5; i++) &#123; System.out.println(mutex.sync.getQueuedThreads()); Thread.sleep(1000); &#125; &#125; catch (Exception e) &#123; &#125; finally &#123; System.out.println(Thread.currentThread().getName() + &quot; write end ing..&quot;); mutex.unlock(); &#125; &#125; &#125;&#125; 原理其实就是基于AQS 内置的一部分参数，然后实现tryAcquire，acquire等接口。 具体的可以看下这篇关于AQS的总结. 理解AQS原理其实就基本把JUC中的锁摸的差不多了。接下来我们主要的聊下公平锁，非公平锁，重入锁，重入读写锁。 公平锁 vs 非公平锁这两个是两种实现方式，一般锁内置的实现都是会有实现这两种。比如重入锁，重入读写锁内部都有公平与非公平方式的实现 “公平性与否是针对获取锁而言的，如果一个锁是公平的，那么锁的获取顺序就应该符合请求的绝对时间顺序，也就是FIFO。” 重入锁顾名思义就是一个线程在获取到锁之后，再次获取锁。sychronized 也是可重入锁。重入锁其实是独占式状态共享 demo 打印当前等待的线程 主要接口就是lock() &amp;&amp; unlock123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public class ReenTrantLockTest &#123; static ReentrantLock reentrantLock = new ReentrantLock2(true); static ReentrantLock reentrantLockUnfair = new ReentrantLock2(false); @Test public void testReenTrantLockUnFairAndFair() throws InterruptedException &#123; Thread[] threads = new Thread[5]; for (int i = 0; i &lt; 5; i++) &#123; threads[i] = new Thread(new Job(reentrantLock)); threads[i].start(); &#125; for (int i = 0; i &lt; 5; i++) &#123; threads[i].join(); &#125; &#125; private static class Job extends Thread &#123; private Lock lock; public Job(Lock lock) &#123; this.lock = lock; &#125; public void run() &#123; for (int i = 0; i &lt; 2; i++) &#123; lock.lock(); try &#123; System.out.print(&quot;获取锁的当前线程[&quot; + Thread.currentThread().getName() + &quot;]&quot;); System.out.print(&quot;等待队列中的线程[&quot;); ((ReentrantLock2) lock).getQueueThreads(); System.out.println(&quot;]&quot;); reenDoSth(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; private void reenDoSth() &#123; lock.lock(); try &#123; System.out.println(&quot;reenDoSth[&quot; + Thread.currentThread().getName() + &quot;]&quot;); &#125; catch (Exception e) &#123; &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; private static class ReentrantLock2 extends ReentrantLock &#123; public ReentrantLock2(boolean fair) &#123; super(fair); &#125; public void getQueueThreads() &#123; ArrayList&lt;Thread&gt; threads = new ArrayList&lt;&gt;(super.getQueuedThreads()); threads.forEach(thread -&gt; System.out.print(thread.getName())); &#125; &#125;&#125; 源码分析 重入锁是一个典型的独占式锁 非公平锁####### lock ######## NonfairSync.lock 123456789101112131415/** * 获取到锁 */final void lock() &#123; // 如果可以直接获取到锁 if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else // 没有获取到锁， acquir会掉用下面的tryAcquire。实际是会调用 Sync.nonfairTryAcquire 方法 acquire(1);&#125;protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires);&#125; ######## Sync.nonfairTryAcquire 123456789101112131415161718192021222324252627/** * 非公平锁的获取到锁 */ final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); // 如果当前的状态是0, 则表示是可获取状态 if (c == 0) &#123; // 在多线程情况下，有可能其他线程已经获取到锁，所以要用CAS尝试赋值 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; // 如果当前锁已经被占用了，尝试判断是否是当前线程，如果是当前线程，则表示可以再次获取到锁. 这里就是重入锁了。 // 仔细想一下这里其实就是非公平锁的非公平，如果某个线程获取到锁了，与此同时如果再有新的(下面会将为什么一定是新的线程)个线程尝试获取锁，就有可能直接获取到锁，继续进行下去。 // 为什么一定是新的线程：因为AQS某个线程(节点)获取到锁的前提是，其前置节点为head 并且tryAcquire获取到锁，才会继续执行下去。具体可以看前置的AQS源码梳理 else if (current == getExclusiveOwnerThread()) &#123; // 这里为什么是c+acquires: 因为有可能在该线程获取到的时候，已经存在其他线程获取到重入锁了 int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125; ####### lock ######## NonfairSync.unlock 实际调用的是Sync.release12345678910111213141516171819202122232425public final boolean release(int arg) &#123; // 释放锁。 if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) // 唤醒后继节点 unparkSuccessor(h); return true; &#125; return false; &#125;protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; // 这里c == 0 才表示该线程所有获取到锁的都已经释放掉了 if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free; &#125; 公平锁####### lock ######## FairSync.lock 公平锁的获取稍微有点不一样123456789101112131415161718192021protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; // 比非公平锁多了一个一个 !hasQueuedPredecessors() 其他都一样 // 就是判断是否有前置节点，就是公平锁的本质，一定是按照顺序来的 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125; ####### unlock公平锁的释放与非公平锁的释放共用的一套代码，这里就不赘述了 重入锁总结 重入锁其实主要是依赖来AQS的内部实现。 公平锁的释放与非公平锁的释放是一样的 公平锁的获取与非公平锁的获取唯一的不同在与公平锁在判断是否可以获取到锁的时候，需要判断是否有前置节点 读写锁demo 读写操作夹杂，然后看当前等待的读写线程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113public class ReenTrantReadWriteLockTest &#123; static Map&lt;String, Integer&gt; cache = new HashMap&lt;&gt;(); static ReentrantReadWriteLock reentrantReadWriteLockUnFair = new ReentrantReadWriteLock2(false); static ReentrantReadWriteLock reentrantReadWriteLockFair = new ReentrantReadWriteLock2(true); @Test public void testWRLock() throws InterruptedException &#123; int index = 0; int length = 14; Thread[] threads = new Thread[length]; for (int i = 0; i &lt; 10; i++) &#123; threads[index++] = new ReadJob(reentrantReadWriteLockFair); if (i % 3 == 0) &#123; threads[index++] = new WriteJob(reentrantReadWriteLockFair); &#125; &#125; for (int i = 0; i &lt; length; i++) &#123; threads[i].start(); &#125;// reentrantReadWriteLockFair.getQueueLength() for (int i = 0; i &lt; length; i++) &#123; threads[i].join(); &#125; &#125; static class WriteJob extends Thread &#123; ReadWriteLock readWriteLock; public WriteJob(ReadWriteLock readWriteLock) &#123; this.readWriteLock = readWriteLock; &#125; public void run() &#123; readWriteLock.writeLock().lock(); try &#123; Thread.sleep(1000); String s = Thread.currentThread().getId() + &quot;-&quot; + cache.get(Thread.currentThread().getName()); cache.put(Thread.currentThread().getName(), ((ReentrantReadWriteLock2) readWriteLock).getQueueLength()); System.out.println(&quot;write[&quot; + Thread.currentThread().getName() + &quot;] &quot; + s); System.out.println(&quot;[&quot; + Thread.currentThread().getName() + &quot;] read &quot; + s); System.out.print(&quot;等待队列中的线程[&quot;); ((ReentrantReadWriteLock2) readWriteLock).getWaitQueue(); System.out.println(&quot;]&quot;); read(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; readWriteLock.writeLock().unlock(); &#125; &#125; private void read() &#123; readWriteLock.readLock().lock(); try &#123; Integer s = cache.get(Thread.currentThread().getName()); System.out.println(&quot;[&quot; + Thread.currentThread().getName() + &quot;] read &quot; + ((ReentrantReadWriteLock2) readWriteLock).getQueueLength());// System.out.print(&quot;等待队列中的线程[&quot;);// ((ReentrantReadWriteLock2) readWriteLock).getWaitQueue();// System.out.println(&quot;]&quot;); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; readWriteLock.readLock().unlock(); &#125; &#125; &#125; static class ReadJob extends WriteJob &#123; public ReadJob(ReadWriteLock readWriteLock) &#123; super(readWriteLock); &#125; public void run() &#123; super.read(); &#125; &#125; private static class ReentrantReadWriteLock2 extends ReentrantReadWriteLock &#123; public ReentrantReadWriteLock2(boolean fair) &#123; super(fair); &#125; public void getWaitQueue() &#123; // 打印等待写的线程 super.getQueuedWriterThreads().forEach(thread -&gt; System.out.print(thread.getName())); System.out.println(); // 打印等待读的线程 super.getQueuedReaderThreads().forEach(thread -&gt; System.out.print(thread.getName())); &#125; &#125; 读写锁重写读写锁 是共享式状态共享(读) + 独占式状态共享(写) 举例A(R)-&gt;B(w)-&gt;C(R)-&gt;D(R)-&gt;E(W)-&gt;F(R) 正确的获取应该是 A获取到锁 其他线程等待 B获取到锁(CDEF等待) C，D获取到锁(EF等待) E获取到锁(F等待) F获取到锁 demo 下面的demo 是读写夹杂，打印等待读写的线程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113public class ReenTrantReadWriteLockTest &#123; static Map&lt;String, Integer&gt; cache = new HashMap&lt;&gt;(); static ReentrantReadWriteLock reentrantReadWriteLockUnFair = new ReentrantReadWriteLock2(false); static ReentrantReadWriteLock reentrantReadWriteLockFair = new ReentrantReadWriteLock2(true); @Test public void testWRLock() throws InterruptedException &#123; int index = 0; int length = 14; Thread[] threads = new Thread[length]; for (int i = 0; i &lt; 10; i++) &#123; threads[index++] = new ReadJob(reentrantReadWriteLockFair); if (i % 3 == 0) &#123; threads[index++] = new WriteJob(reentrantReadWriteLockFair); &#125; &#125; for (int i = 0; i &lt; length; i++) &#123; threads[i].start(); &#125;// reentrantReadWriteLockFair.getQueueLength() for (int i = 0; i &lt; length; i++) &#123; threads[i].join(); &#125; &#125; static class WriteJob extends Thread &#123; ReadWriteLock readWriteLock; public WriteJob(ReadWriteLock readWriteLock) &#123; this.readWriteLock = readWriteLock; &#125; public void run() &#123; readWriteLock.writeLock().lock(); try &#123; Thread.sleep(1000); String s = Thread.currentThread().getId() + &quot;-&quot; + cache.get(Thread.currentThread().getName()); cache.put(Thread.currentThread().getName(), ((ReentrantReadWriteLock2) readWriteLock).getQueueLength()); System.out.println(&quot;write[&quot; + Thread.currentThread().getName() + &quot;] &quot; + s); System.out.println(&quot;[&quot; + Thread.currentThread().getName() + &quot;] read &quot; + s); System.out.print(&quot;等待队列中的线程[&quot;); ((ReentrantReadWriteLock2) readWriteLock).getWaitQueue(); System.out.println(&quot;]&quot;); read(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; readWriteLock.writeLock().unlock(); &#125; &#125; private void read() &#123; readWriteLock.readLock().lock(); try &#123; Integer s = cache.get(Thread.currentThread().getName()); System.out.println(&quot;[&quot; + Thread.currentThread().getName() + &quot;] read &quot; + ((ReentrantReadWriteLock2) readWriteLock).getQueueLength());// System.out.print(&quot;等待队列中的线程[&quot;);// ((ReentrantReadWriteLock2) readWriteLock).getWaitQueue();// System.out.println(&quot;]&quot;); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; readWriteLock.readLock().unlock(); &#125; &#125; &#125; static class ReadJob extends WriteJob &#123; public ReadJob(ReadWriteLock readWriteLock) &#123; super(readWriteLock); &#125; public void run() &#123; super.read(); &#125; &#125; private static class ReentrantReadWriteLock2 extends ReentrantReadWriteLock &#123; public ReentrantReadWriteLock2(boolean fair) &#123; super(fair); &#125; public void getWaitQueue() &#123; super.getQueuedWriterThreads().forEach(thread -&gt; System.out.print(thread.getName())); System.out.println(); super.getQueuedReaderThreads().forEach(thread -&gt; System.out.print(thread.getName())); &#125; &#125;&#125; 原理剖析详细的剖析可以看这篇文章我这边主要聊几个关键点 读写锁是可重入锁 状态的设计 一共32位。 高16位为读锁的状态 ，底16位为写锁的状态。 所以判断读写锁，根据位运算计算即可。 写锁 排它锁 获取的时候需要判断是否有读锁在获取，如果有，则获取失败.（如果可以获取成功，就是锁升级，ReentrantWriteReadLock 不支持） 读锁 共享锁 获取的时候，如果存在写锁，并且是当前线程，则是可以获取到锁的（锁降级） 。 HoldCounter 共享锁从某一角度来讲，就是一个计数器。这个计数器是于当前线程绑定的。 而HoldCounter可以理解为是这个计数器(原理是ThreadLocalCache) 参考大佬 ReentrantReadWriteLock读写锁详解 《java并发编程的艺术》方腾飞 魏鹏 程晓明 著]]></content>
      <tags>
        <tag>java</tag>
        <tag>lock</tag>
        <tag>ReentrantLock</tag>
        <tag>ReentrantReadWriteLock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊java并发编程[JUC中的原子操作类]]]></title>
    <url>%2F2020%2F04%2F29%2FJUC-4%2F</url>
    <content type="text"><![CDATA[通过本片文章，可以了解到JUC中的原子类的不同种类，其原理。 为什么要有原子操作类 前面我们讲过，java并发编程主要解决三个问题，可见性，有序性以及原子性。 对于可见性以及有序性，都可以通过volatile来解决。 原子性可以通过sychronized来修饰保证代码块的原子性，但是如果是使用volatile修饰的变量，其原子性无法保证。 证明 12345678910111213141516171819202122232425262728293031323334public class ValotileAtomicTest &#123; static volatile int a = 0;// AtomicInteger a = new AtomicInteger(0); @Test public void testVolatileUnSafeAtomic() throws InterruptedException &#123; Thread[] threads = new Thread[50]; for (int i = 0; i &lt; 50; i++) &#123; threads[i] = new Thread(new Runnable() &#123; @Override public void run() &#123; for (int j = 0; j &lt; 1000; j++) &#123; ++a;// a.incrementAndGet();// System.out.println(++a); &#125; &#125; &#125;); &#125; for (int i = 0; i &lt; 50; i++) &#123; threads[i].start(); &#125; for (int i = 0; i &lt; 50; i++) &#123; threads[i].join(); &#125; System.out.println(a); &#125;&#125;// 最后的结果 是 48618(机器不一样，可能结果就不一样，可以多跑几次，如果机器性能很好不一定能够看出来不是原子性的) 看到上面的结果是不是很奇怪。正常来讲最后的结果应该是50000。 实际上是因为 ++a 看似是一个操作，但是实际上并不是一个操作 先从主内存中读取a的值 再把a的值+1 再刷新到主存中 如果是多线程，就会有下面的场景出现 1 线程1先读取了a的值，然后被阻塞 2 线程2也先读取了a的值，但是没有被阻塞，然后+1，刷新到内存 3 线程1 解除阻塞，+1，刷新到主内 上述3个流程，实际是两个自增，但是只增加了1次。 原子操作类就是为了解决这种问题的。有兴趣的同学，可以把上面的AtomicInteger 取消注释，测试下，每次的结果都是理想中的50000. 原子操作类的分类(按照具体的场景)基本类型主要是更新基础类型 AtomicInteger 整型 AtomicLong 长整型原子类 AtomicBoolean 布尔类型 数组类型通过原子的方式更新数组中的某个元素 AtomicIntergeArray 整型数组 AtomicLongArray 长整形数组 AtomicReferenceArray 引用类型数组原子类 原子更新引用类型通过原子性的更新多个变量 AtomicReference 原子更新引用类型 AtomicReferenceFieldUpdater 原子更新引用类型里的字段 AtomicMarkableReference 原子更新带标记为的引用类型 原子更新字段类更新某个类的某个字段 AtomicIntegerFileUpdater 原子更新整型字段的更新器 AtomicLongFieldUpdater 原子更新长整型字段的更新器 AtomicStampedReference 原子更新带有版本号的引用类型。解决ABA 原理其实翻看下源码，getAndSet是利用CAS + Unsafe.compareAndSwapXXX() 算法。 CAS 历史文章有聊过这里不在赘述。 Unsafe看下Unsafe的源码，有三个compareAndSwap,分别是: 12345public final native boolean compareAndSwapObject(Object var1, long var2, Object var4, Object var5); public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); public final native boolean compareAndSwapLong(Object var1, long var2, long var4, long var6); 都是引用的native方法。 需要注意的是： 如果是AtomicBoolean 会先转换成int，然后使用compareAndSwapInt. 其他的char也可以利用此方法。 如果是其他的类可以可以使用AtomicReference进行原子性更改。 Unsafe 之所以是 Unsafe 是因为其直接是从内存的地址读取offset，并进行修改。 参考大佬 《java并发编程的艺术》方腾飞 魏鹏 程晓明 著]]></content>
      <tags>
        <tag>java</tag>
        <tag>atomic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无聊刷刷Leetcode(200. 岛屿数量)]]></title>
    <url>%2F2020%2F04%2F20%2Fleetcode-200%2F</url>
    <content type="text"><![CDATA[Leetcode200. 岛屿数量 题解 题目链接 思路 做的时候第一时间就想到了DFS. 从左至右遍历，找到某个1，就使用深搜找到所有相关联的1。并将搜索到的位置的值设置为0(因为是同一个岛屿) 看了下讨论区，还可以用BFS广搜, 或者是并查集…. 代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758class Solution: def numIslands(self, grid: List[List[str]]) -&gt; int: count = 0 // 直接输入[] max_raw = len(grid) if max_raw == 0: return count // 输入[&apos;1&apos;,&apos;0&apos;,&apos;1&apos;,&apos;1&apos;] if not isinstance(grid[0], List): flag = False for i in grid: if i == &apos;1&apos;: if not flag: count += 1 flag = True else: flag = False return count max_col = len(grid[0]) for i in range(max_raw): for j in range(max_col): if grid[i][j] == &apos;1&apos;: count += 1 self.dfs(grid, max_col, max_raw, j, i) return count def dfs(self, grid, max_col, max_row, col_inx, row_inx): grid[row_inx][col_inx] = &apos;0&apos; up_row = row_inx - 1 down_row = row_inx + 1 left_col = col_inx - 1 right_col = col_inx + 1 # 上面 if up_row &gt;= 0 and grid[up_row][col_inx] == &apos;1&apos;: self.dfs(grid, max_col, max_row, col_inx, up_row) # 左 if left_col &gt;= 0 and grid[row_inx][left_col] == &quot;1&quot;: self.dfs(grid, max_col, max_row, left_col, row_inx) # 右 if right_col &lt; max_col and grid[row_inx][right_col] == &quot;1&quot;: self.dfs(grid, max_col, max_row, right_col, row_inx) # 下 if down_row &lt; max_row and grid[down_row][col_inx] == &apos;1&apos;: self.dfs(grid, max_col, max_row, col_inx, down_row)]]></content>
      <tags>
        <tag>python</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊java并发编程[synchronized vs volatile]]]></title>
    <url>%2F2020%2F04%2F19%2FJUC-3%2F</url>
    <content type="text"><![CDATA[上一篇 我们聊了java 基于JMM 的原则，解决了并发编程中的三个点: 原子性 有序性 内存可见性。 java 实际解决依赖的内置原语有两个 synchronized 和volatile. 非内置的CAS，lock也是解决上述三个点的解决措施（之后会在其他文章赘述）。本篇文章，我们简单梳理下java synchornized和volatile的一些日常使用时候的注意点，以及简单的原理概括。 synchronized用法 synchronized 常用于方法或者是代码块。 synchronized 常用下面三个场景 修饰实例方法：作用于当前实例加锁，进入同步代码需要获取到当前实例的锁 修饰静态方法：作用于当前对象加锁，进入同步代码前要获取到当前对象的锁 修饰代码块，指定加锁对象，对指定对象加锁，进入同步代码库前获取到指定对象的锁。 synchronized 底层原理浅析1“JVM基于进入和退出Monitor对象来实现方法同步和代码块同步，但两者的实现细节不一样。代码块同步是使用monitorenter和monitorexit指令实现的，而方法同步是使用另外一种方式实现的，细节在JVM规范里并没有详细说明。但是，方法的同步同样可以使用这两个指令来实现” 《方腾飞,魏鹏,程晓明 著. “Java并发编程的艺术 (Java核心技术系列)》 monitorenter 编译后插入同步代码块的开始位置 monitorexit 编译后插入同步代码块的结束位置。 每个对象都有一个Monitor与之关联，当一个monitor被使用后，当线程在运行到monitorenter指令时候，会尝试获取锁。 Monitor java 内置 的Monitor（监视器），可以确保一个代码块多线程同时执行指定代码块同时只有一个线程在执行。 具体流程如下 因为synchronized 是依赖于java对象头来做monitor的获取和释放，所以下面聊下JAVA对象头 JAVA 对象头 本质上是根据对象头的不同内容来区分开无锁，偏向锁，轻量级锁，重量级锁 见下图 其中32位机器与64为机器头部放置的内容有点区别 锁升级 升级后的锁为无锁状态-&gt;偏向锁-&gt;轻量级锁。 偏向锁的获取与释放 因为大部分线程对统一代码块都是一个线程进行获取，所以引入了偏向锁的概念。 偏向锁的意思是，如果一个线程获取到了偏向锁，如果接下来的一段时间没有其他线程来竞争锁，那么持有偏向锁的线程再次进入或退出同一个代码块，不需要再次进行抢占所和释放锁的操作。 需要注意的是，如果存在多个线程在竞争同一个同步代码块的时候吗，会触发偏向锁的撤销，升级为轻量级锁。这里可以理解存在偏向锁状态，就是同一个线程在重复的执行同步代码块。 偏向锁可以通过 -XX:+UseBiasedLocking开启或者关闭 具体的获取与释放见下图 轻量级锁的获取与释放 前面聊到，多个线程竞争的时候，会导致偏向锁先升级为轻量锁。 轻量级锁，我理解是使用CAS尝试获取锁，如果CAS获取失败，那么就需要升级为重量级锁(线程wait.等待其他节点唤醒)。 具体的获取与释放见下图 重量级锁 当锁升级为重量级锁之后，内部的原理就是讲该线程临时挂起，等待获取锁的线程释放锁之后，再被唤醒。 注意 上面的从上面的分析来看，synchronized 在竞争获取锁的时候，是没有先后顺序的，这就有可能导致某个线程一直在挂起的状态。所以就有了java并发包中的lock接口(后续会聊到)。 volatile volatile 修饰是针对某个变量。 主要作用 保证线程对修饰的变量读取和写入时的可见性。即某个线程对变量修改后，其他线程是可以看到修改后的值的。 禁止指令重排。volatile 底层原理浅析 保证读写的可见性 这块的原理其实就是依赖于JMM的主内容与工作内存。 简单来讲就是线程在读写一个volatile修饰的变量时，都会主动刷新到主内存中，或者是主动从主内从读取。 禁止指令重排 原理是主要通过内存屏障来实现其内存可见性以及禁止指令重排。 关键性的就是要理解CPU指令内存屏障(Memory Barrier): 如果在指令间插入一条内存屏障指令，则表示告诉编译器和CPU，在内存屏障前后的指令都不允许和这条内存屏障重新排序。 内存屏障还有一点是，会强行输出各种CPU缓存数据，因此任何CPU上的线程都可以读取到数据的最新版本。 参考大佬(膜拜) 《java并发编程的艺术》方腾飞 魏鹏 程晓明 著 全面理解Java内存模型(JMM)及volatile关键字 深入理解Volatile (五)Synchronized原理分析]]></content>
      <tags>
        <tag>java</tag>
        <tag>synchronized</tag>
        <tag>volatile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊java并发编程[java实现之JMM]]]></title>
    <url>%2F2020%2F04%2F17%2FJUC-2%2F</url>
    <content type="text"><![CDATA[通过本篇文章，你可以从概念上理解java对于编发编程遇到的问题解决的原则或者是思想(JMM). 引言从聊聊java并发编程 [核心问题以及java解决方案]，聊聊java并发编程 [java实现的基石] 这两篇文章，我们聊到了并发编程的核心问题，以及java依赖相关工具实现。本篇文章，我们开始深入浅出聊下这些工具。 部分概念 线程之间的同步 同步具体是指程序中不同线程间操作发生的相对顺序。 java 共享内存模型表示程序员必须显示的对某个方法或代码块互斥执行。是显式的。 线程之间的通信 通信具体是指线程之间交换信息。 java共享内存模型 表示： 线程间的通信都是隐式通讯的。 JVM 部分概念 具体可以看这篇文章 现存的问题 由于JVM多线程对共享内存区域是有线程不安全的。 所以JVM定义了一组规则(JMM) 来解决这个问题(本质上是内存可见性)。 JMM 解决这个问题的有下面几个原则： 原子性 有序性 可见性(主) JMM相关概念以及理解 JMM(Java Memory Model)即 java 内存模型。是一个抽象的概念规范。其约定了程序中的各个变量(包括实例，静态字段以及其他对象数组元素)的访问方式。 JMM 主要有主内存，工作内存两个概念，来解决线程间的通信和同步问题。 主要解决内存可见性JMM 主内存 线程之间的共享变量(所有实例域，静态域，数组元素,这些都是存储在JVM堆内存中)存储在主内存中。 主要存储Java实例对象。无论该对象是局部变量还是成员变量，自然也包括，共享的类信息，，静态变量。基本可以理解所有的数据都会在主内存中存在。 多个线程同时操作某个变量，就会引发线程不安全。 实际存储： 从JVM的角度来讲，如果对于一个实例对象方法中的本地变量是基础数据类型(boolean,byte,short,char,int,long,float,double)，都是直接存储在JVM工作内存的栈帧结构。 如果本地变量是引用类型，则改变量的引用会存储在JVM工作内存的栈帧结构中，对象实例会在JVM主内存中(共享区域，堆). 对于实例的成员变量不管是基础类型还是非基础类型都是存储在堆中的。类本身信息以及静态变量也是存储在JVM主内存中的。 如果两个线程都调用了某个实例的方法，那么两个线程会将要操作的数据copy一份到自己的工作内存中，执行完成之后才会刷新到自己的工作内存中。JMM 工作内存 每个线程都有自己的私有的本地内存。本地内存存储了该线程的读/写共享变量的副本。 从JVM角度来讲：JMM内存因为是私有的数据变量，某种程度上可以理解为JVM线程栈(虚拟机栈，本地方法栈，程序计数器)JMM 抽象示意图 JMM的抽象示意图 (来源于&lt;Java并发编程的艺术&gt;) 举例(例子来源于&lt;Java并发编程的艺术&gt;) 线程A与线程B进行数据同步(线程A先修改某个变量值，然后线程B获取更新后的值。) JMM 解决原子性 除了JVM自身提供的对基本数据类型读写操作的原子性外，对于方法级别或者代码块级别的原子性操作，可以使用synchronized关键字或者锁保证程序执行的原子性。 JMM 解决可见性 使用sychronized 以及volatile 都可以在一个线程对某个变量修改后，其他变量可见。 JMM 解决有序性 有序性涉及到了指令重排(可以简单理解为硬件系统会将程序的指令做一次优化, 优化的时候可能会存在结果不一致的存在)。 这种使用volatile就可以解决。 volatile是禁止重排序优化。 参考大佬(膜拜) 《java并发编程的艺术》方腾飞 魏鹏 程晓明 著 全面理解Java内存模型(JMM)及volatile关键字 深入理解Volatile]]></content>
      <tags>
        <tag>java</tag>
        <tag>volatile</tag>
        <tag>JMM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊java并发编程 [java实现的基石]]]></title>
    <url>%2F2020%2F04%2F11%2Fjava%2Fjava-concurrent%2F</url>
    <content type="text"><![CDATA[通过本片文章，你可以了解到：java 是基于那些具体的实现来构建java并发体系的 前提上一篇我们聊到了并发编程遇到的核心问题(线程间的通信与同步)，以及java的解决方案(内存共享)。下面我们具体的聊下java实际实现中依赖于那些工具. 一些概念 锁 因为线程间的通信与同步，我们需要解决的是多线程访问某个资源(在一定时间内只能有部分线程可以访问操作). 我们可以简单的理解为锁，谁获取到了锁，谁就可以操作。 线程不安全 多线程情况下，对某个公共资源的多次操作会有不同的值（有别于理论上的结果），这就叫线程不安全。反之则称为线程安全。 实际实现的工具 原理层次 synchronized volatile final CAS 基于原理实现的工具类 java 并发包(JUC) java并发包(JUC) 实际操作中，我们用到最多的就是JUC了，理解整个java高并发体系的核心也是在于JUC。 先来一张图镇楼 相关模块(从底部向上) volatile 变量读写/CAS (底层实现) 这两个能够保证线程对于同一个变量进行修改 一定是对最新的变量值修改或者是读取。保证数据的正确性。实现基于共享内存模型线程间通讯 java 中volatile简单理解： 如果一个变量被volatile修饰，那么对于任意线程对于该线程的读写都可以被其他线程看到。 CAS 无锁对数据进行修改 AQS/非阻塞数据结构/原子变量类(底层接口的抽象封装) Lock/同步锁/阻塞队列/并发容器/Executor (对AQS等进行更高一层的封装) 12本质上其实都是基于volatile以及CAS的类volatile的内存读写语义，保证程序的正确顺序来进行线程间的通信与数据同步。 参考《java并发编程的艺术》方腾飞 魏鹏 程晓明 著]]></content>
      <tags>
        <tag>java</tag>
        <tag>synchronized</tag>
        <tag>AQS</tag>
        <tag>concurrent</tag>
        <tag>volatitl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊java并发编程 [核心问题以及java解决方案]]]></title>
    <url>%2F2020%2F04%2F10%2FJUC-1%2F</url>
    <content type="text"><![CDATA[通过本片文章你可以了解到： 并发编程核心问题以及java解决方案 并发线程核心问题 注意下，这里并发编程的场景是线程之间存在一定的竞争关系。如果没有竞争，其实线程并发就只是涉及到了硬件资源相关的问题。我们这次是要从软件层次上聊聊并发线程核心问题。 多线程之间存在竞争的情况下，多线程并发会有问题。 举例场景 多个线程对于某个文件进行读写操作。同一时间只能一个写，但是可以多个读。当某个线程获取到写的权限(锁)的时候，其他需要写的线程需要等待上一个线程完成之后，才可以继续操作。当某个线程可以读取到文件的时候，这个时候部分线程也是可以同时读取该文件的。 在上面的场景中，我们可以注意到两个问题： 当某个线程获取到写的权限(锁)的时候，其他需要写的线程需要等待。即表示锁被获取到时候，其他线程可以知道锁已经被获取了(状态同步)。 等待上一个线程完成之后，才可以继续操作。即当锁被释放的时候，其他线程需要知道所已经被释放了(线程之间要有通讯) 所以核心是两个问题： 线程之间的通信与同步 解决上面的问题有两种： 共享内存(java使用) 消息传递]]></content>
      <tags>
        <tag>java</tag>
        <tag>volatitle</tag>
        <tag>synchronized</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊java并发编程[JAVA-AQS]]]></title>
    <url>%2F2020%2F04%2F09%2FJAVA-AQS%2F</url>
    <content type="text"><![CDATA[通过本篇文章，你可以了解到： 1 java中的锁实际是基于AQS来进行实现的。 2 AQS内部的数据结构 3 独占式同步状态的获取与释放 4 共享式同步状态的获取与释放 一些概念 如果对于CAS,自旋锁不了解，麻烦去上一篇《java自旋锁》. 简单理解队列同步器本质上是在多线程获取锁的时候，如果获取锁失败，那么就将线程以节点的方式放进AQS内部的FIFO(双向队列)队列中，并且轮询前驱节点是否是head，如果是head则表示该节点获取到了锁。反之则表示获取到了锁。释放：当前节点释放了之后，将本节点从队列中移除。将下一节点的prev指向head. 从一个独占式锁示例代码开始下面这段代码是实现了一个独占式锁。并创建了了一个类有读和写功能 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158package concurrent.lock;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.AbstractQueuedSynchronizer;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;/** * Created by louxiu */public class Mutex implements Lock &#123; private static class Sync extends AbstractQueuedSynchronizer &#123; @Override protected boolean isHeldExclusively() &#123; return getState() == 1; &#125; public boolean tryAcquire(int acquire) &#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; public boolean tryRelease(int release) &#123; if (getState() == 0) throw new IllegalMonitorStateException(); setExclusiveOwnerThread(null); setState(0); return true; &#125; Condition newCondition() &#123; return new ConditionObject(); &#125; &#125; private final Sync sync = new Sync(); @Override public void lock() &#123; sync.acquire(1); &#125; @Override public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1); &#125; @Override public boolean tryLock() &#123; return sync.tryAcquire(1); &#125; @Override public boolean tryLock(long time, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(time)); &#125; @Override public void unlock() &#123; sync.release(1); &#125; @Override public Condition newCondition() &#123; return sync.newCondition(); &#125; public static void main(String[] args) throws InstantiationException, IllegalAccessException, InterruptedException &#123; Mutex mutex = new Mutex();// Thread x = ObjectLock.class.newInstance();// x.start(); Thread t1 = mutex.new FuncLock2(false, mutex); Thread t2 = mutex.new FuncLock2(true, mutex); Thread t3 = mutex.new FuncLock2(true, mutex); t1.start(); t2.start(); t3.start(); t1.join(); t2.join(); t3.join(); &#125; public class FuncLock2 extends Thread &#123; private Mutex mutex; private boolean boo; public FuncLock2(boolean b, Mutex mutex) &#123; this.boo = b; this.mutex = mutex; &#125; @Override public synchronized void run() &#123; if (this.boo) &#123; this.read(); &#125; else &#123; this.write(); &#125; &#125; private void read() &#123; mutex.lock(); try &#123; System.out.println(Thread.currentThread().getName() + " read lock ing..."); for (int i = 0; i &lt; 5; i++) &#123; System.out.println(mutex.sync.getQueuedThreads()); Thread.sleep(1000); &#125; &#125; catch (Exception e) &#123; &#125; finally &#123; System.out.println(Thread.currentThread().getName() + " read lock end..."); mutex.unlock(); &#125; &#125; private void write() &#123; mutex.lock(); try &#123; System.out.println(Thread.currentThread().getName() + " write lock ing.."); for (int i = 0; i &lt; 5; i++) &#123; System.out.println(mutex.sync.getQueuedThreads()); //打印当前队列中的数据 Thread.sleep(1000); &#125; &#125; catch (Exception e) &#123; &#125; finally &#123; System.out.println(Thread.currentThread().getName() + " write end ing.."); mutex.unlock(); &#125; &#125; &#125;&#125; 运行结果 1234567891011121314151617181920212223Thread-0 write lock ing..[Thread[Thread-1,5,main]][Thread[Thread-2,5,main], Thread[Thread-1,5,main]][Thread[Thread-2,5,main], Thread[Thread-1,5,main]][Thread[Thread-2,5,main], Thread[Thread-1,5,main]][Thread[Thread-2,5,main], Thread[Thread-1,5,main]]Thread-0 write end ing..Thread-1 read lock ing...[Thread[Thread-2,5,main]][Thread[Thread-2,5,main]][Thread[Thread-2,5,main]][Thread[Thread-2,5,main]][Thread[Thread-2,5,main]]Thread-1 read lock end...Thread-2 read lock ing...[][][][][]Thread-2 read lock end...Process finished with exit code 0 上面这段代码，使用自建的独占式锁，根据不同的场景进行读写操作（同时只允许读和写，上面的结果也是证明了同时启动多个线程，同时只有一个线程在运行）。 查看Mutex的具体实现其实就是依赖于Mutex中的sync(队列同步器，继承AQS)。这就引出了本篇文章要详细剖析的AQS. 什么是AQS AQS(AbstractQueueSynchronizer) 队列同步器，是构建锁或其他同步组件的基础框架，使用一个int成员变量表示同步状态，通过内置的FIFO队列来完成线程获取资源的排队工作。 主要的接口(主要作用是保证状态的改变是安全的) 整形变量 12// volatile修饰. private volatile int state; 同步队列 != 等待队列（Condition实现） getState() 获取状态 （AQS实现） 1234 protected final int getState() &#123; return state;&#125; setState(int newStatus) 设置状态 （AQS实现） 1234// 注意：虽然volatile在某一定情况下不是线程安全的(++i/i++)，但是下面的操作是线程安全的protected final void setState(int newState) &#123; state = newState; &#125; compareAndSetState(int expect, int update) CAS操作设置状态 （AQS实现） 1234 protected final boolean compareAndSetState(int expect, int update) &#123; // See below for intrinsics setup to support this return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125; AQS内部的数据结构当前线程获取同步状态失败时，同步器会将当前线程以及等待状态等信息构造成一个节点(Node),并将节点加入到队列中，同时会阻塞当前线程。当同步状态被释放时，会将首节点中的线程唤醒，使其再次尝试获取同步状态。所以同步器在实现中涉及到一个节点信息为Node的双向FIFO队列。 Node 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475static final class Node &#123; // 标记节点信息是共享同步状态节点，还是独享状态节点 static final Node SHARED = new Node(); // 标记节点信息是共享同步状态节点，还是独享状态节点 static final Node EXCLUSIVE = null; /** 等待状态： 由于同步队列中等待的线程等待超时或者被中断，需要从同步队列中取消等待，节点进入该状态将不会变化 */ static final int CANCELLED = 1; /** 等待状态：后续节点的线程处于等待状态。如果当前线程释放了同步状态或者被取消，将会通知后续节点线程运行。 所以signal 都是后继节点设置的*/ static final int SIGNAL = -1; /** 节点在等待队列中，等待某一个condition触发。当其他线程调用了condition的signal方法后，该节点将会从等待队列移动到同步队列中，加入到对同步状态的获取中 */ static final int CONDITION = -2; /** * 标识下一次共享式同步状态获取将会无条件被传播下去 * unconditionally propagate */ static final int PROPAGATE = -3; /** 等待状态，只有CANCELLED.SIGNAL.CONDITION.PROPAGATE.INITIAL（初始为0） */ volatile int waitStatus; /** * 前驱节点（检查其等待状态），入队前指定并且出队前置为null(gc). */ volatile Node prev; /** * 后继节点 默认Null */ volatile Node next; /** * 入队前的线程，并且出队后为null */ volatile Thread thread; /** * 链接到等待队列中的节点，或者是节点类型(独占或者共享)。意思就是节点类型和等待队列中的后继节点共用一个字段。 * * 因为只有独占同步状态模式的时候才有条件队列？？？ */ Node nextWaiter; /** * Returns true if node is waiting in shared mode. */ final boolean isShared() &#123; return nextWaiter == SHARED; &#125; /** 获取前驱节点 */ final Node predecessor() throws NullPointerException &#123; Node p = prev; if (p == null) throw new NullPointerException(); else return p; &#125; Node() &#123; // Used to establish initial head or SHARED marker &#125; Node(Thread thread, Node mode) &#123; // Used by addWaiter 共享模式？ this.nextWaiter = mode; this.thread = thread; &#125; Node(Thread thread, int waitStatus) &#123; // Used by Condition // 独占模式？ this.waitStatus = waitStatus; this.thread = thread; &#125; &#125; 独占式同步状态的获取与释放获取。1、多个节点等待获取状态时的队列 2、自旋的逻辑见下图 通过acquire()获取同步状态 tryAcquire先尝试获取状态，如果没有获取到状态则调用acquireQueued将当前线程放入同步队列中。其中tryAcquire是一个线程安全的获取获取同步状态的函数。Node.EXCLUSIVE表示是独占式模式12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; addWaiter是构建节点信息。1234567891011121314151617 /** * 生成节点信息，并放入同步队列 */ private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node;&#125; enq 将节点插入到队列中123456789101112131415161718/*** 将节点插入到队列中，如果没有头部，那么久就行初始化，设置一个空的Node**/private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; acquireQueued 自旋查询是否可以获取到锁123456789101112131415161718192021222324252627// 自旋查询是否可以获取到锁final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); // 如果前驱几点是head,并且可以获取锁 if (p == head &amp;&amp; tryAcquire(arg)) &#123; // 将当前节点设置为head节点 setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; // 如果获取失败，要挂起， if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; // 挂起后检查是否被中断 parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) // 获取失败了，就取消获取锁 cancelAcquire(node); &#125;&#125; shouldParkAfterFailedAcquire 检查以及修改前驱节点12345678910111213141516171819202122232425// 这里用到了private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * 如果前驱节点是signal 那么释放的时候要唤醒后继节点。已经唤醒了，所以直接返回true 即可 */ return true; if (ws &gt; 0) &#123; /* * &gt;0 就是被取消了 * 那么就轮询当前节点的前驱节点，把前驱节点取消的节点都删除掉. */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * 前驱节点不是cancell 又不是signal 那就将前驱节点设置成signal 给自己一个闹钟。标识前驱节点OK了，就唤醒本节点 */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125;释放 release()函数 由释放锁的子类实现 unparkSuccessor(h) 唤醒后续进程 简单逻辑具体见下图 release 由释放锁的子类实现12345678910public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; // 更新头部节点的状态，以及释放头部节点，并唤醒下一个节点 if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false; &#125; unparkSuccessor 唤醒后续节点 唤醒后继等待获取锁的节点 1234567891011121314151617181920212223private void unparkSuccessor(Node node) &#123; // 这里如果是1 则是cancel // 如果是小于0，但是该节点要被唤醒，所以就置为0 int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); // 唤醒下一个节点 Node s = node.next; // 如果下一个节点是null 或者是下一个节点waitStatus&gt;0(被取消) if (s == null || s.waitStatus &gt; 0) &#123; s = null; // 则从tail 找到最近的没有被取消的节点 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; // 如果下一个节点不为null,即还在等待锁 if (s != null) // 唤醒下一个节点 LockSupport.unpark(s.thread); &#125; 共享式同步状态获取与释放 共享同步状态的获取与独占式同步状态的获取稍微有点不一样。独占式释放锁之后才能触发后继节点获取锁。 共享式同步状态可以被多个线程获取所以共享式同步状态在获取和释放的时候，都会唤醒后继节点。简单理解就是当某个线程可以获取到锁的时候，对于独占式就只能该线程释放后其他线程才能获取。共享式在某个线程获取的时候，其他线程有可能也可以获取到锁。 如下图(读写锁只是举例) 独占式 当读(A)获取到锁的时候，读(B)只能等待读(A)释放后才可以 共享式 当读(A)获取到锁的时候，读(B)可以同时获取到锁 当读取到写(C) 则只能写(C) 单独占据 当读(D)获取到锁的时候，读(E)可以同时获取到锁 获取 这里需要注意的是，在轮询当前锁获取到的时候，需要通知其他等待获取锁的节点尝试获取锁 看下图 代码详解acquireShared 尝试获取共享锁123456789// 获取public final void acquireShared(int arg) &#123; // tryAcquireShared(arg) &lt;0 的时候表示没有获取到同步状态，调用doAcquireShared进行CAS获取状态。 // val = tryAcquireShared(arg) &gt;= 0 则表示获取到的同步状态 // val 大于0 表示当前线程获取共享锁成功，并且接下来其他线程尝试获取共享锁的行为可以成功(可能) // val 等于0.表示当前线程获取共享锁成功，但是接下来其他线程尝试获取共享锁会失败 if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125; doAcquireShared 自旋获取锁 如果当前节点的前驱节点是头部节点，并且tryAcquireShared(arg) &gt;= 0，则表示获取到了同步状态,设置当前节点为head,并且通知其他可以获取到锁的节点获取锁 1234567891011121314151617181920212223242526272829303132 private void doAcquireShared(int arg) &#123; // addWaiter(Node.SHARED)只是标记是共享式的 final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; // 获取前置节点 final Node p = node.predecessor(); if (p == head) &#123; // 如果前置节点是Head int r = tryAcquireShared(arg); //并且可以获取到锁 if (r &gt;= 0) &#123; // 设置当前节点为head,通知其他节点获取锁 setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; setHeadAndPropagate 通知后继节点获取锁123456789101112131415161718// 这里是setHead 以及共享式是否通知其他等待获取锁的节点获取锁private void setHeadAndPropagate(Node node, int propagate) &#123; // 下面两行与独占式是一样的 Node h = head; // Record old head for check below setHead(node); // propagate &gt; 0 代表后续的节点是可以获取 // h == null 则表示是初始节点 // h.waitStatus &lt; 0 则表示是条件，表示后续节点需要唤醒 // (h = head) == null || h.waitStatus &lt; 0 则是判断当前节点的head （注意这里因为后续的节点在成为head之后，也会release,所以这个(h=head)不一定刚开始的head） if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; // 如果符合上面的条件，当前节点的next是null(则表示当前节点的next节点也已经被释放了，或者下一个节点是共享节点) if (s == null || s.isShared()) // 这里在共享锁的释放中，来解读 doReleaseShared(); &#125;&#125; 释放releaseShared 注意这里，释放成功之后，也是要通知后继的节点获取锁1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125; doReleaseShared 通知可以获取到锁的其他节点(核心) 这里注意两个if 以及第二个if里面的compareAndSetWaitStatus(h, 0, Node.PROPAGATE)123456789101112131415161718192021222324252627282930// 通知可以获取到锁的其他节点。// 只有当（h==head）时候才会终止. 标识所有可以获取到锁的节点都已经获取到锁了private void doReleaseShared() &#123; for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; // 如果当前节点是signal, 因为已经可以获取到锁(doAcquire)或者是释放掉锁(release), 所以都可以将当前节点的status 设置成为0. 如果没有设置成功，跳过。 if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases // 如果设置成功，其实就是需要唤醒后继节点了 unparkSuccessor(h); &#125; // ws == 0 并且是至少两个节点， // ws== 0 有下面几种分析: // 1 多线程情况下，某个线程上面的compareAndSetWaitStatus(h, Node.SIGNAL, 0) 成功(注意这种情况是多个节点的head都是这个head). 这种情况不可能出现的。因为doReleaseShare的大前提是当前节点就是前置节点是可以获取到锁的。前置节点可以获取到锁，其实就是前驱节点已经是head.多个线程操作，不会同时获取到同一个head. // 2 当头结点刚创建的时候，status为0.尾结点已经追加进来，需要执行shouldParkAfterFailedAcquire将head的waitStatus设置为signal.但是还没有执行，所以会有ws==0. else if (ws == 0 &amp;&amp; // !compareAndSetWaitStatus(h, 0, Node.PROPAGATE) 当h的waitStatus不是0的时候，说明h.waitStatus被改了。说明之前的shouldParkAfterFailedAcquire已经执行了，所以需要continue. // 如果compareAndSetWaitStatus(h, 0, Node.PROPAGATE)成功了，对于上文的setHeadAndPropagate,中有```|| h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0``` h.waitStatus &lt; 0. (h = head) == null || h.waitStatus &lt; 0) !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125; &#125; 参考大佬 逐行分析AQS源码(1)——独占锁的获取 逐行分析AQS源码(2)——独占锁的释放 逐行分析AQS源码(3)——共享锁的获取与释放 PROPAGATE状态存在的意义]]></content>
      <tags>
        <tag>AQS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊高并发之盾（设计一个高并发后端）]]></title>
    <url>%2F2020%2F03%2F24%2FHCD-2%2F</url>
    <content type="text"><![CDATA[前面我们聊了如何高并发请求. 本篇从通俗的角度来梳理下一个稍微高并发的后端会涉及到哪些。 脱离业务聊高并发，都是在扯淡 下面我就是在扯淡 最基本的一个后端 后端最基本的属性请求的数据进行增删改查。 如上图所示，demo版服务基本就是基本这个样子. 上面的基本不考虑其他的业务逻辑，超过一定的qps，基本上服务端就会出现响应慢，偶尔服务端报错 公司业务上来了 大部分操作其实都是进行读操作，所以这个时候可以加缓存。毕竟单机redis轻松几万并发。改造之后的架构如下 业务更上一层楼 随着业务的扩展，对数据库的增删改也变得越来越多，单独连一个数据库，扛不住了。 怎么办？ 拆分系统—-&gt;一个系统对应一个数据库。 统一业务数据库，分库分表，减少对单一数据库的请求压力 读写分离 搞个主从 写也跟不上了 写的瓶颈实在是瓶颈了。 怎么办？ 延迟写入. 加个MQ，慢慢写。 数据统计太慢了 上es.（es 对于一些统计性的工作，支持能力很强，而且是分布式，扩容方便） 总结下 基本是从下面几个面 数据库分库分表 数据库读写分离 系统拆分(都放在一个系统内，系统之间会相互影响) 数据读取+缓存 查询，统计等可以使用es 并发实在是高，并且业务允许延迟更新，可以加MQ，延迟更新 参考大佬如何设计一个高并发系统？]]></content>
      <tags>
        <tag>高并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊高并发之矛（设计一个高并发爬虫系统）]]></title>
    <url>%2F2020%2F03%2F23%2FHCD-1%2F</url>
    <content type="text"><![CDATA[高并发是工程师老生常谈的事情。高并发简单来讲就是是服务器端，能够及时响应每秒成千上万次的请求，并且没有任何异常。博主根据自身的工作经历，在接下来的几篇文章中，从矛(爬虫)以及盾(服务端开发)两个方面来聊聊高并发。本篇是主要聊矛 先瞎聊几句 关于爬虫(网络爬虫)相关的一些概念，请读者自行google。 爬虫的主要功能：本质上还是数据采集。 本篇文章只是博主的个人见解，仅供参考。大家还是要做个盾法的公民，违法后果自负。 一些前提 工具语言使用python（python中线程对于Io基本是单线程，所以考虑进程+协程） 假设网站服务端支持QPS是无限的(1s返回结果) 数据库存储采用mysql（写入QPS 2048/s） 机器是4核8G. 最多支持开8个进程，每个进程可以支持开256个协程。即一台机器的最大并发是(8*256=2048/s)(这个已经算很高了) 需要采集10亿个网页数据 爬虫执行的任务都是去重后的(去重也是一门学问，后面细聊，本篇不作为重点) 不使用代理也不会被风控掉最原始的爬虫架构（单线程） 目前看1/s，一个小时也就采集了3600个网页，对于我们实际需要的10亿条，大概也就跑个760+年吧。看来这个可以做为老祖宗的遗产了。 疯狂的多进程+协程 这次我们直接放了大招。直接在一台机器上开了多进程+多协程。我们现在的抓取速度是(8*256=2048/s), 正好是mysql的写入qps，勉强可以。那我们需要多少135天。基本4个月. 怕是跑完之后公司就gg了。 我想飞起来 上面就是 加了3台机器( 我们现在需要大概1个多月(前提是入库的速度与抓取的速度是一致的，不存在消息堆积)，也可以再加机器，加个100台，2天就给你跑完（这只是假设的场景）)。 上面还多了三个东西。 消息中间件集群(一般kafka即可) 消费者服务 存储服务集群。 因为单个mysql的Qps就是2048. 如果并发量再多，mysql就直接炸掉，就算抓取到了数据，数据没有保存起来也是白搭。所以一般就是采用消息中间件，作为临时缓冲，然后搭建分布式存储集群(分库分表)，以保证能够及时存储。 来个小总结 看了上面的，这不就是同时请求的并发数目，加机器其实也算提高并发数。对，高并发对于矛(爬虫)来讲其实就是，疯狂的加并发。 别慌，坑多着呢。(基本就是爬虫工程师常遇到的问题，等我有时间来填) 我们上面讲的是只是理想情况下。现实很残酷的。一个能够高并发分布式的爬虫系统，大概率是会遇到下面的问题： 服务端有风控(风控又是很多种) js混淆(有时候难到你怀疑人生) token鉴权 验证码验证 同一Ip请求次数限制(换ip即可) 页面定时改版 还有其他类型的(参考大厂) url去重 脏数据清理 服务端不行(解决了其他的问题之后的瓶颈)(比如某些渣的网站，QPS就那么多，稍微高点并发，直接服务端500,或者官网直接挂掉) … 最后的总结 对于矛方的高并发，最核心的其实还是在与服务端的响应瓶颈。所以如果做好一个高并发的盾方才是难度最高的。]]></content>
      <tags>
        <tag>高并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊消息队列（六）(自己设计一个消息系统怎么玩)]]></title>
    <url>%2F2020%2F03%2F21%2FMQ-6%2F</url>
    <content type="text"><![CDATA[上面几篇都是聊消息中间件遇到的问题以及相关的解决方案。那如果需要你来设计一个消息系统该怎么设计呢。 回顾梳理 先回想下我们第一篇文章 ，消息队列主要有三个功能解耦，异步，削峰，并且有提高系统复杂性，降低系统可用性等弊端。 以及我们后面几篇提到的问题： 高可用 重复消费如何解决(幂等) 消息丢失如何解决（可靠性） 保证消息消费的顺序型 消息失效或者是延时如何解决 消息堆积如何解决 一般自己搭建消息队列都需要那些模块见招拆招 其中与消息中间件相关的有下面几个点： 高可用，可扩展。 不能说我用着用着就挂了。或者是我某个机器挂了，整个queue数据都丢了 解决方案:可以参考kafka的高可用架构。数据分partition存储，partition自有备份。多个副本之件选举出leader于follower.一旦leader挂掉，就可以有其他的follower升级为leader. 支持可伸缩 我要异步其实就是为了提高并发，提高吞吐量。加机器增加我吞吐量总得支持。 解决方案：参考kafka。如果吞吐量不够。先增加机器-&gt;topic增加partition-&gt;做数据迁移.就可以存放更多的数据，提高并发量了。 持久化 我机器有可能会挂，那么如果都放在内存里面，一旦某个机器挂掉，部分数据还是有丢失的可能性。 解决方案：就做数据持久化，按照消息的顺序写磁盘。这样下次读取数据的时候，不会因为消息地址散乱导致加载缓慢。 还有其他的问题：具体可以看下我们之前梳理的那么多问题。见招拆招即可。 参考大佬如果让你写一个消息队列，该如何进行架构设计啊？说一下你的思路。]]></content>
      <tags>
        <tag>mq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊消息队列(五)[消息顺序消费&&消息堆积]]]></title>
    <url>%2F2020%2F03%2F20%2FMQ-5%2F</url>
    <content type="text"><![CDATA[某些场景对于消息的顺序消费还是需要保证的（比如扣款查询，先验证权限，然后再扣款）。还有当消费的速度跟不上堆积的速度，就会造成消息堆积。本篇针对上面两个问题场景简单聊一下。 消息顺序消费 消息顺序消费其实是业务常见的场景。从生产者生产消息没有按照顺序生产，到消费者没有按照顺序消费，都是会对业务有影响。但是本质上还是消费者拿到消息之后能够保证消费是按照顺序来消费。如何解决 我们先从本质上来看这个问题：消息顺序消费，其实就是在前置消息没有完成，后面的消息就不能够被消费。基本上就是同步的任务执行顺序。 我们要解决上面的本质问题有下面几种方案： 把相关的消息做成一个原子消息，任意一个消费者拿到消息都是可以保证按照顺序执行的。 但是这个方案有个限制，需要将相关的消息封装成一个原子消息。有可能消息是不同的服务生产的，所以就无法在生产者将消息直接封装成一个原子消息。这种情况也是可以解决的，在消费者中间增加一个消息拼装的服务，用来专门做消息封装的工作，然后再讲相关的消息发送给消费者。 有些消息可能不能合并成一个原子消息(比如消息太多，无法合并等)，这个时候，我们可以针对这一类型消费指定一个key,每个key我们放置到一个内存queue里面，每个queue单独一个thread,来消费消息即可。 消息堆积 产生消息堆积的场景有很多，但本质还是消费跟不上生产的频率。 一般不会发生，一旦发生就是大问题！！！(都是泪) 实际生产上的一个问题：因为刚开始写消费的时候，没有考虑到并发消费的问题。所以实际消费是1个服务1个消费线程再跑。等待发现问题的时候，线上已经堆积了接近100w的消息了。如何解决解决的思路；先修复消费者的问题—&gt;堆积消息迁移-&gt;消费迁移之后的堆积消息-&gt;恢复原有架构 先修复消费者单线程消费–&gt;改成多线程。 消息迁移，先将堆积的消息消费掉，扔到其他的队列里面(不影响后续的生产环境的消息) 扩容10倍的机器，对迁移之后的数据进行消费。 等待所有消费都完成之后，再把扩容的机器，重新下掉。 参考大佬如何保证消息的顺序性？ 如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？]]></content>
      <tags>
        <tag>mq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊消息队列(四) (数据丢失怎么玩)]]></title>
    <url>%2F2020%2F03%2F19%2FMQ-4%2F</url>
    <content type="text"><![CDATA[本篇文章梳理了数据丢失的源头，以及关于如何避免的一些思考 数据丢失的源头 看上图，还是生产者，消息队列，消费者。 生产者&amp;&amp;相关的解决方案 生产者数据丢失场景其实很常见。举例：程序宕机, 网络问题等。 不同的MQ有不同的解决措施，下面从RabbitMQ&amp;&amp;Kakfa 两个常见 的消息中间件来解决。 RabbitMQ RabbitMQ有提供事务功能以及confirm模式####### 事务功能(类似mybatis的事务功能) 数据发送前开始RabbitMQ事务，如果没有成功被RabbitMQ接收到，就会报错。此时可以事务回滚，尝试重新发送数据。 但是这种是有代价的，会消耗MQ的性能，吞吐量就下来了。 这个功能是同步的####### confirm模式 生产者开启confirm模式之后，每次消息都会有一个唯一的id，如果写入的RabbitMQ，RabbitMQ会回传一个ack,标识消息ok了。如果RabbitMQ没有处理这个消息，会回调一个nack消息，标识接受失败。可以重发。生产者可以结合这个唯一id，维护发送状态，基本可以保证数据无丢失。 confirm模式是异步的。 kafka kafka 有个acks参数.（ack=0,ack=1,ack=all）.ack=1标识发送的消息写入主副本，返回ack给生产者。ack=all标识写入所有副本之后再返回ack给生产者。 一般来讲只要开启了ack=all.数据一定不会丢，kafka如果写数据出现异常，生产者会一直重试写入。 消息中间件数据丢失&amp;&amp;以及解决方案就是消息中间件自己弄丢了数据。宕机之类的 RabbitMQ 解决方案 RabbitMQ 开启持久化。持久化到磁盘里面，不管是宕机还是重启，数据都大概率不会丢失。但是如果数据在持久化之前，还没有写入磁盘，重启服务，那么还是会存在数据丢失的。 设置持久化有两个步骤(必须同时开启这两个): 创建queue的时候将其设置持久化。可以保证queue的meta信息会保存起来。 发送数据的时候将deliverMode=2。 标识将消息设置为持久化，此时消息就会被持久化写到磁盘上去。 结合生产者的confirm机制，基本就可以保证生产者发送数据到RabbitMQ，是数据没有丢失的。 Kafka 解决方案 因为kafka的读写都是在leader节点。如果leader节点挂掉了，但是其他follower部分数据还没有同步，然后重新选择leader，那么部分数据就丢了。 所以kafka要配置下面几个参数 topic 设置replication.factor：这个值必须要大于1，标识每个partition必须至少有2个副本。 kafka服务端设置min.insync,repicas：这个值必须要大于1。标识leader至少与一个follower还要在保持联系。才能确保leader挂了，还有一个follower. 在生产者设置acks=all:标识消息在写入所有的副本之后，才认为是写成功的。 在生产者端设置retries=MAX：标识一旦写入失败，就无限重试。线程或者是进程就阻塞住了。 消费者数据丢失&amp;&amp;以及解决方案 常见的就是消费者拿到数据之后，直接挂掉了，消息中间件接受到了已经消费的通知，那么数据就丢失了，RabbitMQ RabbitMQ 是有自动Ack的。 如果是消费者消费的时候，先自动ack，然后再消费。自动ack之后就直接挂了。但是RabbitMQ认为消费者已经完成了，实际上消费者还没有消费。这样数据就丢失了。 所以需要先关闭RabbitMQ的自动ack，然后消费完成之后，手动ack就好。那这个时候问题来了，如果消费中间出问题了，不就重复消费了么。如果数据丢失了大概率是找不回来的，重复消费不可怕，只需要保持消费幂等即可。 kafka kafka跟RabbitMQ很像。kafka有offset。关闭自动offset，然后手动offse。然后再处理幂等即可。 消息丢失以及处理方案 参考大佬如何保证消息的可靠性传输？（如何处理消息丢失的问题）]]></content>
      <tags>
        <tag>mq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊消息队列(三) (重复消费如何解决(幂等))]]></title>
    <url>%2F2020%2F03%2F18%2FMQ-3%2F</url>
    <content type="text"><![CDATA[这个问题一定是要结合实际的业务来判断，本篇只是梳理了下一般的排查思路以及相应的解决方案。 什么场景才会引起重复消费 看上图，一般使用消息队列的场景就是，生成者生产数据到消息队列。消息队列存储数据。消费者从消息队列中获取数据消费。下面我们分别从三个场景来分析那种情况会有重复消费。 生产者重复发送数据 在消费和消息队列存储都没有问题的情况下，如果生产者生产的重复的数据，这个样子就会有重复的消息消费 这种情况下，大部分都是由于业务代码逻辑问题。需要梳理下业务代码中是否会存在数据重新发送的情况。如果不能判断这种情况，也没有问题，在消费者消费的时候解决即可（即消费幂等） 消息队列重复存储 一般不会出现这种，例如RabbitMQ，kafka，一般都是会保证数据存储的唯一性的。 消费者重复消费 这种其实也是业务代码负重要责任。所有的MQ基本都会复现这种情况。 Kafka举例:kafka有offset的概念。每个数据写进去kafka，都会有一个offset。消费者每消费一个消息后，就将自己的offset提交下，表示这个消息我消费过了，下次从这个offset之后的数据开始给我数据。由于我们消费的时候，有可能是代码进程直接挂掉，导致消费了，但是offset没有提交成功，下次获取数据的时候就重新获取到了实际已经消费国的数据了。 RabbitMQ也有类似kakfa offset的机制，是ack机制。 重复消费其实 不可怕，只需要我保持每次消费一样的消息，我的结果都是一样的即可。 举例：我们需要将每次消费的信息都保存到数据库中。如果同样的消息我们消费最终数据库只有一条，那么其实对我们实际业务是没有任何影响的。这就是所谓的幂等 关于幂等，业务角度的一点思考 如果消费是更新数据库，那么可以先查询是否存在，如果存在就不插入，如果不存在就插入 如果是做缓存，就保持唯一的key, 一直更新缓存就好。只要消息内容一样，无论什么时候缓存结果都是一样。 如果是其他场景，可以考虑对每个消息都有一个唯一标识，消费了就保存起来。下次再接收到类型的先查询是否消费过唯一标识，那么就可以避免重复消费。 还可以考虑如果是一样的数据，对数据进行合并操作（具体业务具体分析） 参考大佬如何保证消息不被重复消费？（如何保证消息消费的幂等性）]]></content>
      <tags>
        <tag>mq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊消息队列(二) (如何保证消息队列高可用)]]></title>
    <url>%2F2020%2F03%2F18%2FMQ-2%2F</url>
    <content type="text"><![CDATA[通过本篇，你可以了解到RabbitMQ以及Kafka是如何保证消息队列高可用的 如何保证消息队列高可用 在上一篇 我们聊到使用消息队列，会降低系统可用性(简单来讲，MQ挂掉了怎么办) 不同的MQ对于高可用有不同的措施，面试问，也是回答自己用到哪些MQ，分别介绍相应的高可用措施是什么。 RabbitMQ RabbitMQ 是基于主从（非分布式）做高可用的 RabbitMQ分为三种模式。 单机模式(无高可用性) 基本就是自己玩玩 普通集群模式(无高可用性) 普通集群模式就是启动多个RabbitMQ实例，这个MQ之间互相同步meta信息(可以理解为queue的一些配置信息,通过meta信息，可以找到queue所在的实例)。消费的时候，如果queue所在的实例与连接的实例不是一个，连接的实例将会从实际queue所在实例，拉取数据。 很明显的这种方式有几个弊端 随机选择一个实例，会有拉取数据的开销 如果固定选择一个实例，会有单例性能瓶颈 如果存放数据的实例宕机了，会导致其他无法获取到数据。当然也可以开启消息持久化，理论上数据不会丢，但是其他实例还是要等恢复了之后才可以拿到数据. 所以这个普通模式其实提高吞吐量，多个节点集中读取某个queue的数据. 镜像集群模式(高可用性) 镜像集群模式，简单说，就是queue的数据不是像普通集群模式，实际上只有一个queue保存数据。而且部分实例上有queue的备份。这样即使某个实例宕机掉了，服务也还是正常的。 弊端 每个queue都会备份到部分实例，如果实例很大，那么磁盘，性能（备份数据，带宽和内存都负载很重）。 这种不是分布式的，不存在扩展。例如某个queue的数据很多，新增机器其实也是需要备份所有的数据，根本解决不了负载的问题。 Kafka kafka是基于副本机制来做高可用的 kafka基本架构 由多个broker组成(节点) topic是由多个partition组成的 每个partition可以放在不同的broker上，每个partition只存储部分数据 每个partition 在其他节点上会有自己的副本。相同partition会选举出一个leader节点，所有的数据都会通过leader读写 所以kafka的高可用机制是: 不同的partition有不同的备份，如果某一台机器宕机了，没关系，还有备份，如果这个机器上的partition是leader，那么剩余的partition重新选举出新leader，由新leader进行数据更新. kafka与RabbitMQ还有一点就是，kafka的数据是真正的分布式，即部分数据在其他节点上。RabbitMQ镜像模式其实还是所有数据都是在一个节点上，其他节点都是所有数据的备份。 kafka详细剖析，待有时间补坑 参考大佬如何保证消息队列的高可用？]]></content>
      <tags>
        <tag>mq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊消息队列(一)]]></title>
    <url>%2F2020%2F03%2F15%2FMQ-1%2F</url>
    <content type="text"><![CDATA[通过本文你可以了解到： 0 为什么要使用消息队列（MQ） 1 消息队列 优缺点 2 消息队列 市场上现有MQ分析 为什么要使用消息队列 用消息队列的场景有很多，但是核心点有三个：解耦，削峰，异步 解耦 考虑下一个场景，有三个系统，A系统完成之后，需要同步结果给B，C系统。后续系统变动，又需要多通知一个D。那么A系统就需要在原来的代码上更改下。再考虑后面C不需要了，A还要去掉。A系统负责人怕是头发全掉了。 上面的场景其实就是A系统与其他系统太过耦合了 这个时候MQ可以很好的解决这种场景了。A系统完成之后，向MQ发送一个消息，后续那个系统需要，那个系统就去MQ取消息。这样A系统只需要关系自己有没有发送MQ消息，其他系统只需要关系MQ有没有消息。这样就很好的解耦了。 异步 用户点击某个操作A时，服务器端需要做一些列(BCD)操作。其执行顺序就是A(1s)-&gt;B(2s)-&gt;C(3s)-&gt;D(4s).链路长，耗时就很长。用户点击了某个操作，需要等待10s，用户怕是直接走了。 上面的场景其实就是常见的异步场景。 MQ这个时候也可以用上。A操作后，发送3个消息出来。BCD通过监听MQ拿到消息，计算。其执行顺就是A-&gt;MQ-(BCD). 用时其实就是:A(1s)+MQ(0.5s)+BCD(用时最长的那个4s)=5.5s 比原来的用时，提高了接近一半。 削峰 考虑一个场景：线上生产会收集用户点击的日志，而这些日志全部都是由mysql存储的。一般mysql可以2k/s, 如果是5k,基本上就是要被打挂了。 上面的场景其实就是峰值过高，导致其他系统处理不过来，直接崩。 解决上面的方法有很多，mysql分表分库,考虑其他数据库。用MQ也可以解决。日志都先扔到MQ中，起一个服务专门消费日志MQ消息(消费频率是2k/s)。就算是后面每秒发送5k，消费频率也不会边，自然而然mysql就不会挂了。 MQ的优缺点 优点上面就已经描述了。下面聊聊缺点 缺点 降低系统可用性 原来只有4个系统，现在又多了一个MQ，而且又是核心中间件，万一MQ挂了怎么办！！ 增加系统复杂度 消息有没有重复消费，消息丢失 结果一致性 一部分消费MQ成功，一部分消费失败，数据就不一致了。就需要解决这个一致性 上面前两个点，其实就是分别对应MQ的高可用性，ack机制 市面上常用的MQ比较 特性 ActiveMQ RabbitMQ RocketMQ Kafka 单机吞吐量 万级，比 RocketMQ、Kafka 低一个数量级 同 ActiveMQ 10 万级，支撑高吞吐 10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景 topic 数量对吞吐量的影响 topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源 时效性 ms 级 微秒级，这是 RabbitMQ 的一大特点，延迟最低 ms 级 延迟在 ms 级以内 可用性 高，基于主从架构实现高可用 同 ActiveMQ 非常高，分布式架构 非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 消息可靠性 有较低的概率丢失数据 基本不丢 经过参数优化配置，可以做到 0 丢失 同 RocketMQ 功能支持 MQ 领域的功能极其完备 基于 erlang 开发，并发能力很强，性能极好，延时很低 MQ 功能较为完善，还是分布式的，扩展性好 功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用 参考大佬为什么使用消息队列？消息队列有什么优点和缺点？Kafka、ActiveMQ、RabbitMQ、RocketMQ 都有什么优点和缺点？]]></content>
      <tags>
        <tag>mq</tag>
        <tag>rabbitmq</tag>
        <tag>kafka</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java自旋锁]]></title>
    <url>%2F2020%2F01%2F16%2Fjava%2FJAVA-SPIN%2F</url>
    <content type="text"><![CDATA[通过本篇文章，你可以了解到 1 什么是CAS 2 什么是自旋锁 3 公平自旋锁 4 MCS自旋锁 5 CLH 自旋锁 什么是CAS假设一种场景，你想修改某个共享变量的值，比如对该变量进行加1的操作，因为其他线程有可能已经更改了这个变量的值。如果直接进行+1,就有可能导致线程不安全。这个时候就可以使用CAS。 CAS compareAndSet/compareAndSwap 比较并且替换。一般使用compareAndSet(address,expect, update).对于某一内存地址address上的值，比较是否等于expect，如果等于就更新为update的值。 大部分的主流cpu都有支持相应的原子操作命令。 通过CAS的特性，对数据进行修改就不会出现线程安全问题了(只是大概来讲，具体的线程安全还是要结合代码来讲)。 其中J.U.C包中的原子类，都是支持CAS操作的。什么是自旋锁这里假设一个简单的锁场景。两个线程A，B.都在竞争一个资源C.资源C有且仅能被一个线程同时使用。那么这个时候如果A获取到C的时候(即A已经获取到了锁)，B在此时是无法获取到C的，但是这个时候有两种解决方案， 一种就是线程挂起，放弃CPU时间片，等待被唤醒。 另外一种就是不放弃时间片，轮询获取C. 第二种轮询获取资源C的方式就称为自旋锁. 从这里就可以看出来，自旋锁最适用于时间较短的场景，如果是时间比较长，就白白的浪费了系统资源. demo 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758 public class SpinLock &#123; private AtomicReference&lt;Thread&gt; owner = new AtomicReference&lt;&gt;(); private void lock() &#123; Thread curThread = Thread.currentThread(); // 如果owner不为null，则表示此时锁被其他线程拥有，自旋获取锁 while (!owner.compareAndSet(null, curThread)) ; &#125; private void unlock() &#123; owner.compareAndSet(Thread.currentThread(), null); &#125; public static void main(String[] args) &#123; SpinLock spinLock = new SpinLock(); Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; spinLock.lock(); System.out.println("dsadsa"); Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; &#125; finally &#123; spinLock.unlock(); &#125; &#125; &#125;); Thread t2 = new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; spinLock.lock(); System.out.println("94382843902834902"); Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; &#125; finally &#123; spinLock.unlock(); &#125; &#125; &#125;); t1.start(); t2.start(); &#125;&#125;公平点的自旋锁从上面的自旋锁中，我们不难看到一点，上面获取锁的方式其实是不公平的。大家都在竞争，谁运气好，谁就可以获取到锁。如果做到公平呢：其实就是给每一个获取锁的线程发个排号，锁就按照顺序依次给到相应的线程 **demo** 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364 public class ReenLock &#123; // 表示当前锁给到的序号 private AtomicInteger serviceNum = new AtomicInteger(); // 发号员 private AtomicInteger ticketNum = new AtomicInteger(); private int lock()&#123; int myticket = ticketNum.getAndIncrement(); // 先给个号 while (serviceNum.get()!=myticket)&#123;&#125; // 如果目前的叫号不是自己，就等着 return myticket; &#125; private void unlock(int myticket)&#123; int next = myticket + 1; serviceNum.compareAndSet(myticket, next);//叫下一个号 &#125; public static void main(String[] args) &#123; ReenLock reenLock = new ReenLock(); Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; int lock = reenLock.lock(); try &#123; System.out.println(lock); Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; &#125; finally &#123; reenLock.unlock(lock); &#125; &#125; &#125;); Thread t2 = new Thread(new Runnable() &#123; @Override public void run() &#123; int lock = reenLock.lock(); try &#123; System.out.println(lock); Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; &#125; finally &#123; reenLock.unlock(lock); &#125; &#125; &#125;); t1.start(); t2.start(); &#125;&#125;MCS自旋锁MCS其实是发明人的名字John Mellor-Crummey和Michael Scott 原理是基于链表，对每一个获取锁的线程都创建一个node, 获取锁的时候，查看当前链表的是否存在前驱节点，如果不存在，就表示已经获取到锁。如果存在，就表示需要等待，这个时候将前置节点的next指向自己，然后轮询自己的变量。 释放锁的时候，判断是否有下一个节点，如果不存在下一个节点，就将当前队列置为Null.如果存在下一个节点，将下一个节点的状态变量置为false(表示不需要等待了)。 **demo** 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990 public class MCSLock &#123;public static class MCSNode &#123; volatile MCSNode next; volatile boolean isWaiting = true;&#125;volatile MCSNode queue;private static final AtomicReferenceFieldUpdater&lt;MCSLock, MCSNode&gt; update = AtomicReferenceFieldUpdater.newUpdater(MCSLock.class, MCSNode.class, &quot;queue&quot;);public void lock(MCSNode curThread) &#123; MCSNode predecessor = update.getAndSet(this, curThread); //setp 1 if (predecessor != null) &#123; predecessor.next = curThread; //step 2 while (curThread.isWaiting) &#123; // step 3 System.out.println(Thread.currentThread().getName() + &quot;waiting...&quot;); &#125; &#125; else &#123; // 只有一个线程在使用锁，没有前驱通知他，就直接标记自己已经获取到锁了 curThread.isWaiting = false; &#125;&#125;public void unlock(MCSNode curThread) &#123; if (curThread.isWaiting) &#123; // 拥有者释放，才有意义 return; &#125; if (curThread.next == null) &#123; // 检查是否有人排在后面 //cas返回true 标识真的是没有排在后面 if (update.compareAndSet(this, curThread, null)) &#123; return; &#125; else &#123; //就表示突然有人在后面。需要等待后面的节点 // 场景是 step运行了，但是step2还没有执行完 while (curThread.next == null) &#123; &#125; &#125; &#125; curThread.next.isWaiting = false; curThread.next = null;&#125;public static void main(String[] args) &#123; MCSLock lock = new MCSLock(); Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; final MCSNode mcsNode = new MCSNode(); lock.lock(mcsNode); try &#123; System.out.println(&quot;111&quot;); Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; &#125; finally &#123; lock.unlock(mcsNode); &#125; &#125; &#125;); Thread t2 = new Thread(new Runnable() &#123; @Override public void run() &#123; final MCSNode mcsNode = new MCSNode(); lock.lock(mcsNode); try &#123; System.out.println(&quot;2222&quot;); Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; &#125; finally &#123; lock.unlock(mcsNode); &#125; &#125; &#125;); t1.start(); t2.start();&#125;&#125;CLH自旋锁入股知道AQS，肯定知道CLH自旋锁。CLH自旋锁，原理跟MCS自旋锁差不多。CLH是检测前驱节点的运行状态，MCS是检测自身节点状态信息.获取时：如果有前驱节点，那么就等待前驱节点释放。如果没有就表示获取到了锁。释放：直接释放当前节点状态。 相比较之下，CLH理解起来比较简单，实现起来也比较简单. **demo** 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677 public class CLHLock &#123; private final static AtomicInteger in = new AtomicInteger(); public static class CLHNode &#123; private volatile boolean isWaiting = true; private final int a = in.getAndIncrement(); &#125; private volatile CLHNode tail; private static final AtomicReferenceFieldUpdater&lt;CLHLock, CLHNode&gt; update = AtomicReferenceFieldUpdater.newUpdater(CLHLock.class, CLHNode.class, &quot;tail&quot;); public void lock(CLHNode curNode) &#123; CLHNode preNode = update.getAndSet(this, curNode); if (preNode != null) &#123; while (preNode.isWaiting) &#123; &#125; &#125; &#125; public void unlock(CLHNode curNode) &#123; if (!update.compareAndSet(this, curNode, null)) &#123; curNode.isWaiting = false; &#125; &#125; public static void main(String[] args) &#123; CLHLock lock = new CLHLock(); Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; final CLHLock.CLHNode mcsNode = new CLHLock.CLHNode(); lock.lock(mcsNode); try &#123; System.out.println(&quot;111&quot;); Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; &#125; finally &#123; System.out.println(&quot;release&quot;); lock.unlock(mcsNode); &#125; &#125; &#125;); Thread t2 = new Thread(new Runnable() &#123; @Override public void run() &#123; final CLHLock.CLHNode mcsNode = new CLHLock.CLHNode(); lock.lock(mcsNode); try &#123; System.out.println(&quot;2222&quot;); Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; &#125; finally &#123; lock.unlock(mcsNode); &#125; &#125; &#125;); t1.start(); t2.start(); &#125;&#125;参考线程安全实现与CLH队列]]></content>
      <tags>
        <tag>java</tag>
        <tag>自旋锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA中的锁]]></title>
    <url>%2F2019%2F12%2F23%2Fjava%2FJAVA%E4%B8%AD%E7%9A%84%E9%94%81%2F</url>
    <content type="text"><![CDATA[java中的各种锁 本文参考了美团技术团队整理的锁内容 [参考]: https://tech.meituan.com/2018/11/15/java-lock.html “比较详细”]]></content>
      <tags>
        <tag>java, 锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql高性能优化]]></title>
    <url>%2F2019%2F12%2F16%2Fmysql%2Fmysql%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[mysql高性能优化的一些策略 mysql高性能优化 参考地址 what 什么是mysql性能优化 why 为什么要了解mysql性能优化 how 怎么做性能优化 what mysql性能优化是对mysqlcrud操作的优化。 why 对于并发量大，要求性能高的服务，性能优化是不得不做的。 how 查询流程图 优化哲学优化有风险，涉足需谨慎 优化可能带来的问题 优化本身就有风险，只不过是没有意识到 优化有时候不总是对一个单纯的环境进行修改，还可能是对一个复杂的生产环境 任何技术都可以解决一个问题，单必然存在带来另外一个问题的风险 保持现状或者是更差都是失败的优化 优化的需求 稳定性和业务可持续性，通常比性能更重要 优化就存在变更，变更就可能带来风险 优化要由业务驱使 优化思路 安全和性能 安全—&gt;数据可持续性 性能—&gt;数据的高性能访问 优化的维度 硬件《 系统 《 数据库《sql以及索引 基本优化思路 硬件-&gt;系统-&gt;应用-&gt;数据库-&gt;架构(高可用，读写分离，分库分表)]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql 字段定义后面的(20)]]></title>
    <url>%2F2019%2F12%2F15%2Fmysql%2Fmysql%20bigint(20)%2F</url>
    <content type="text"><![CDATA[字段定义后面的(20) 其实是宽度，并不是长度 bigint(20) 后面的20是宽度，不是长度 binint -&gt; varchar(20+) 是不影响数据的。]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 基础学习之JVM学习]]></title>
    <url>%2F2019%2F12%2F14%2Fjava%2Fjava%E8%99%9A%E6%8B%9F%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[JVM学习 JVM学习 [参考]: https://blog.csdn.net/xiangzhihong8/article/details/80412795 “比较详细” [参考2]: https://blog.csdn.net/u011546655/article/details/52175550 概念 又称为JVM. 通过在实际的计算机上仿真模拟各种计算机功能的虚拟计算机。 主要由字节码指令集，寄存器，栈，垃圾回收堆和存储方法域构成。 java 程序 与操作系统之间的翻译官 Java 程序编译后 生成.class文件. JVM针对不同的都有不同的解释器，所以只要针对系统中有相关的jvm，那么对应的编译后的程序就可以运行起来. — 一份代码多次运行. JVM 生命周期 JVM 随Java程序开始而开始，结束而停止。一个Java程序会开启一个JVM进程，一台计算机上可以运行多个程序===&gt; 多个JVM进程 JVM将线程分为：守护线程和普通线程两种。 守护线程： JVM自己使用的线程，比如GC(垃圾回收) 普通线程一般是Java程序的线程，只要JVM有普通线程在执行，JVM就不会停止. JVM 内存模型 堆和方法区是所有线程共有的，虚拟机栈和本地方法栈和程序计数器都是线程私有的。 堆内存（线程共享） 分为年轻代和老年代. 还有一个永久代在1.8之前存在，1.8(含)之后永久代被移除。 堆内存是内存优化中的一个重要内容。 方法区（线程共享） 存储已经被虚拟机加载的类信息,常量，静态变量，即时编译(JIT)后的代码等数据。 因为线程共享，所以方法区的信息，必须要保证线程安全。如果有两个线程同时加载一个类，只能一次加载一个。 运行时，方法区内存可变更（扩展以及回收）。方法区里面的对象也可以被回收，但必须是该类没有任何引用的情况，才可以被回收。 程序计数器 职责: 字节码解释器依赖程序计数器来选取下一条要执行的指令。分支，循环，跳转，异常处理，线程恢复等基础功能都需要依赖这个计数器来完成。 JVM多线程依赖线程轮流切换并分配处理器执行时间的方式来实现的,为了每个线程切换后都能够找到正确的下一条指令，所以每个线程都有一个独立的程序计数器 Java虚拟机栈 即通常所说的堆栈里面的栈，用于Java方法运行时候的内存模型。 Java虚拟栈运行过程：每个方法执行的时候都会创建一个栈帧(stack Frame)用于存储变量表(强类型，所以内存大小不会更改),操作，动态链接，方法出口等信息。每个方法从调用到出栈 的过程，就对用栈帧在虚拟机中从入栈到出栈的过程。 本地方法栈 Native Method java调用非java代码的接口。(本质上还是) 主要用于存储本地方法的局部变量表，本地方法的操作数栈等信息，超过作用域时，被自动释放掉 主要用于JVM调用本地方法接口(Native)。 类加载过程 Load 一，通过类的全限定名(java.package.class) 获取定义好的二进制字节流(这个应该是编译好的.class文件) 二，将字节流代表的静态存储结构转化为方法区的运行时的数据结构 三，在Java堆生成一个代表该类的java.lang.class对象,作为对方法区中这些数据的访问入口 注意： Load阶段是获取类的二进制类字节流的最佳阶段，开发既可以使用System类加载器，又可以使用自己的类加载器 Link 将Java中的二进制代码合并到JVM运行状态之中的过程 一， 验证： 确保被加载类正确 文件格式验证 验证字节流中是否符合class文件的规范。例如是否以OxCAFEBABE开头，主次版本号是否在当前虚拟机的处理范围之内，常量池中常量是否有不被包含支持的类型 元数据验证：对字节码描述的信息进行语义分析。保证其描述的信息与Java语言规范符合. 字节码验证：通过数据流和控制流分析，确定程序语义是合法的，符合逻辑的。 符号引用验证:确保解析动作能正确执行。 注意：验证很重要，但不是必须，对程序运行期没影响。由-Xverifynone参数。 二，准备：为类的静态变量分配内存，并将其初始化为初始值 这个时候分配内存仅是类变量(static),不是实例变量，实例变量会再对象实例化随对象一块分配在Java堆中. 这里的初始值为数据类型的零值(0, 0L, false, null等) 三，解析： 将类中相关符号引用转换为直接引用 Initialize 为类的静态变量设置正确的初始值 class加载器 Bootstap classLoader 负责加载$JAVA_HOME中 jre/lib/rt.jar 里所有的class或Xbootclassoath选项指定的jar包。由C++实现，不是ClassLoader子类。 Extension ClassLoader 负责加载java平台中扩展功能的一些jar包，包括$JAVA_HOME中jre/lib/*.jar 或 -Djava.ext.dirs指定目录下的jar包。 App classLoader 负责加载classpath中指定的jar包及 Djava.class.path 所指定目录下的类和jar包 Customer classLoader 通过java.lang.ClassLoader的子类自定义加载class，属于应用程序根据自身需要自定义的ClassLoader，如tomcat、jboss都会根据j2ee规范自行实现ClassLoader。]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 基础学习之final finally finalize 区别]]></title>
    <url>%2F2019%2F12%2F14%2Fjava%2Ffinal%20finally%20finalize%20%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[final finally finalize 区别 final finally finalize 区别 final (可以修饰 类 方法 变量) 修饰类 表示不允许继承 final类中所有的成员方法都会隐式的定义为final方法。 修饰方法 表示子类不能重写此方法 提高效率 锁定方法 修饰变量 final成员变量表示常量，只能被赋值一次，赋值后其值不再改变 finally(跟try…except连用) 不关有没有异常都会执行。 注意： 只有当执行的时候，并且没有发生 线程被kill,断电，退出虚拟机等情况(这些情况不会执行finally)，finally才会执行. 特殊 123456789101112131415161718private int testFinallyString(String str) &#123; try &#123; return str.charAt(0) - &apos;0&apos;; &#125; catch (NullPointerException e) &#123; return 1; &#125; catch (StringIndexOutOfBoundsException e) &#123; return 2; &#125; finally &#123; return 6; &#125;&#125;// 调用函数System.out.println(testFinallyString(null) + &quot; &quot; + testFinallyString(&quot;0&quot;) + &quot; &quot; + testFinallyString(&quot;&quot;));// 结果将会输出 6 6 6// 原因是因为 finally 特殊，会撤销之前的return. finalize(在java.lang.Object里定义的) 这个方法在gc启动，该对象被回收的时候被调用 跟析构函数不一样. 注意： 这个跟c++ 中的析构函数是不一样的。 c++ 调用delete 时候，对象就会被删除掉。 java 里面的调用gc，也不一定会及时删除。而是根据下一个删除动作才会删除]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 基础学习之int 与 Integer 区别]]></title>
    <url>%2F2019%2F12%2F13%2Fjava%2Fint%20%E4%B8%8EInteger%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[int 与 Integer 区别 int 与 Integer 区别 基本概念 java里面有基础类型和引用数据类型 (1）基本数据类型，分为boolean、byte、int、char、long、short、double、float； (2）引用数据类型 ，分为数组、类、接口。 为什么只提到了 int和Integer 因为Integer内部装箱做了一个额外的处理(用了缓存). 基本对比 Integer 是 int 的包装类，int 是基本数据类型. Integer 必须实例化才可以使用，int 可以直接赋值 Integer 实际是个类，所以是对象的引用，int是数据的存储 Integer 默认值为null, int 默认值为0. 并且int声明为0; 深入对比 Integer实际是对象，所以两个new的对象 是不等的(因为是new 内存地址不一样)。 123456789101112131415161718192021222324252627282930Integer i = new Integer(100);Integer j = new Integer(100);System.out.println(i == j); //false// ①注意：如果是-128到127直接的变量赋值，则 nteger b = 5; // 与 int b = 5; 一样Integer a = 5;Integer b = 5; // 与 int b = 5; 一样int c = 5;System.out.println(a == c); // trueSystem.out.println(a == b); // trueSystem.out.println(a.equals(b)); // true// ②如果是超过这个范围 那么结果就不一样了Integer a = 599999999;Integer b = 599999999;int c = 599999999;System.out.println(a == c); // trueSystem.out.println(a == b); // false 这个是false.System.out.println(a.equals(b)); // true// 出现①和②是因为 java在编译Integer a = 5 ;时，会翻译成为Integer a = Integer.valueOf(5)。而java API中对Integer类型的valueOf的定义如下，对于-128到127之间的数，会进行缓存，Integer a = 5 b = 5时，就会直接从缓存中取，就不会new了。见源码 public static Integer valueOf(int i) &#123; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); &#125;]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 基础学习之反射的用途及实现&&简单的注解]]></title>
    <url>%2F2019%2F12%2F13%2Fjava%2F%E5%8F%8D%E5%B0%84%E7%9A%84%E7%94%A8%E9%80%94%E4%BB%A5%E5%8F%8A%E5%AE%9E%E7%8E%B0%26%26%E7%AE%80%E5%8D%95%E7%9A%84%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[反射的用途及实现&amp;&amp;简单的注解 反射的用途及实现&amp;&amp;简单的注解 反射基本概念 反射(reflection)是java的特征之一,允许java程序在运行中能够操作类或者对象内部相关属性(所属类，对象，变量以及方法)。 是运行时不是编译时 主要用途 google出来的都是开发通用框架 但是用的最多的应该利用注解以及反射实现一些通用的工具 反射中invoke过程 注解基本概念 放张网络图 [来源]: https://www.jianshu.com/p/83cff6b6971e {% asset_image 5618238-2e8f1e36d062f4d2.png %} 。 实现 下面是将同名对象copy, 并且根据不同的注解进行不同的处理 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879/*** 注解类**/@Target(value = &#123;ElementType.FIELD&#125;)@Retention(RetentionPolicy.RUNTIME)public @interface FieldsValidAnnotation &#123; // 将double * 100之后转换为Long boolean doubleMul100ToLong() default false; // 将double 转换为String boolean doubleToString() default false;&#125;/** * 转换两个变量name一样，但是不同类型的数据。 * * @param source 源变量 * @param target 目标变量 */public static void copyProties(final Object source, final Object target) &#123; if (source == null) &#123; return; &#125; Field[] fields = target.getClass().getDeclaredFields(); Method[] targetMethodList = target.getClass().getMethods(); for (Method targetMethod : targetMethodList) &#123; try &#123; // 不是set Func 就不 if (!targetMethod.getName().startsWith("set")) &#123; continue; &#125; String fieldName = targetMethod.getName().replaceFirst("set", ""); Field field = target.getClass().getDeclaredField(StringUtils.uncapitalize(fieldName)); field.setAccessible(true); Method sourceGetMethod = source.getClass() .getMethod("get" + fieldName, new Class[]&#123;&#125;); Object object = sourceGetMethod.invoke(source, new Object[]&#123;&#125;); object = realConvert(field, object); targetMethod.invoke(target, object); &#125; catch (Exception e) &#123; continue; &#125; &#125;&#125; /** * 注解. **/ private static Object realConvert(Field field, Object object) &#123; Annotation[] annotations = field.getAnnotations(); for (Annotation annotation : annotations) &#123; if (annotation.annotationType().getName().equals(FieldsValidAnnotation.class.getName())) &#123; if (((FieldsValidAnnotation) annotation).doubleMul100ToLong()) &#123; object = formatDigit(String.valueOf(object)); &#125; if (((FieldsValidAnnotation) annotation).doubleToString()) &#123; object = new BigDecimal(String.format("%.16f", object)).stripTrailingZeros().toString(); &#125; &#125; &#125; return object; &#125;]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 基础学习之抽象类与接口对比]]></title>
    <url>%2F2019%2F12%2F11%2Fjava%2F%E6%8A%BD%E8%B1%A1%E7%B1%BB%E4%B8%8E%E6%8E%A5%E5%8F%A3%E5%AF%B9%E6%AF%94%2F</url>
    <content type="text"><![CDATA[抽象类与接口对比 抽象类与接口对比 参数 抽象类 接口 默认的方法实现 可以有自己的 抽象函数，不存在实现 实现 extends implements 构造器 可以有 不能有 与正常java类 除了不可实例化，其他一样 完全不同 权限 private public protected 只能为public 多继承 子类一次只能继承一个抽象类 可以继承多个接口 速度 比接口快 接口要花时间找在类中实现的方法 添加新方法 不影响子类 子类必须要实现 如果是基本功能一直在改，直接用抽象类 如果是接口不变，或者多继承，使用抽象。]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面向对象的特征与特性]]></title>
    <url>%2F2019%2F12%2F11%2Fjava%2F%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%9A%84%E7%89%B9%E5%BE%81%E4%B8%8E%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[面向对象的特征与特性 面向对象的特征与特性 特征（一般是表面） 封装 抽象 继承 多态 特性（一般是本质） 封装 继承 多态]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 基础学习之重载和重写的区别]]></title>
    <url>%2F2019%2F12%2F11%2Fjava%2F%E9%87%8D%E8%BD%BD%E5%92%8C%E9%87%8D%E5%86%99%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[重载和重写的区别 重载和重写的区别 重载(OverLoad)和重写(OverRiding) 本质上都是多态特性的实现. 重载是类统一调用方式。多个同名函数同时存在，但是有不同类型的入参(必须)和出参. 123456789101112131415@Testpublic void testOverLoad()&#123; System.out.println(testOL1()); // 1 System.out.println(testOL1(3));// 1.1 &#125; private Integer testOL1()&#123; return 1;&#125; private Double testOL1(Integer a)&#123; return 1.1;&#125; 重写(父子类之间的多态性) 对父类函数中的函数进行重新定义。 重写函数的入参（必须）和出参(必须)与父类函数一样. 子类重写函数权限不能少于父类的。]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微服务之前后端分离]]></title>
    <url>%2F2019%2F12%2F10%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%2F%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E6%98%AF%E4%BB%80%E4%B9%88%2F</url>
    <content type="text"><![CDATA[什么是前后端分离，主要主要职责是什么 前后端分离 [参考地址]: http://blog.720ui.com/2016/arch_web_server/ 主要是为了分工明确，职责清晰，实现产品更快速 前端职责: 页面UI,展示，交互等 后端职责：数据储存，业务逻辑，restful接口，性能，可用性，伸缩性，扩展性，安全性等]]></content>
      <tags>
        <tag>java</tag>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发编程]]></title>
    <url>%2F2019%2F12%2F09%2F%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[通过本片文章，你可以了解到：1 什么是并发编程2 并发编程有哪些挑战3 相关的解决方案 为啥要并发在程序中，并发本质上是提高任务的执行效率，减低程序运行的时间。不多解释 并发遇到的挑战有哪些&amp;&amp;解决方案上下文切换 首先要明确的就是即使是在单核cpu条件下，多线程也是支持的。从操作系统上来讲，CPU通过时间片机制来执行多线程。因为时间片很短，所以在我们看来是多线程并发执行，其实是cpu在内部根据时间片，在某一时间片时间结束后，保存当前线程状态，加载下一个线程之前的状态，然后在下一时间片时间内执行下一个线程的任务。保存当前线程状态，加载下一个线程的状态，其实就是上下文切换。举例就是说，你看一本英文书，有个词不会，然后你去翻词典，查到这个词，然后再回来继续读。去翻词典然后再回来继续读，这样读书效率不高的。 上下文切换解决方案本质上是减少上下文切换，或者是不使用系统切换。 无锁并发编程 多线程竞争锁的时候会进行上线文切换 CAS算法 CAS算法是无锁编程的一种算法 使用最小线程 使用最小的线程，以避免大量空闲线程等待浪费切换时间 使用协程 协程简单理解就是用户级的上下文切换，比系统上下文切换减少切换时间 死锁 作为开发，对于死锁肯定是不会陌生。如果你写的程序遇到了线程死锁，正常运行就有问题，更不用说并发来减少运行时间，反倒要延长时间。 死锁解决方案其实就是减少死锁。常见的有避免一个线程获取多个锁，使用定时锁（超过时间就释放掉）等等 资源限制 一台1核1G的服务器，可能最多支持同时跑40个线程，超过这个限制，cpu就会陷入疯狂切换上下文，也就执行不了实际的任务。或者说网络带宽是1M/s, 开多少线程也顶多下载速度是1M/s。 资源限制解决方案两个方向一是从程序上减少资源的浪费二是增加资源 参考《java并发编程的艺术》方腾飞 魏鹏 程晓明 著]]></content>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java微服务]]></title>
    <url>%2F2019%2F12%2F09%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%2Fjava%E5%BE%AE%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[java微服务 的一些对比 java微服务 微服务 概念 一种架构模式，提倡将单一应用划分为一组小的服务，服务之间相互协调，相互配合 特点 独立部署 不需要因单一服务重新部署全部服务 技术选型灵活 去中心化 容错 会隔离到单独的服务 扩展 每个小服务都可以增加额外的扩展 复杂度可控 每个微服务功能可以单一 在分布式环境下，REST方式的服务依赖要比RPC方式的依赖更为灵活 Dubbo 弊端 调用方与提供方依赖性太强 Spring-boot. 弊端 rest比rpc 更轻，不存在各种强依赖。但是要统一管理好文档 可以通过整合swagger 使每个服务代码与文档一体化，解决上面的问题 比较 Dubbo Spring-boot 交互方式 定义DTO json 调用方式 rpc http 代码入侵 配置xml,无代码入侵 注解配置有代码入侵 依赖情况 调用方与提供方强依赖 无依赖，可跨平台 版本管理 要有完善的版本管理 省略了版本管理的问题，但是具体字段约定要统一管理 服务注册中心 Zookeeper redis Netflix Eureka 服务网关 无 Netflix Zuul 断路（熔断器） 暂不完善 Netflix Hystrix 配置中心 无 Spring-cloud config 调用链追踪 无 Spring Cloud Sleuth 消息总线 无 spring-cloud 数据流 无 Spring Cloud Stream 封装了与Redis,Rabbit、Kafka等发送接收消息 批量任务 无 Spring Cloud Task Dubbo只是实现了服务治理 SpringCloud子项目分别覆盖了微服务架构体系下的方方面面，服务治理只是其中的一个方面 Dubbo额外提供了Filter扩展，对于上述“暂无”的部分，都可以通过扩展Filter来完善]]></content>
      <tags>
        <tag>java</tag>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 基础学习之Java.util.function 简单使用]]></title>
    <url>%2F2019%2F12%2F08%2Fjava%2FFunction%E7%AE%80%E5%8D%95%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Java.util.function 简单使用 Java.util.function 简单使用 有很多函数 Consumer 接受一个入参，无返回值。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@Datapublic class TestArgumentFunction &#123; private String a = "1"; private Integer b = 0; private Long c = 9L; private boolean d = true; @Test public void test() &#123; System.out.println("str " + getA()); setValue("bb ", this::setA); System.out.println("str " + getA()); System.out.println("In " + getB()); setValue(78, this::setB); System.out.println("In " + getB()); System.out.println("Lo " + getC()); setValue(78L, this::setC); System.out.println("Lo " + getC()); System.out.println("bo " + isD()); setValue(false, this::setD); System.out.println("bo " + isD()); /* result str 1 str bb In 0 In 78 Lo 9 Lo 78 bo true bo false */ &#125; public void set(String str, Consumer&lt;String&gt; function) &#123; function.accept(str); &#125; public void setA(String a) &#123; this.a = a; &#125; public String getA() &#123; return a; &#125; // 设置参数 private &lt;T&gt; void setValue(T value, Consumer&lt;T&gt; consumer) &#123; consumer.accept(value); &#125;&#125;]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之里氏替换原则(Liskov Substitution Principle，LSP)]]></title>
    <url>%2F2019%2F12%2F07%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E5%9F%BA%E6%9C%AC%E5%8E%9F%E5%88%99%2F%E9%87%8C%E6%B0%8F%E6%9B%BF%E6%8D%A2%E5%8E%9F%E5%88%99%2F</url>
    <content type="text"><![CDATA[里氏替换原则(Liskov Substitution Principle，LSP) 里氏替换原则(Liskov Substitution Principle，LSP) If for each object 01 of type S there is a object 02 of type T such that for all program P define in terms of T, the behavior of P is unchanged where o1 substitude o2, then S is a subtype of T.(对于每一个类型是S的对象，存在一个类型为T的对象，使得以T定义的程序P所在的对象由o2替换为o1时，行为不发生任何变化。那么S就是T的子类) Function that use pointers or refererence to base classes must be able to use objects of derived classes without knowing it.(使用基类的地方必须能透明的使用子类) 子类必须完全实现所有父类的方法 子类可以有自己的特性 覆盖或者实现父类的方法的时参数可以被放大 （可以理解为父类的入参类型是子类入参的子类） 注意： 尽量的不要子类太过于个性化，以免后期维护复杂。]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之迪米特原则（least knowledge principle）]]></title>
    <url>%2F2019%2F12%2F07%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E5%9F%BA%E6%9C%AC%E5%8E%9F%E5%88%99%2F%E8%BF%AA%E7%B1%B3%E7%89%B9%E5%8E%9F%E5%88%99%2F</url>
    <content type="text"><![CDATA[迪米特原则 迪米特原则(law of demeter) (least knowledge principle) Only talk to your imediate friends(只跟你最近的朋友聊天) 朋友类：（出现在成员变量，方法输入输出的类都是朋友类） 原则： 只和朋友聊 朋友之间不易耦合不要太强 自己的就是自己的]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之接口隔离原则]]></title>
    <url>%2F2019%2F12%2F06%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E5%9F%BA%E6%9C%AC%E5%8E%9F%E5%88%99%2F%E6%8E%A5%E5%8F%A3%E9%9A%94%E7%A6%BB%E5%8E%9F%E5%88%99%2F</url>
    <content type="text"><![CDATA[接口隔离原则 接口隔离原则 Clients should not be force do depend upon interfaces that they don’t need. The dependency of one class to another one should depend on the smallest possible interface. 客户端不应该依赖不需要的接口 类之间的依赖关系应该是最小的接口上。 对接口的规范 接口尽量小(如果与lsp冲突，以lsp为准) 接口要高内聚(提高接口,类内部处理能力，减少对外的交互) 要明白接口设计是有限度的。 实践 一个接口只服务于一个子模块或者业务逻辑 通过业务逻辑压缩接口中的public 方法接口要时常回顾，尽量的精简 已经被污染的接口，尽量去修改，若有风险，使用适配器适配 一切从业务触发.]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之单一职责原则]]></title>
    <url>%2F2019%2F12%2F05%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E5%9F%BA%E6%9C%AC%E5%8E%9F%E5%88%99%2F%E5%8D%95%E4%B8%80%E8%81%8C%E8%B4%A3%E5%8E%9F%E5%88%99%2F</url>
    <content type="text"><![CDATA[单一职责原则 单一职责原则(single Responsibility Principle) There should no more than one reason for a class to change. This is sometimes hard to say. 在符合业务场景下，尽量的对模块做到：职能单一，行为单一。]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之开闭原则]]></title>
    <url>%2F2019%2F12%2F04%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E5%9F%BA%E6%9C%AC%E5%8E%9F%E5%88%99%2F%E5%BC%80%E9%97%AD%E5%8E%9F%E5%88%99%2F</url>
    <content type="text"><![CDATA[开闭原则 开闭原则 Software entities likes classes,modules and fuctions should be open for extension but close for modifications. 软件实体例如类，模块，方法，都应该对拓展开放，对修改关闭. 设计原则中的精神领袖。包含的东西太多。 具体怎么用，可以参考其他五个原则。 注意： 开闭原则也只是个原则，最合适的一定是结合业务 项目规章很重要 预知变化]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之依赖倒置原则]]></title>
    <url>%2F2019%2F12%2F04%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E5%9F%BA%E6%9C%AC%E5%8E%9F%E5%88%99%2F%E4%BE%9D%E8%B5%96%E5%80%92%E7%BD%AE%E5%8E%9F%E5%88%99%2F</url>
    <content type="text"><![CDATA[依赖倒置原则 依赖倒置原则（dependecy inversion principle） High level modules should not depend upon law level modules. Both should depend upon abstraction modules. Abstraction shuold not depend upon detail. Detail should depend upon abstraction. 高层模块不应该依赖底层模块，两者都要依赖其抽象 抽象不能依赖细节 细节应该依赖抽象 依赖的三种方式 作为构造函数 setter 接口声明 注意 任何类都应该尽量有抽象类或者接口，或者二者都有 变量表面尽量是抽象或者接口 任何类都不应该从具体类派生 尽量不要覆盖父类的方法（因为后期维护是个问题） 与 LSP 结合]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之装饰模式]]></title>
    <url>%2F2019%2F12%2F03%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%A3%85%E9%A5%B0%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[装饰模式 装饰模式 场景 对已有模块进行额外的行为操作（增加或者是撤销） 当不能采用继承的方式对系统进行扩充或者采用继承不利于系统扩展和维护时。不能采用继承的情况主要有两类：第一类是系统中存在大量独立的扩展，为支持每一种组合将产生大量的子类，使得子类数目呈爆炸性增长；第二类是因为类定义不能继承（如final类）. 角色 抽象接口 装饰抽象类(implements 抽象接口) 抽象实现类(实现 抽象接口) 装饰实现类（实现 装饰抽象类） 优点 不需要多重继承，装饰灵活 装饰组合灵活 新增额外行为不会影响原有系统，符合开闭原则 缺点 在过程中会生成多个动态的子类，增加系统的开销以及复杂度 多种装饰器，排错比较麻烦。]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之工厂模式vs建造者模式]]></title>
    <url>%2F2019%2F12%2F03%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%B0%81%E4%B8%8E%E4%BA%89%E9%94%8B%2F%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8Fvs%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[工厂模式vs建造者模式 工厂模式vs建造者模式举例： 人分为大人，小孩。大人可以抽烟喝酒，小孩子只会玩泥巴。 从角色上看 工厂模式 工厂 抽象产品类 具体产品类 建造者模式 指挥者 抽象builder 具体builder 产品 对外部来讲 使用工厂，外部需要知道有哪些产品 使用建造者，外部不知道有什么产品，也不知道是谁来建造，全部由指挥者来决定生产什么东西。 其他差异 关注的颗粒度不同 工厂模式关注的是产品的整体 建造者可以的话，更关注的是产品实现的步骤，顺序组合等 如何取舍 如果是关注产品的实现的步骤，顺序组合等，建议使用建造者模式。反之建议使用工厂模式。]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之观察者模式]]></title>
    <url>%2F2019%2F12%2F03%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[观察者模式(observer。。 publish|subscribe) 从属模式，model-View等 观察者模式(observer。。 publish|subscribe) 从属模式，model-View等 场景 当一个对象状态改变之后，需要通知其他对象进行相应的动作 角色 抽象观察者 具体观察者 抽象观察目标 具体观察目标 优点 联动/广播通信/消息传递 符合开闭原则 缺点 观察者只知道目标变化，而不知道具体什么变化 观察者众多，会导致系统复杂]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之适配器模式]]></title>
    <url>%2F2019%2F12%2F03%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[适配器模式 适配器模式 场景（目的） 把适配的类的api转换成目标的api 一般是对外接口通用适配对外接口 角色 抽象Adapter 抽象Target 具体Target(实际上是这里做了一个适配,调用了不同的具体Adapter) 具体Adapter 优点 使用灵活，对上层友好，符合开闭，支持不同的适配 缺点 需要引用对象实例.]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之桥接模式]]></title>
    <url>%2F2019%2F12%2F02%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[桥接模式 桥接模式 场景 系统需要在抽象化与具体话之间更加灵活，避免多个层次的有静态的继承关系，通过桥接模式，可以再抽象层建立一个连接 系统存在多个独立变化，且每个维度都需要独立的变化，并且有一定的关联使用(一般是这个) 角色 抽象类Abstraction（维护一个实现类接口） (也可以理解这里是个桥，连接了具体实现类) 扩充抽象类(扩充Abstraction的接口, extends Abstraction) 实现类接口 具体实现类 优点 抽象类与具体实现类解耦分类，避免了多层次继承导致的系统复杂度 独立各维度模块，单纯的改动任意模块都不会对之前的有所影响. 缺点 大部分桥接工作都是在抽象类中做的，会带来一定的系统理解复杂度 桥接模式最常解决的问题是多个独立维度的问题，所以使用该模式要对独立模式有很好的拆解]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之建造者模式]]></title>
    <url>%2F2019%2F12%2F01%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[建造者模式 建造者模式 优点 不必知道产品的组装细节，直接沟通领导者即可获得所需，将产品本身与产品的创建解耦，可以在相同的步骤创造不同产品对象 创造者之间各自独立 更有效的掌控产品的生产过程 新的创建者无需更改原有类，更加符合开闭原则 缺点 产品之间类似，创建的步骤基本一致. 如差异性很大，该模式就不太符合 todo 还有一点待理解 角色 指挥者(Director) 抽象建造者 具体建造者 产品 场景 产品内部有多个内部结构，多个变量属性 产品对象的属性之间有一定的依赖，要有一定的顺序生产 产品创建复杂，且创建过程可以创建其他的产品.]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之享元模式（flyweight）]]></title>
    <url>%2F2019%2F11%2F30%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E4%BA%AB%E5%85%83%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[享元模式（flyweight） 享元模式（flyweight） 场景 频繁的创建可复用对象，有性能，特别是内存造成一定的压力 角色 抽象享元类 具体享元类 享元工厂类 优点 解决场景锁带来的问题 缺点 加深系统的复杂度 享元对象存活时间过长。 举例： java里面的整型(-128-127全部是用的缓存，也可以变相的理解为享元模式)]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之代理模式]]></title>
    <url>%2F2019%2F11%2F30%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[代理模式 代理模式 场景 对于客户端不想或者是不能直接引用一个对象，需要引进一个代理 代理大致种类 虚拟代理 将一个大的对象，先用一个小对象代替，具体使用时在生成，减小系统消耗 远程代理 对于不同地址空间提供个局域代理对象，就像是在对统一地址空间操作 保护代理 权限保护 角色 接口Subject 代理Proxy(实现Sunject) 具体实现类(SubjectImpl) 优点 协调调用者与被调用者，降低系统耦合度 缺点 因为有代理，可能会降低系统的性能 代理实现可能会比较复杂（特别低是动态代理）]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之外观模式]]></title>
    <url>%2F2019%2F11%2F30%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[外观模式 外观模式 场景 内部接口众多，client需要手动调用每个接口 角色 外观角色 子系统角色 优点 对使用方简单化，减少client处理的对象数目，并对子系统使用更加容易 缺点 因外观类整合了子系统类，使用缺乏一定的灵活性.]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之命令模式(command)]]></title>
    <url>%2F2019%2F11%2F30%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[命令模式(command) 命令模式(command) 场景 解耦调用者与被调用者，使二者不直接交互（类似代理模式） 角色 调用者 命令接口(command) 具体命令(xxcommand) 被调用者(receiver) 客户端(这个其实有些时候可以跟调用者合并) 优点 解耦接口调用者与被调用者之间关系 缺点 命令太多，会导致系统复杂]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之工厂模式汇总]]></title>
    <url>%2F2019%2F11%2F29%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[工厂模式汇总 工厂模式汇总 简单工厂，方法工厂，抽象工厂总结 工厂模式目的就是解耦 存在等级结构（抽象类），且产品之间有一定的联系，就可以使用抽象工厂。 如果不存在等级结构，或者是工厂生产的产品无联系，可以使用方法工厂。 简单工厂一般是知道了需要的产品是什么样子。 抽象工厂是方法工厂的高级模式。 各类模式关键点 简单工厂 场景 根据不同参数，返回不同类的实例。 就是常用的工厂函数 优点 使用者不需要知道实现细节，只需要相关的类就好 使用以及维护代码方便 缺点 对于工厂类，负担过重，如果有额外的逻辑，可能会导致工厂过于复杂。 违反“开闭原则”，一旦添加新产品就不得不修改逻辑 包含角色 工厂 抽象产品 具体产品 uml图 方法工厂 优点 更符合“开闭原则”，新产品，只需要新建工厂类以及产品类即可。 简单工厂是需要更改工厂逻辑 符合单一职责原则。每个工厂生产对应的产品 简单工厂工厂生成所有的产品 不使用静态工厂，可以形成基于继承的等级结构 简单工厂使用静态工厂 总的来说，方法工厂是简单工厂的扩展，让扩展更简单，继承可行。 缺点 每增加一个产品，就要生成一个工厂，增加编译运行，项目代码复杂度 单一工厂只能生产一种产品 场景 不知道所需要的类是什么（简单工厂反之） 类通过子类创建对象 角色 抽象工厂 工厂 抽象产品 产品 uml 抽象工厂 优点 继承方法工厂的优点，解决方法工厂工厂只能生产单一产品的缺点 增加等级机构。并且对工厂产生的产品进行约束(产品簇) 缺点 产品簇的扩展比较复杂。如果新增一种产品，可能需要改动所有的工厂 场景 相关的产品存在一定的联系，存在一定的等级结构，就可以用抽象工厂。 (这里可以用方法工厂模式，因为工厂模式各个产品不存在等级结构，且不存在相关的联系) 角色 抽象工厂(可以生产多个产品) 具体工厂类 抽象产品 具体产品 uml图]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之单例模式]]></title>
    <url>%2F2019%2F11%2F29%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[单例模式 单例模式 场景- 某个类智能有一个示例，提供一个全局的访问点 节省系统资源，提高系统效率，严格限制访问。]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-boot 运行源码分析]]></title>
    <url>%2F2019%2F11%2F28%2FspringBoot%2Fspring-boot%2F</url>
    <content type="text"><![CDATA[spring-boot 运行源码分析 spring-boot 一个简单的demo。 1234567891011@SpringBootApplicationpublic class Main &#123; public static void main(String[] args) &#123; // 主要运行类 SpringApplication.run(Main.class, args); &#125;&#125; 可以看到源码 12345public static ConfigurableApplicationContext run(Object[] sources, String[] args) &#123; // 加载资源， // 再运行. return new SpringApplication(sources).run(args);&#125; 初始化资源 1234public SpringApplication(Object... sources) &#123; // 初始化资源。 initialize(sources);&#125; 1234567891011121314151617181920// 加载资源。主要初始化上下文，以及监听器@SuppressWarnings(&#123; &quot;unchecked&quot;, &quot;rawtypes&quot; &#125;)private void initialize(Object[] sources) &#123; if (sources != null &amp;&amp; sources.length &gt; 0) &#123; this.sources.addAll(Arrays.asList(sources)); &#125; // deduceWebEnvironment 判断是不是web环境 this.webEnvironment = deduceWebEnvironment(); // 获取ContextInitializer 应用程序初始化器 /* getSpringFactoriesInstances 会读取spring-core-xxx . META-INF 中的spring.factory中的文件。 */ setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); // listener 应用程序监听器 setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); // 找出main类，这里是MyApplication类 this.mainApplicationClass = deduceMainApplicationClass();&#125; spring.factory 主要包含了以下几个。1234567891011121314151617# PropertySource Loadersorg.springframework.boot.env.PropertySourceLoader# Failure Analyzersorg.springframework.boot.diagnostics.FailureAnalyzer# Run Listenersorg.springframework.boot.SpringApplicationRunListener# Environment Post Processorsorg.springframework.boot.env.EnvironmentPostProcessor# Application Listenersorg.springframework.context.ApplicationListener=# FailureAnalysisReportersorg.springframework.boot.diagnostics.FailureAnalysisReporter=]]></content>
      <tags>
        <tag>java</tag>
        <tag>spring boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-data-jpa多源配置 隐式命名规则（驼峰转蛇形）失效 解决]]></title>
    <url>%2F2019%2F11%2F27%2FspringBoot%2Fspring-data-jpa%E5%A4%9A%E6%BA%90%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[spring-data-jpa多源配置 隐式命名规则（驼峰转蛇形）失效 解决 spring-data-jpa多源配置 隐式命名规则（驼峰转蛇形）失效 Q 配置好多源之后，隐式命名策略失效 A 要单独写一个配置JpaProperties的函数，在生成LocalContainerEntityManagerFactoryBean的时候，初始化12345678910111213141516171819202122232425//注入JPA配置实体@Autowiredprivate JpaProperties jpaProperties;//获取jpa配置信息private Map&lt;String, String&gt; getVendorProperties(DataSource dataSource) &#123; // 添加自己要选择的命名策略 jpaProperties.getHibernate().getNaming().setPhysicalStrategy("org.springframework.boot.orm.jpa.hibernate.SpringPhysicalNamingStrategy"); return jpaProperties.getHibernateProperties(dataSource);&#125;@Primary@Bean(name = "entityManagerFactorySpiderShard")public LocalContainerEntityManagerFactoryBean entityManagerFactorySpiderSharding( EntityManagerFactoryBuilder builder) &#123; return builder .dataSource(primaryDataSource) .packages("xx") // 在这里初始化每个源自己的命名规则 .properties(getVendorProperties(primaryDataSource)) .persistenceUnit("spiderShardPersistenceUnit") .build();&#125;]]></content>
      <tags>
        <tag>java</tag>
        <tag>spring boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 简单了解]]></title>
    <url>%2F2019%2F11%2F26%2FspringBoot%2F%E7%AE%80%E5%8D%95%E4%BA%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Spring Boot 简单了解 Spring Boot结构 spring-boot 提供Application类，便捷启动，以及刷新ApplicationContext 嵌套可选择性Web服务容器 外部配置 让ApplicationContext初始化配置更为方便，包括日志等 spring-boot-autoconfigure 自动注入 spring-boot-starters 三方包支持 spring-boot-cli spring-boot 终端命令 spring-boot-actuator 提供自身以及监控功能 spring-boot-actuator-autoconfigure spring-boot-actuator相关自动注入 spring-boot-test spring-boot 测试 spring-boot-test-autoconfigure 自动配置 spring-boot-loader 我理解是单元化测试加载相关项目 spring-boot-devtools 运维相关工具 个人理解1spring-boot 是spring 全家桶的易上手版，其中的自动注入，以及starters都是蛮好的思想，主要可以看这两个，其他的还是要看下spring相关的源码设计。 大佬的面试总结 梁桂钊 链接]]></content>
      <tags>
        <tag>java</tag>
        <tag>spring boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[thread-state]]></title>
    <url>%2F2019%2F11%2F25%2Fjava%2Fthread-state%2F</url>
    <content type="text"><![CDATA[本文章介绍 Java Thread State各种状态.通过本篇文章你可以了解到：1 Java 线程中都有哪些状态2 这些状态之间的联系是怎样的3 使用jstack查看运行中的线程状态 Java 线程中的状态其实只要看下Thread.State源码就可以知道有几种类型了 1234567891011121314151617181920212223242526272829303132333435363738394041424344public enum State &#123; /** * 初始状态。线程刚创建，还没有调用start() */ NEW, /** * 正在运行的状态（java 将系统中的Ready和运行都笼统的成为运行中）。正在运行的线程有可能处于等待状态。例如等待系统io */ RUNNABLE, /** * 阻塞状态。等待锁的释放 */ BLOCKED, /** * 等待状态 * 线程变为等待状态，分为下面三种情况 * 1 Object.wait() 并且没有timeout参数 * 2 Thread.join 没有timeout参数 * 3 LockSupport.park() * 例如： * 一个线程调用了Object.wait(). 直到另外的线程调用了该Object.notify()或者是Object.notify()方法才会解除waiting状态。 */ WAITING, /** * 超时等待状态。等待一定时间后，自动释放该状态 * 例如：调用了下面的函数并有时间相关参数 * &lt;li&gt;&#123;@link #sleep Thread.sleep&#125;&lt;/li&gt; * &lt;li&gt;&#123;@link Object#wait(long) Object.wait&#125; with timeout&lt;/li&gt; * &lt;li&gt;&#123;@link #join(long) Thread.join&#125; with timeout&lt;/li&gt; * &lt;li&gt;&#123;@link LockSupport#parkNanos LockSupport.parkNanos&#125;&lt;/li&gt; * &lt;li&gt;&#123;@link LockSupport#parkUntil LockSupport.parkUntil&#125;&lt;/li&gt; * &lt;/ul&gt; */ TIMED_WAITING, /** * 线程终止状态 */ TERMINATED; &#125; 这些状态之间的联系是怎样的具体见下图（图源《Java 并发编程艺术》4.1.4节） 从上图可以到 1 初始化线程状态表示为New. 调用Thread.start()转换状态为RUNNABLE 2 调用Object.wait()/Object.join()/LockSupport.park会由RUNNABLE转换为WAITING转态。调用Object.notify()/Object.notifyAll()/LockSupport.unpark()才会由，WAITING转为RUNABLE 3 调用Thread.sleep(long)/Object.wait(long)/Thread.join(long)/LockSupport.pardNanos(long)/LockSupport.parkUntil(long) 由 RUNNABLE-&gt; TIMED_WAITING 反之通过Object.notify()/Object.notifyAll()/LockSupport.unpark()才会由，TIMED_WAITING转为RUNABLE 4 在调用synchronized函数时候，未获取到锁，会变为BLOCKED。 获取到之后即变为RUNNABLE 5 执行完成之后转换为TERMINATED 使用jstack查看运行中的线程状态 NEW 1234567@Testpublic void testNew() &#123; Thread thread = new Thread(); System.out.println(thread.getState()); // NEW&#125; RUNNABEL &amp;&amp; WAITING 1234567891011121314@Testpublic void testRunnable() throws InterruptedException &#123; Thread testRunnable = new Thread(new Runnable() &#123; @Override public void run() &#123; for (int i = 0; i &lt; Integer.MAX_VALUE; i++) &#123; System.out.println(i); &#125; &#125; &#125;, &quot;testRunnable&quot;); testRunnable.start(); testRunnable.join();&#125; testRunnable 线程是在运行 main此时状态为WAITING. 因为调用了thread.join函数 BLOCKED &amp;&amp; WAITING 123456789101112131415161718192021222324252627282930313233343536373839public static void main(String[] args)&#123; final Object lock = new Object(); Thread waitingA = new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (lock) &#123; try &#123; Thread.sleep(20000); System.out.println(&quot;waiting&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;, &quot;waitingA&quot;); Thread waitingB = new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (lock) &#123; try &#123; Thread.sleep(20000); System.out.println(&quot;waiting&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;, &quot;waitingB&quot;); waitingA.start(); waitingB.start();&#125; 可以看下图中 A TIMED_WAITING B因为A获取到了lock，而为BLOCKED状态]]></content>
      <tags>
        <tag>java, Thread-State</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[==equals]]></title>
    <url>%2F2019%2F11%2F25%2Fjava%2Fequal%2F</url>
    <content type="text"><![CDATA[通过本篇文章，你可以了解到 == 与equals的区别 == 比较的是 地址。 如果是基础类型就比较值。如果是对象就比较地址 equals() : 它的作用也是判断两个对象是否相等。但它一般有两种使用情况：情况1：类没有覆盖 equals() 方法。则通过 equals() 比较该类的两个对象时，等价于通过“==”比较这两个对象。情况2：类覆盖了 equals() 方法。一般，我们都覆盖 equals() 方法来比较两个对象的内容是否相等；若它们的内容相等，则返回 true (即，认为这两个对象相等)。 举个栗子 1234567891011121314151617public class test1 &#123; public static void main(String[] args) &#123; String a = new String(&quot;ab&quot;); // a 为一个引用 String b = new String(&quot;ab&quot;); // b为另一个引用,对象的内容一样 String aa = &quot;ab&quot;; // 放在常量池中 String bb = &quot;ab&quot;; // 从常量池中查找 if (aa == bb) // true System.out.println(&quot;aa==bb&quot;); if (a == b) // false，非同一对象 System.out.println(&quot;a==b&quot;); if (a.equals(b)) // true System.out.println(&quot;aEQb&quot;); if (42 == 42.0) &#123; // true System.out.println(&quot;true&quot;); &#125; &#125;&#125;]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA String vs StringBuffer vs StringBuilder]]></title>
    <url>%2F2019%2F11%2F25%2Fjava%2Fstring-stringbuilder-stringbuffer%2F</url>
    <content type="text"><![CDATA[通过本篇文章，你可以了解到StringBuffer与StringBuilder的区别。 String 不可变内部数据是由final 修饰的 1234public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123; /** The value is used for character storage. */ private final char value[]; StringBuffer vs StringBuilder 均可变StringBuffer 和 StringBuilder 都是继承AbstractStringBuilder。 12345678910abstract class AbstractStringBuilder implements Appendable, CharSequence &#123; /** * The value is used for character storage. */ char[] value; /** * The count is the number of characters used. */ int count; 线程安全性 StringBuffer 是线程安全的 使用synchronized 修饰了函数 StringBuilder 没有用synchronized修饰,是非线程安全的 数据修改 StringBuffer 每次都是对原有对象的引用修改 1234567@Overridepublic synchronized String toString() &#123; if (toStringCache == null) &#123; toStringCache = Arrays.copyOfRange(value, 0, count); &#125; return new String(toStringCache, true);&#125; StringBuilder 每次都是创建一个新的对象 12345@Overridepublic String toString() &#123; // Create a copy, don&apos;t share the array return new String(value, 0, count);&#125; 性能 相比之下 StringBuilder要比StringBuffer快，但是有线程不安全]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[同步，异步，阻塞，非阻塞]]></title>
    <url>%2F2019%2F11%2F12%2Fblock-non%2F</url>
    <content type="text"><![CDATA[同步，异步，阻塞，非阻塞是日常开发中经常聊的，但是真正说起来什么是这些东西的时候，还是有点绕. so 找找资料记录下. 重要 阻塞和非阻塞描述的是调用方。 同步与异步描述的是被调用方 以高科技钓鱼， 鱼咬钩之后会报警为例。 A调用B 阻塞抛竿之后，就一直看着鱼竿等着鱼咬钩A调用B，A一直等着B返回，在这期间A啥也不干 非阻塞抛竿之后，开始玩手机，不需要一直看鱼竿A调用B， A不用等着B,可以先忙着其他。 同步鱼咬钩,告警器才亮A调用B, B结束了之后才给A返回 异步鱼竿抛出之后，鱼没有咬钩，但是告警器可以闪烁A调用B, B先给A返回我收到了，等B结束之后再通过其他方式通知A（回调） 参考 漫话编程文章]]></content>
      <tags>
        <tag>概念</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[io模型]]></title>
    <url>%2F2019%2F11%2F12%2Fio-model%2F</url>
    <content type="text"><![CDATA[并发处理，对于各种io模型还是需要掌握的。 建议直接看最后面的链接，图文并茂理解更佳。 前提io其实就是输入输出. 就是平时的文件读取，或者是网络爬虫抓取页面（socket io）. 举例读取文件：将文件从磁盘读取到内存中，然后再从内存中读取到用户空间中 以钓鱼为例,拆分为抛竿，鱼咬钩，拉起三个操作 阻塞io 抛竿之后等着鱼咬钩然后再拉起 非阻塞io 抛竿之后，边玩手机边看鱼咬钩，然后再拉起 I/O复用 一次性抛多个鱼竿，挨个检查各个鱼竿有没有咬钩，咬钩了就拉起 信号驱动IO 鱼竿上面有个报警器，抛竿之后，一直玩手机，直到鱼咬钩触发了报警，然后再拉起 异步IO 抛竿之后，干其他的，鱼咬钩之后自动拉起，然后再通知你 参考 漫话编程]]></content>
      <tags>
        <tag>io</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop-hbase-zookeeper]]></title>
    <url>%2F2019%2F11%2F02%2Fhadoop%2Fhadoop-hbase-zookeeper%2F</url>
    <content type="text"><![CDATA[大数据开发，hadoop,hbase 环境搭建肯定是必不可少少了。之前已经把hadoop搞清楚了，但是直到今天才把Hbase搭建成功（虽然中间还是有点瑕疵），记录下相关的操作. 系统相关配置 三台机器centos7(master(10.211.55.20), slave1(10.211.55.21), slave2(10.211.55.22)) java 1.8 hadoop 2.7.2 hbase 1.4.9 zookeeper 3.4.14 各节点功能 节点/hostname 服务 master/10.211.55.20 DataNode JournalNodeNodeManagerQuorumPeerMainHRegionServerNameNodeJpsHMaster slave1/10.211.55.21 JournalNode ResourceManager NodeManager HRegionServerQuorumPeerMain NameNode slave2/10.211.55.22 JournalNodeHRegionServerNodeManagerDataNodeQuorumPeerMain 预先配置 用户(hadoop) 在三台机器上创建hadoop用户（之后的操作都是在用户hadoop下操作的） 1useradd hadoop 开启免密登录 1234# 在三台机器上分别执行ssh-copy-id 10.211.55.20ssh-copy-id 10.211.55.21ssh-copy-id 10.211.55.22 下载相关安装包到/home/hadoop（我们的安装目录）下面，解压，此时的目录下为 12345hadoop@master [04:47:44 PM] [~/hadoop-2.7.2]-&gt; % lsbin lib logs sbinetc libexec NOTICE.txt shareinclude LICENSE.txt README.txt tmp 配置java文件 将下面的几句话添加到.bashrc中(因为我用的是zsh,所以是.zshrc), 三台机器都需要配置 1234# jdk1.8export JAVA_HOME=/home/hadoop/jdk1.8export PATH=$JAVA_HOME/bin:$PATHexport CLASS_PATH=$JAVA_HOME/lib 添加完之后，记得source .bashrc 或者是source .zshrc 关闭三台机器的防火墙,分别登录到三台机器上执行 1234567891011121314151617# 关闭防火墙sudo systemctl stop firewalld.service# 开机关闭防火墙sudo systemctl disable firewalld.service## 验证是否关闭成功sudo systemctl status firewalld.service ## 执行上面的命令后，出现下面的日志即表示已经关闭防火墙了● firewalld.service - firewalld - dynamic firewall daemon Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled; vendor preset: enabled) Active: inactive (dead) Docs: man:firewalld(1)Nov 01 06:54:04 slave1 systemd[1]: Starting fir...Nov 01 06:54:05 slave1 systemd[1]: Started fire...Nov 01 07:38:19 slave1 systemd[1]: Stopping fir...Nov 01 07:38:20 slave1 systemd[1]: Stopped fire...Hint: Some lines were ellipsized, use -l to show in full. zookeeper 在 master(10.211.55.20上) 12cd /home/hadoop/zookeeper-3.4.14/confmv zoo_sample.cfg zoo.cfg 将下面的东西复制进zoo.cfg 删除原来的配置 12345678910111213141516171819202122232425262728293031# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial# synchronization phase can takeinitLimit=10# The number of ticks that can pass between# sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just# example sakes.dataDir=/home/hadoop/zookeeper-3.4.14/data/zkdata# the port at which the clients will connectclientPort=2181# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the# administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to &quot;0&quot; to disable auto purge feature#autopurge.purgeInterval=1server.1=master:2888:3888server.2=slave1:2888:3888server.3=slave2:2888:3888 创建zookeeper 数据保存文件夹 123mkdir -p /home/hadoop/zookeeper-3.4.14/data/zkdatacd /home/hadoop/zookeeper-3.4.14/data/zkdataecho &quot;1&quot; &gt; myid 将master机器上改过之后的zookeeper 文件夹发送到slave1以及slave2机器上 ​ 123cd ~scp -r zookeeper-3.4.14 10.211.55.21:/home/hadoopscp -r zookeeper-3.4.14 10.211.55.22:/home/hadoop 登录到slave1 1echo &quot;2&quot; /home/hadoop/zookeeper-3.4.14/data/zkdata/myid 登录到slave2 1echo &quot;2&quot; /home/hadoop/zookeeper-3.4.14/data/zkdata/myid 分别登录上三台机器执行下面命令，启动zookeeper集群 12cd /home/hadoop/zookeeper-3.4.14./bin/zkServer.sh start 启动成功之后，检测三台机器状态(因zookeeper内部选取机制，所以下面的leader与fellower仅供参考，并不一定是下面的情况) 1234567891011121314151617hadoop@master [04:48:24 PM] [~/zookeeper-3.4.14]-&gt; % ./bin/zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /home/hadoop/zookeeper-3.4.14/bin/../conf/zoo.cfgMode: followerhadoop@slave1 [04:49:18 PM] [~/zookeeper-3.4.14]-&gt; % ./bin/zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /home/hadoop/zookeeper-3.4.14/bin/../conf/zoo.cfgMode: leaderhadoop@slave2 [04:49:24 PM] [~/zookeeper-3.4.14]-&gt; % ./bin/zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /home/hadoop/zookeeper-3.4.14/bin/../conf/zoo.cfgMode: follower hadoop 修改配置(下面的操作都是在/home/hadoop/hadoop-2.7.2/etc/hadoop目录下面进行修改) 修改hadoop-env.sh 12# 找到JAVA_HOME 修改为export JAVA_HOME=/home/hadoop/jdk1.8 vi core-site.xml 12345678910111213141516171819&lt;configuration&gt; &lt;!-- hdfs地址，ha模式中是连接到nameservice --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://ns1&lt;/value&gt; &lt;/property&gt; &lt;!-- 这里的路径默认是NameNode、DataNode、JournalNode等存放数据的公共目录，也可以单独指定 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/home/hadoop/hadoop-2.7.2/tmp&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定ZooKeeper集群的地址和端口。注意，数量一定是奇数，且不少于三个节点--&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;master:2181,slave1:2181,slave2:2181&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; vi hdfs-site.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485&lt;configuration&gt; &lt;!-- 指定副本数，不能超过机器节点数 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt; &lt;!-- 为namenode集群定义一个services name --&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;ns1&lt;/value&gt; &lt;/property&gt; &lt;!-- nameservice 包含哪些namenode，为各个namenode起名 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.ns1&lt;/name&gt; &lt;value&gt;master,slave1&lt;/value&gt; &lt;/property&gt; &lt;!-- 名为master的namenode的rpc地址和端口号，rpc用来和datanode通讯 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.ns1.master&lt;/name&gt; &lt;value&gt;master:9000&lt;/value&gt; &lt;/property&gt; &lt;!-- 名为slave1的namenode的rpc地址和端口号，rpc用来和datanode通讯 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.ns1.slave1&lt;/name&gt; &lt;value&gt;slave1:9000&lt;/value&gt; &lt;/property&gt; &lt;!--名为master的namenode的http地址和端口号，用来和web客户端通讯 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.ns1.master&lt;/name&gt; &lt;value&gt;master:50070&lt;/value&gt; &lt;/property&gt; &lt;!-- 名为slave1的namenode的http地址和端口号，用来和web客户端通讯 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.ns1.slave1&lt;/name&gt; &lt;value&gt;slave1:50070&lt;/value&gt; &lt;/property&gt; &lt;!-- namenode间用于共享编辑日志的journal节点列表 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://master:8485;slave1:8485;slave2:8485/ns1&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定该集群出现故障时，是否自动切换到另一台namenode --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled.ns1&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- journalnode 上用于存放edits日志的目录 --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;/home/hadoop/hadoop-2.7.2/tmp/data/dfs/journalnode&lt;/value&gt; &lt;/property&gt; &lt;!-- 客户端连接可用状态的NameNode所用的代理类 --&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.ns1&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt; &lt;/property&gt; &lt;!-- 一旦需要NameNode切换，使用ssh方式进行操作 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;sshfence&lt;/value&gt; &lt;/property&gt; &lt;!-- 如果使用ssh进行故障切换，使用ssh通信时用的密钥存储的位置 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt; &lt;value&gt;/home/hadoop/.ssh/id_rsa&lt;/value&gt; &lt;/property&gt; &lt;!-- connect-timeout超时时间 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;/name&gt; &lt;value&gt;30000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; vi mapred-site.xml 1234567&lt;!-- 采用yarn作为mapreduce的资源调度框架 --&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; vi yarn-site.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;configuration&gt; &lt;!-- 启用HA高可用性 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定resourcemanager的名字 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt; &lt;value&gt;yrc&lt;/value&gt; &lt;/property&gt; &lt;!-- 使用了2个resourcemanager,分别指定Resourcemanager的地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt; &lt;value&gt;rm1,rm2&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定rm1的地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt; &lt;value&gt;master&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定rm2的地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt; &lt;value&gt;slave1&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定当前机器master作为rm1 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.id&lt;/name&gt; &lt;value&gt;rm1&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定zookeeper集群机器 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt; &lt;value&gt;master:2181,slave1:2181,slave2:2181&lt;/value&gt; &lt;/property&gt; &lt;!-- NodeManager上运行的附属服务，默认是mapreduce_shuffle --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; vi slaves(删除localhost) 123masterslave1slave2 将修改后的文件夹发送到其他两台机器 123cd ~scp -r hadoop-2.7.2 10.211.55.21:/home/hadoopscp -r hadoop-2.7.2 10.211.55.22:/home/hadoop 登录到slave1 修改/etc/hadoop/yarn-site.xml 1234&lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.id&lt;/name&gt; &lt;value&gt;rm2&lt;/value&gt;&lt;/property&gt; 登录到slave2 。 对/etc/hadoop/yarn-site.xml删除上面的键值对 初始化 在三台机器上使用命令启动journalnode 12cd /home/hadoop/hadoop-2.7.2./sbin/hadoop-daemon.sh start journalnode 在master机器上执行 123cd /home/hadoop/hadoop-2.7.2./bin/hdfs namenode -format./hdfs zkfc -formatZK 这个时候目录在目录上会出现一个tmp目录(/home/hadoop/hadoop-2.7.2/tmp) 将该目录发送到slave1,/home/hadoop/hadoop-2.7.2文件夹中 1scp -r tmp 10.211.55.21:/home/hadoop/hadoop-2.7.2 在slave1 机器上执行 12cd /home/hadoop/hadoop-2.7.2./bin/hdfs namenode -bootstrapStanby 在maser机器上启动hadoop集群 123cd /home/hadoop/hadoop-2.7.2./sbin/start-dfs.sh./sbin/start-yarn.sh 如果正常启动成功，那么在master执行jps,会出现 12345624624 DataNode24179 JournalNode25075 NodeManager25977 NameNode1147 Jps24974 ResourceManager hbase 登录到master,进入目录hbase配置目录 1cd /home/hadoop/hbase-1.4.9/conf vim hbase-env.sh 12345678//配置JDKexport JAVA_HOME=/opt/jdk//配置hbase 启动进程idexport HBASE_PID_DIR=/home/hadoop/hbase-1.4.9/pids//不用自带的zkexport HBASE_MANAGES_ZK=false vi hbase-site.xml 12345678910111213141516171819202122232425262728293031323334353637&lt;configuration&gt; &lt;!-- 设置HRegionServers共享目录，请加上端口号 --&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://master:9000/hbase&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定HMaster主机 --&gt; &lt;property&gt; &lt;name&gt;hbase.master&lt;/name&gt; &lt;value&gt;hdfs://master:60000&lt;/value&gt; &lt;/property&gt; &lt;!-- 启用分布式模式 --&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定Zookeeper集群位置 --&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;master:2181,slave1:2181,slave2:2181&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定独立Zookeeper安装路径 --&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt; &lt;value&gt;/home/hadoop/zookeeper-3.4.14&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定ZooKeeper集群端口 --&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt; &lt;value&gt;2181&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; vi regionservers 123masterslave1slave2 创建pids 1mkdir -p /home/hadoop/hbase-1.4.9/pids 将hbase发送到其他机器上 123cd ~scp -r hbase-1.4.9 10.211.55.21:/home/hadoopscp -r hbase-1.4.9 10.211.55.22:/home/hadoop 启动hbase 12cd /home/hadoop/hbase-1.4.9./bin/start-hbase.sh 如果启动成功，执行hbase shell 出现下面提示，即表示成功. 12345678-&gt; % ./bin/hbase shell2019-11-01 16:37:41,780 WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicableHBase ShellUse &quot;help&quot; to get list of supported commands.Use &quot;exit&quot; to quit this interactive shell.Version 1.4.9, rd625b212e46d01cb17db9ac2e9e927fdb201afa1, Wed Dec 5 11:54:10 PST 2018hbase(main):001:0&gt; 注意 如果hadoop namenode 全部是standy,需要手动指定active （master机器） 12cd /home/hadoop/hadoop-2.7.2./bin/hdfs haadmin -transitionToActive --forcemanual master 参考（都是大佬啊）]]></content>
      <tags>
        <tag>zookeeper</tag>
        <tag>hadoop</tag>
        <tag>hbase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scrapy(2)之执行分析]]></title>
    <url>%2F2019%2F07%2F17%2Fpython%2Fscrapy-2%2F</url>
    <content type="text"><![CDATA[根据之前写的scrapy-1,我们分析到了初始化引擎。下面就实际运行是如何运行的。 scapy.crawler.Crawler.crawl 主要工作 实例化spider （这个源码就跳过了，就是简单的创建spider实例，并将参数设置好） 实例化engine (下面详细讲下)1234567891011121314151617181920212223242526272829303132@defer.inlineCallbacksdef crawl(self, *args, **kwargs): assert not self.crawling, &quot;Crawling already taking place&quot; self.crawling = True try: self.spider = self._create_spider(*args, **kwargs) ## 这个就是实例化了一个scrapy.core.engine.ExecutionEngine类 self.engine = self._create_engine() # 这里就是从自定义的start_url里面读取url,并封装成 scrapy.http.request.Request实例 start_requests = iter(self.spider.start_requests()) yield self.engine.open_spider(self.spider, start_requests) yield defer.maybeDeferred(self.engine.start) except Exception: # In Python 2 reraising an exception after yield discards # the original traceback (see https://bugs.python.org/issue7563), # so sys.exc_info() workaround is used. # This workaround also works in Python 3, but it is not needed, # and it is slower, so in Python 3 we use native `raise`. if six.PY2: exc_info = sys.exc_info() self.crawling = False if self.engine is not None: yield self.engine.close() if six.PY2: six.reraise(*exc_info) raisedef _create_engine(self): return ExecutionEngine(self, lambda _: self.stop()) 这个函数在creat_engine之后，调用了open_spider函数。 scrapy.core.engine.ExecutionEngine.open_spider 主要做了以下动作 将_next_request 注册到twisted 实例化调度器 中间件封装start_request 将事件，start_reqeusts,调度器封装成slot 并将其设置为实例属性 调用scheduler.open函数，初始化去重过滤器中间件（默认是DUPEFILTER_CLASS = ‘scrapy.dupefilters.RFPDupeFilter’） 调用scraper.open_spider(spider) 生成pipline slot.nextcall.schedule() 这个是调用前面注册成CallLaterOnce的_next_request函数。 123456789101112131415161718192021@defer.inlineCallbacks def open_spider(self, spider, start_requests=(), close_if_idle=True): assert self.has_capacity(), &quot;No free spider slot when opening %r&quot; % \ spider.name logger.info(&quot;Spider opened&quot;, extra=&#123;&apos;spider&apos;: spider&#125;) ## 这里是将_next_requests 注册到了twisted nextcall = CallLaterOnce(self._next_request, spider) scheduler = self.scheduler_cls.from_crawler(self.crawler) start_requests = yield self.scraper.spidermw.process_start_requests(start_requests, spider) slot = Slot(start_requests, close_if_idle, nextcall, scheduler) self.slot = slot self.spider = spider # 初始化去重过滤器中间件（默认是DUPEFILTER_CLASS = &apos;scrapy.dupefilters.RFPDupeFilter&apos;） yield scheduler.open(spider) # 生成pipline yield self.scraper.open_spider(spider) self.crawler.stats.open_spider(spider) yield self.signals.send_catch_log_deferred(signals.spider_opened, spider=spider) # 这个是调用前面注册成CallLaterOnce的_next_request函数。 slot.nextcall.schedule() slot.heartbeat.start(5) _next_reuqests 需要注意的是 在调用 _next_request_from_scheduler 的时候，调用了Download 第一次调用_next_request_from_scheduler是没有的数据的，调用self._crawl之后才会吧request放进队列里面12345678910111213141516171819202122232425262728def _next_request(self, spider): slot = self.slot if not slot: return if self.paused: return # 是否需要等待 while not self._needs_backout(spider): # 是否有下一个request，如果没有就break if not self._next_request_from_scheduler(spider): break # 如果还有start_requests 并且没有等待，那么就获取下一个request 并放入队列中 if slot.start_requests and not self._needs_backout(spider): try: request = next(slot.start_requests) except StopIteration: slot.start_requests = None except Exception: slot.start_requests = None logger.error(&apos;Error while obtaining start requests&apos;, exc_info=True, extra=&#123;&apos;spider&apos;: spider&#125;) else: # 将request放进队列 self.crawl(request, spider) if self.spider_is_idle(spider) and slot.close_if_idle: self._spider_idle(spider) _next_request_from_scheduler 主要做的事情 先从scheduler.next_request() 获取队列中的next_request 调用engine._download 下载（需要注意的是，这里经过了下载中间件） 下面会详细分析 下载完成之后调用engine._handle_downloader_output 后面会讲到。下面先讲下如何下载的。1234567891011121314151617181920def _next_request_from_scheduler(self, spider): slot = self.slot request = slot.scheduler.next_request() if not request: return d = self._download(request, spider) ## d.addBoth(self._handle_downloader_output, request, spider) d.addErrback(lambda f: logger.info(&apos;Error while handling downloader output&apos;, exc_info=failure_to_exc_info(f), extra=&#123;&apos;spider&apos;: spider&#125;)) d.addBoth(lambda _: slot.remove_request(request)) d.addErrback(lambda f: logger.info(&apos;Error while removing request from slot&apos;, exc_info=failure_to_exc_info(f), extra=&#123;&apos;spider&apos;: spider&#125;)) d.addBoth(lambda _: slot.nextcall.schedule()) d.addErrback(lambda f: logger.info(&apos;Error while scheduling new request&apos;, exc_info=failure_to_exc_info(f), extra=&#123;&apos;spider&apos;: spider&#125;)) return d engine.crawl 实际就是把request放进调度器重123456789101112def crawl(self, request, spider): assert spider in self.open_spiders, \ &quot;Spider %r not opened when crawling: %s&quot; % (spider.name, request) self.schedule(request, spider) self.slot.nextcall.schedule()def schedule(self, request, spider): self.signals.send_catch_log(signal=signals.request_scheduled, request=request, spider=spider) if not self.slot.scheduler.enqueue_request(request): self.signals.send_catch_log(signal=signals.request_dropped, request=request, spider=spider) scheduler.enqueue_request 如果计算指纹 参考看下scrapy.utils.request.py中的request_fingerprint函数12345678910111213def enqueue_request(self, request):# 如果不需要过滤 或者是指纹重复就不进队列 if not request.dont_filter and self.df.request_seen(request): self.df.log(request, self.spider) return False dqok = self._dqpush(request) if dqok: self.stats.inc_value(&apos;scheduler/enqueued/disk&apos;, spider=self.spider) else: self._mqpush(request) self.stats.inc_value(&apos;scheduler/enqueued/memory&apos;, spider=self.spider) self.stats.inc_value(&apos;scheduler/enqueued&apos;, spider=self.spider) return True 上面介绍了如果request如何进队列，下面介绍下scrapy是如何下载request ExecutionEngine._download1234567891011121314151617181920212223def _download(self, request, spider): slot = self.slot slot.add_request(request) def _on_success(response): assert isinstance(response, (Response, Request)) if isinstance(response, Response): response.request = request # tie request to response received logkws = self.logformatter.crawled(request, response, spider) logger.log(*logformatter_adapter(logkws), extra=&#123;&apos;spider&apos;: spider&#125;) self.signals.send_catch_log(signal=signals.response_received, \ response=response, request=request, spider=spider) return response def _on_complete(_): slot.nextcall.schedule() return _ # 这里下载 调用的是scrapy.core.download.Downloader.fetch dwld = self.downloader.fetch(request, spider) # 注册成功之后的调用 dwld.addCallbacks(_on_success) # 注册完成 dwld.addBoth(_on_complete) return dwld scrapy.core.download.Downloader.fetch 注意 这里有个时间是完成之后，会从active中去除掉改request123456789def fetch(self, request, spider): def _deactivate(response): self.active.remove(request) return response self.active.add(request) ## 这里调用的是scrapy.core.downloader.DownloaderMiddlewareManager dfd = self.middleware.download(self._enqueue_request, request, spider) return dfd.addBoth(_deactivate) scrapy.core.downloader.DownloaderMiddlewareManager.download 注意 这个函数主要是调用了下载中间件，最后再proecss_request执行完之后调用** scrapy.core.downloader.Downloader._enqueue_request** 才会真正的调用的下载 这里注册了三个事件, 这些调用定义的下载中间件。 默认的请参考default_setting.py DOWNLOADER_MIDDLEWARES_BASE配置 process_request 处理下载 process_response 处理返回 process_exception 处理异常 process_request 处理完之后会调用self._enqueue_request函数 这个函数12345678910111213141516171819202122232425262728293031323334353637383940414243def download(self, download_func, request, spider): @defer.inlineCallbacks def process_request(request): for method in self.methods[&apos;process_request&apos;]: response = yield method(request=request, spider=spider) if response is not None and not isinstance(response, (Response, Request)): raise _InvalidOutput(&apos;Middleware %s.process_request must return None, Response or Request, got %s&apos; % \ (six.get_method_self(method).__class__.__name__, response.__class__.__name__)) if response: defer.returnValue(response) defer.returnValue((yield download_func(request=request, spider=spider))) @defer.inlineCallbacks def process_response(response): assert response is not None, &apos;Received None in process_response&apos; if isinstance(response, Request): defer.returnValue(response) for method in self.methods[&apos;process_response&apos;]: response = yield method(request=request, response=response, spider=spider) if not isinstance(response, (Response, Request)): raise _InvalidOutput(&apos;Middleware %s.process_response must return Response or Request, got %s&apos; % \ (six.get_method_self(method).__class__.__name__, type(response))) if isinstance(response, Request): defer.returnValue(response) defer.returnValue(response) @defer.inlineCallbacks def process_exception(_failure): exception = _failure.value for method in self.methods[&apos;process_exception&apos;]: response = yield method(request=request, exception=exception, spider=spider) if response is not None and not isinstance(response, (Response, Request)): raise _InvalidOutput(&apos;Middleware %s.process_exception must return None, Response or Request, got %s&apos; % \ (six.get_method_self(method).__class__.__name__, type(response))) if response: defer.returnValue(response) defer.returnValue(_failure) ## 注册事件 deferred = mustbe_deferred(process_request, request) deferred.addErrback(process_exception) deferred.addCallback(process_response) return deferred scrapy.core.downloader.Downloader._enqueue_request/_process_queue/_download 这里涉及到了三个Downloader的函数 -_enqueue_request 将request 和spider封装成slot 放进队列后，调用_process_queue _process_queue 在判断是否需要延迟之后，调用_download，进行下载 _download 调用self.handlers.download_request(默认的是scrapy.core.downloader.handlers.DownloadHandlers)，这个函数会根据不同的scheme选择不同的handler. 默认的分为 1234567 &apos;data&apos;: &apos;scrapy.core.downloader.handlers.datauri.DataURIDownloadHandler&apos;, &apos;file&apos;: &apos;scrapy.core.downloader.handlers.file.FileDownloadHandler&apos;, &apos;http&apos;: &apos;scrapy.core.downloader.handlers.http.HTTPDownloadHandler&apos;, &apos;https&apos;: &apos;scrapy.core.downloader.handlers.http.HTTPDownloadHandler&apos;, &apos;s3&apos;: &apos;scrapy.core.downloader.handlers.s3.S3DownloadHandler&apos;, &apos;ftp&apos;: &apos;scrapy.core.downloader.handlers.ftp.FTPDownloadHandler&apos;,&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869def _enqueue_request(self, request, spider): key, slot = self._get_slot(request, spider) request.meta[self.DOWNLOAD_SLOT] = key def _deactivate(response): slot.active.remove(request) return response slot.active.add(request) self.signals.send_catch_log(signal=signals.request_reached_downloader, request=request, spider=spider) deferred = defer.Deferred().addBoth(_deactivate) slot.queue.append((request, deferred)) self._process_queue(spider, slot) return deferreddef _process_queue(self, spider, slot): if slot.latercall and slot.latercall.active(): return # Delay queue processing if a download_delay is configured now = time() delay = slot.download_delay() if delay: penalty = delay - now + slot.lastseen if penalty &gt; 0: slot.latercall = reactor.callLater(penalty, self._process_queue, spider, slot) return # Process enqueued requests if there are free slots to transfer for this slot while slot.queue and slot.free_transfer_slots() &gt; 0: slot.lastseen = now request, deferred = slot.queue.popleft() dfd = self._download(slot, request, spider) dfd.chainDeferred(deferred) # prevent burst if inter-request delays were configured if delay: self._process_queue(spider, slot) breakdef _download(self, slot, request, spider): # The order is very important for the following deferreds. Do not change! # 1. Create the download deferred dfd = mustbe_deferred(self.handlers.download_request, request, spider) # 2. Notify response_downloaded listeners about the recent download # before querying queue for next request def _downloaded(response): self.signals.send_catch_log(signal=signals.response_downloaded, response=response, request=request, spider=spider) return response dfd.addCallback(_downloaded) # 3. After response arrives, remove the request from transferring # state to free up the transferring slot so it can be used by the # following requests (perhaps those which came from the downloader # middleware itself) slot.transferring.add(request) def finish_transferring(_): slot.transferring.remove(request) self._process_queue(spider, slot) return _ return dfd.addBoth(finish_transferring) 至此，下载以及下载中间件的处理已经完成了。我们现在回到### _next_request_from_scheduler,看下前面所讲到的engine._handle_downloader_output。 ExecutionEngine._handle_downloader_output 如果返回的response是request 那么久调用crawl方法，将request放入scheduler 如果返回的response 不是request。调用scraper.enqueue_scrape方法，处理response.123456789101112def _handle_downloader_output(self, response, request, spider): assert isinstance(response, (Request, Response, Failure)), response # downloader middleware can return requests (for example, redirects) if isinstance(response, Request): self.crawl(response, spider) return # response is a Response or Failure d = self.scraper.enqueue_scrape(response, request, spider) d.addErrback(lambda f: logger.error(&apos;Error while enqueuing downloader output&apos;, exc_info=failure_to_exc_info(f), extra=&#123;&apos;spider&apos;: spider&#125;)) return d scrapy.core.scraper.Scraper.enqueue_scrape 注册结束处理事件(从active队列中移除掉)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# 将结果放入slot队列中def enqueue_scrape(self, response, request, spider): slot = self.slot dfd = slot.add_response_request(response, request) # 这个就是处理完成之后，已出队列中response def finish_scraping(_): slot.finish_response(response, request) self._check_if_closing(spider, slot) self._scrape_next(spider, slot) return _ dfd.addBoth(finish_scraping) dfd.addErrback( lambda f: logger.error(&apos;Scraper bug processing %(request)s&apos;, &#123;&apos;request&apos;: request&#125;, exc_info=failure_to_exc_info(f), extra=&#123;&apos;spider&apos;: spider&#125;)) self._scrape_next(spider, slot) return dfd# 取出队列中的元素，进行处理def _scrape_next(self, spider, slot): while slot.queue: response, request, deferred = slot.next_response_request_deferred() self._scrape(response, request, spider).chainDeferred(deferred)# 注册 两个时间def _scrape(self, response, request, spider): &quot;&quot;&quot;Handle the downloaded response or failure through the spider callback/errback&quot;&quot;&quot; assert isinstance(response, (Response, Failure)) dfd = self._scrape2(response, request, spider) # returns spiders processed output # 这个是处理错误 dfd.addErrback(self.handle_spider_error, request, response, spider) # 处理callback dfd.addCallback(self.handle_spider_output, request, response, spider) return dfd# 如果成功就调用下载中间件以及在经过中间件处理完之后调用call_spider函数，调用，否则就记录下载失败相关信息def _scrape2(self, request_result, request, spider): &quot;&quot;&quot;Handle the different cases of request&apos;s result been a Response or a Failure&quot;&quot;&quot; ## 这里调用的是scrapy.core.spidermw.SpiderMiddlewareManager.scrape_response if not isinstance(request_result, Failure): return self.spidermw.scrape_response( self.call_spider, request_result, request, spider) else: dfd = self.call_spider(request_result, request, spider) return dfd.addErrback( self._log_download_errors, request_result, request, spider)# 调用spider.callback和spider.parse函数def call_spider(self, result, request, spider): result.request = request dfd = defer_result(result) dfd.addCallbacks(request.callback or spider.parse, request.errback) return dfd.addCallback(iterate_spider_output) scrapy.core.spidermw.SpiderMiddlewareManager.scrape_response 先调用process_spider_input, 预处理response 注意此时没有调用spider中的callback或者是parse函数 执行完process_spider_input后 调用scrapy.core.scraper.Scraper.call_spider函数， 如果有异常会调用process_spider_exception 如果无异常会调用 process_spider_output 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778def scrape_response(self, scrape_func, response, request, spider): fname = lambda f:&apos;%s.%s&apos; % ( six.get_method_self(f).__class__.__name__, six.get_method_function(f).__name__) def process_spider_input(response): for method in self.methods[&apos;process_spider_input&apos;]: try: result = method(response=response, spider=spider) if result is not None: raise _InvalidOutput(&apos;Middleware &#123;&#125; must return None or raise an exception, got &#123;&#125;&apos; \ .format(fname(method), type(result))) except _InvalidOutput: raise except Exception: return scrape_func(Failure(), request, spider) return scrape_func(response, request, spider) def process_spider_exception(_failure, start_index=0): exception = _failure.value # don&apos;t handle _InvalidOutput exception if isinstance(exception, _InvalidOutput): return _failure method_list = islice(self.methods[&apos;process_spider_exception&apos;], start_index, None) for method_index, method in enumerate(method_list, start=start_index): if method is None: continue result = method(response=response, exception=exception, spider=spider) if _isiterable(result): # stop exception handling by handing control over to the # process_spider_output chain if an iterable has been returned return process_spider_output(result, method_index+1) elif result is None: continue else: raise _InvalidOutput(&apos;Middleware &#123;&#125; must return None or an iterable, got &#123;&#125;&apos; \ .format(fname(method), type(result))) return _failure def process_spider_output(result, start_index=0): # items in this iterable do not need to go through the process_spider_output # chain, they went through it already from the process_spider_exception method recovered = MutableChain() def evaluate_iterable(iterable, index): try: for r in iterable: yield r except Exception as ex: exception_result = process_spider_exception(Failure(ex), index+1) if isinstance(exception_result, Failure): raise recovered.extend(exception_result) method_list = islice(self.methods[&apos;process_spider_output&apos;], start_index, None) for method_index, method in enumerate(method_list, start=start_index): if method is None: continue # the following might fail directly if the output value is not a generator try: result = method(response=response, result=result, spider=spider) except Exception as ex: exception_result = process_spider_exception(Failure(ex), method_index+1) if isinstance(exception_result, Failure): raise return exception_result if _isiterable(result): result = evaluate_iterable(result, method_index) else: raise _InvalidOutput(&apos;Middleware &#123;&#125; must return an iterable, got &#123;&#125;&apos; \ .format(fname(method), type(result))) return chain(result, recovered) dfd = mustbe_deferred(process_spider_input, response) ## 注册了这个callback事件 dfd.addCallbacks(callback=process_spider_output, errback=process_spider_exception) return dfd 结至此，scrapy crawl xxx 整体流程分析完毕 核心类图 其中褐色表示方法 淡黄表示属性 仔细观察还是结合scrapy整体架构图的]]></content>
      <tags>
        <tag>scrapy</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊环境隔离]]></title>
    <url>%2F2019%2F07%2F16%2F%E8%81%8A%E8%81%8A%E5%85%B6%E4%BB%96%2F%E8%81%8A%E8%81%8A%E7%8E%AF%E5%A2%83%E9%9A%94%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[环境问题是日常开发以及服务上线碰到的问题。这里简单聊下自己所知道的环境隔离的方案 参考有赞环境隔离分享]]></content>
      <tags>
        <tag>环境隔离</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊dubbo与zookeeper]]></title>
    <url>%2F2019%2F07%2F16%2F%E8%81%8A%E8%81%8A%E5%85%B6%E4%BB%96%2F%E8%81%8A%E8%81%8Adubbo%E4%B8%8Ezookeeper%2F</url>
    <content type="text"><![CDATA[dubbo简单来讲就是一个远程调用RPC协议框架。本质上还是个协议 zookeeper是一个注册中心。本质上还是一个软件(software) dubbo 分组 vs zk分组dubbo 分组本意上是当应用有多种版本的时候，可以用group。 （从这点来看用来做环境弱隔离也是可以的）zk分组实际上是根据物理机ip分组。]]></content>
      <tags>
        <tag>java</tag>
        <tag>dubbo</tag>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scrapy(1)深入-环境配置]]></title>
    <url>%2F2019%2F07%2F02%2Fpython%2Fscrapy-1%2F</url>
    <content type="text"><![CDATA[scrapy 是python 爬虫框架中用度最广，且简单的流行款。这里笔者依据源码，分析下 scrapy crawl xxx 之后的操作。 scrapy crawl xxx 调用流程 由setup.py 123entry_points=&#123; &apos;console_scripts&apos;: [&apos;scrapy = scrapy.cmdline:execute&apos;] &#125; 我们找到开始的python 脚本 scrapy.cmdline:execute 主要做了下面几件事情 初始化环境配置，在项目中运行项目 初始化CrawlProcess 调用run1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162def execute(argv=None, settings=None): if argv is None: argv = sys.argv # --- 兼容之前版本配置 --- if settings is None and &apos;scrapy.conf&apos; in sys.modules: from scrapy import conf if hasattr(conf, &apos;settings&apos;): settings = conf.settings # ------------------------------------------------------------------ # 初始化scrapy.cfg 以及 scrapy.settings.default_setting.py 中的配置 if settings is None: settings = get_project_settings() # set EDITOR from environment if available try: editor = os.environ[&apos;EDITOR&apos;] except KeyError: pass else: settings[&apos;EDITOR&apos;] = editor # 输出deprecated 配置 check_deprecated_settings(settings) # --- 兼容之前版本配置--- import warnings from scrapy.exceptions import ScrapyDeprecationWarning with warnings.catch_warnings(): warnings.simplefilter(&quot;ignore&quot;, ScrapyDeprecationWarning) from scrapy import conf conf.settings = settings # ------------------------------------------------------------------ # 判断是否在project中 inproject = inside_project() # 加载支持的命令 即package scrapy.commands下面的所有的文件 集合成字典 cmds = _get_commands_dict(settings, inproject) cmdname = _pop_command_name(argv) parser = optparse.OptionParser(formatter=optparse.TitledHelpFormatter(), \ conflict_handler=&apos;resolve&apos;) if not cmdname: _print_commands(settings, inproject) sys.exit(0) elif cmdname not in cmds: _print_unknown_command(settings, cmdname, inproject) sys.exit(2) cmd = cmds[cmdname] parser.usage = &quot;scrapy %s %s&quot; % (cmdname, cmd.syntax()) parser.description = cmd.long_desc() settings.setdict(cmd.default_settings, priority=&apos;command&apos;) cmd.settings = settings cmd.add_options(parser) # 解析参数 opts, args = parser.parse_args(args=argv[1:]) # 这里是对命令中一些参数进行设置 比如是 ```-logfile=xxx.xx```等 _run_print_help(parser, cmd.process_options, args, opts) # 爬虫运行类 cmd.crawler_process = CrawlerProcess(settings) # 执行 cmd 中的run类。 ** 在这里就是执行scrapy.commands.crawler.run函数** _run_print_help(parser, _run_command, cmd, args, opts) sys.exit(cmd.exitcode) scray.crawler.CrawlerProcess 这个类是继承了scray.crawler.CrawlerRunner，主要是增加了一个start函数。需要注意的是init 函数。 scray.crawler.CrawlerRunner.init 中有个属性是spider_loader 是所有爬虫类的加载器，默认使用的是 default_setting.py中的 SPIDER_LOADER_CLASS =’scrapy.spiderloader.SpiderLoader’。 scrapy.commands.crawler.run 这里就是调用了CrawlProcess.crawl/start 函数 123456789101112def run(self, args, opts): if len(args) &lt; 1: raise UsageError() elif len(args) &gt; 1: raise UsageError(&quot;running &apos;scrapy crawl&apos; with more than one spider is no longer supported&quot;) spname = args[0] self.crawler_process.crawl(spname, **opts.spargs) self.crawler_process.start() if self.crawler_process.bootstrap_failed: self.exitcode = 1 CrawlProcess.crawl/CrawlerRunner.crawl 实际上这个调用的是父类 rawlerRunner.crawl 主要工作 初始化并返回一个scrapy.crawler.Crawler实例 调用_crawl函数12345678910def crawl(self, crawler_or_spidercls, *args, **kwargs): if isinstance(crawler_or_spidercls, Spider): raise ValueError( &apos;The crawler_or_spidercls argument cannot be a spider object, &apos; &apos;it must be a spider class (or a Crawler object)&apos;) ## 返回一个scrapy.crawler.Crawler对象 crawler = self.create_crawler(crawler_or_spidercls) ## 调用 CrawlerRunner._crawl 函数 return self._crawl(crawler, *args, **kwargs) scrapy.crawler.Crawler 初始化1234567891011121314151617181920212223242526272829303132333435363738def __init__(self, spidercls, settings=None): if isinstance(spidercls, Spider): raise ValueError( &apos;The spidercls argument must be a class, not an object&apos;) if isinstance(settings, dict) or settings is None: settings = Settings(settings) self.spidercls = spidercls self.settings = settings.copy() self.spidercls.update_settings(self.settings) d = dict(overridden_settings(self.settings)) logger.info(&quot;Overridden settings: %(settings)r&quot;, &#123;&apos;settings&apos;: d&#125;) self.signals = SignalManager(self) self.stats = load_object(self.settings[&apos;STATS_CLASS&apos;])(self) handler = LogCounterHandler(self, level=self.settings.get(&apos;LOG_LEVEL&apos;)) logging.root.addHandler(handler) if get_scrapy_root_handler() is not None: # scrapy root handler already installed: update it with new settings install_scrapy_root_handler(self.settings) # lambda is assigned to Crawler attribute because this way it is not # garbage collected after leaving __init__ scope self.__remove_handler = lambda: logging.root.removeHandler(handler) self.signals.connect(self.__remove_handler, signals.engine_stopped) lf_cls = load_object(self.settings[&apos;LOG_FORMATTER&apos;]) self.logformatter = lf_cls.from_crawler(self) self.extensions = ExtensionManager.from_crawler(self) self.settings.freeze() self.crawling = False # spider 实例 初始化 self.spider = None # 核心engine self.engine = NoneCrawlerRunner._crawl 主要工作 上面初始化了一个Crawler 对象， 调用Crawler.crawl函数（初始化引擎等其他配置） 12345678910111213def _crawl(self, crawler, *args, **kwargs): self.crawlers.add(crawler) // Crawler.crawl d = crawler.crawl(*args, **kwargs) self._active.add(d) def _done(result): self.crawlers.discard(crawler) self._active.discard(d) self.bootstrap_failed |= not getattr(crawler, &apos;spider&apos;, None) return result return d.addBoth(_done) scapy.crawler.Crawler.crawl 主要工作 实例化spider （这个源码就跳过了，就是简单的创建spider实例，并将参数设置好） 实例化engine (下面详细讲下)12345678910111213141516171819202122232425262728293031@defer.inlineCallbacksdef crawl(self, *args, **kwargs): assert not self.crawling, &quot;Crawling already taking place&quot; self.crawling = True try: self.spider = self._create_spider(*args, **kwargs) ## 这个就是实例化了一个scrapy.engine.ExecutionEngine类 self.engine = self._create_engine() start_requests = iter(self.spider.start_requests()) yield self.engine.open_spider(self.spider, start_requests) yield defer.maybeDeferred(self.engine.start) except Exception: # In Python 2 reraising an exception after yield discards # the original traceback (see https://bugs.python.org/issue7563), # so sys.exc_info() workaround is used. # This workaround also works in Python 3, but it is not needed, # and it is slower, so in Python 3 we use native `raise`. if six.PY2: exc_info = sys.exc_info() self.crawling = False if self.engine is not None: yield self.engine.close() if six.PY2: six.reraise(*exc_info) raisedef _create_engine(self): return ExecutionEngine(self, lambda _: self.stop()) scrapy.engine.ExecutionEngine init 函数主要工作 加载调度器(默认是SCHEDULER = ‘scrapy.core.scheduler.Scheduler’) 加载下载器(默认是DOWNLOADER = ‘scrapy.core.downloader.Downloader’) 初始化 scrapy.core.scrapyer.Scraper 对象(下面详解)1234567891011121314151617class ExecutionEngine(object): def __init__(self, crawler, spider_closed_callback): self.crawler = crawler self.settings = crawler.settings self.signals = crawler.signals self.logformatter = crawler.logformatter self.slot = None self.spider = None self.running = False self.paused = False self.scheduler_cls = load_object(self.settings[&apos;SCHEDULER&apos;]) downloader_cls = load_object(self.settings[&apos;DOWNLOADER&apos;]) self.downloader = downloader_cls(crawler) # self.scraper = Scraper(crawler) self._spider_closed_callback = spider_closed_callback scrapy.core.scrapyer.Scraper 主要工作 (连接 middleware pipline spider) 初始化中间件 初始化item1234567891011class Scraper(object): def __init__(self, crawler): self.slot = None self.spidermw = SpiderMiddlewareManager.from_crawler(crawler) itemproc_cls = load_object(crawler.settings[&apos;ITEM_PROCESSOR&apos;]) self.itemproc = itemproc_cls.from_crawler(crawler) self.concurrent_items = crawler.settings.getint(&apos;CONCURRENT_ITEMS&apos;) self.crawler = crawler self.signals = crawler.signals self.logformatter = crawler.logformatter 到此核心插件初始化就完成了。]]></content>
      <tags>
        <tag>scrapy</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flink之Flink 简单介绍]]></title>
    <url>%2F2019%2F06%2F15%2FFlink%2FFlink-4-What-is-Flink%2F</url>
    <content type="text"><![CDATA[通过前几篇Flink 实战的文章，应该对Flink有点印象了。接下来，本片文章就简单从基本概念，场景， 架构， 特点等方面介绍下Flink. 什么是Flink 官网介绍如下Apache Flink is a framework and distributed processing engine for stateful computations over unbounded and bounded data streams. 个人理解Flink 是一个框架和分布式处理引擎，可以对无界或有界数据流进行状态计算。 注意加粗的几个字是核心。下面会聊到。 能够解决什么问题 通用处理流/批处理。 适用场景 实时智能推荐 复杂事件处理 实时数仓与ETL 流数据分析 实时报表分析 基本的概念 流/批处理处理思想 Flink对于批处理认为是有界的流处理。而Spark则认为流处理是更快的批处理。那个更有优势不重要，符合自己的需求并扩展性良好即可。 流 stream 有界流（批处理）vs 无界流（流处理） 有界流：一批连续的数据有开始有结束。（几何中的段的概念） 无界流：连续且无边界的数据流。（几何中射线的概念） 实时流和record Stream 实时流：举例天猫双十一大盘 record Stream： 离线数据清洗。 状态 state 状态可以简单理解为在处理数据的过程中，每个数据的改变都是状态的改变。 时间 time Event time 时间发生的时间 Process Time 消息被计算处理的时间 Ingestion Time 摄取时间：事件进入流处理系统的时间。 架构 组件结构 参考 API&amp;&amp;组件库层 Flink 同时提供了高级的流处理API(eg flatmap filter等),以及相对低级的processFunction. 在API的基础上，抽象除了不同场景下的组件库（FlinkML(机器学习)，CEP(复杂事件处理)等） Runtime层 是Flink的核心层。支持分布式作业的执行，任务调度等。 Deploy 层 部署相关。支持 local, yarn ,cloud等运行环境。 注意 FLink组件库调用API(StreamAPI或者是DataSetAPI)， API(StreamAPI或者是DataSetAPI) 生成jobGraph,并传递给Runtime层，jobGraph 根据不同的部署环境，采用不同的配置项（Flink内置的）执行。 Flink 集群运行时架构 参考 jobManagers(master) 负责 （至少有一个） 协调分布式执行 任务调度 协调检查 协调错误恢复 taskManagers(slave) 负责 （至少有一个） 执行数据流任务 缓存并交换流数据 client 作为数据源的输入，输入之后，可以被清除，也可以或者是处理其他的任务。 特性 流处理 支持高吞吐，低延迟，高性能流处理操作 支持高度灵活窗口(slideWindow SessionWindow等) 支持状态计算，同时具有exactly-once特性 支持 batch on stream API StreamAPI BatchAPI 众多Libraries 机器学习 图处理 。。。 总结Flink 本质上还是只是一个专门解决流批数据处理的框架，并且在性能，稳定，开发，部署等方面具有独到之处。如果我们日常需求中有涉及到大数据处理，且很可能会涉及到协同分布式等，Flink是一个很好的选择。 参考Flink 官网文档]]></content>
      <categories>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flink之收入最高出租车司机]]></title>
    <url>%2F2019%2F06%2F14%2FFlink%2FFlink-learning-in-action-3%2F</url>
    <content type="text"><![CDATA[本篇文章使用纽约市2009-1015年关于出租车驾驶的公共数据集，模拟现实数据流，获取一定时间内收入最高的出租车司机。 输入输出输入: 详见下面数据集输出：每个小时收入收入topN的driverId.额外条件：模拟丢失数据。每n条记录丢失一条数据。 数据集网站New York City Taxi &amp; Limousine Commission提供了关于纽约市从2009-1015年关于出租车驾驶的公共数据集。 下载：12wget http://training.ververica.com/trainingData/nycTaxiRides.gzwget http://training.ververica.com/trainingData/nycTaxiFares.gz TaxiRides 行程信息。每次出行包含两条记录。分别标识为 行程开始start 和 行程结束end。数据集结构 1234567891011rideId : Long // 唯一行程idtaxiId : Long // 出租车唯一id driverId : Long // 出租车司机唯一idisStart : Boolean // 是否是行程开始。false标识行程结束 startTime : DateTime // 行程开始时间endTime : DateTime // 行程结束时间 对于行程开始记录该值为 1970-01-01 00:00:00startLon : Float // 开始行程的经度startLat : Float // 开始行程的纬度endLon : Float // 结束的经度endLat : Float // 结束的纬度passengerCnt : Short // 乘客数量 TaxiRides 数据示例 TaxiFares 费用信息。 与上面行程信息对应 12345678rideId : Long // 唯一行程idtaxiId : Long // 出租车唯一iddriverId : Long // 出租车司机唯一idstartTime : DateTime // 行程开始时间paymentType : String // CSH or CRDtip : Float // tip for this ride (消费)tolls : Float // tolls for this ridetotalFare : Float // total fare collected TaxiFares 数据示例 分析通过上面的数据集以及输入输出的要求，可以分析如下：先根据上满两个数据集，生成输入流。再根据ridrId进行join，对join的结果进行窗口分割，最后对窗口内的数据入库计算收入最高的n个driverId. 思路 生成数据流。（读取上面两个数据集） 模拟丢失数据 filter 根据routId 将两个输入流join (这里其实是过滤掉了filter过滤掉的数据的对应数据) 对上面join的结果划分窗口，并以driverId分组计算窗口内收入，(这里就是简单对taxiFare进行取topN) 选出topN 输出。 部分核心实现新建两个class 表示ride和fare 完整代码 对应source 完整代码 主要逻辑 完整代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394public static void main(String[] args) throws Exception &#123; // 初始化enviorment StreamExecutionEnvironment environment = StreamExecutionEnvironment.getExecutionEnvironment(); // 设置事件事件 environment.setStreamTimeCharacteristic(TimeCharacteristic.EventTime); // 读取输入流 DataStreamSource&lt;TaxiFare&gt; taxiFareDataStreamSource = environment .addSource(new TaxiFareSource()); DataStream&lt;TaxiFare&gt; taxiFare = taxiFareDataStreamSource .keyBy(new KeySelector&lt;TaxiFare, Long&gt;() &#123; @Override public Long getKey(TaxiFare value) throws Exception &#123; return value.getRideId(); &#125; &#125;);// taxiFareDataStreamSource.print(); DataStreamSource&lt;TaxiRide&gt; taxiRideDataStreamSource = environment .addSource(new TaxiRideSource());// taxiRideDataStreamSource.print(); // 对source 过滤掉rided % 1000 == 0, 模拟现实世界丢失数据 DataStream&lt;TaxiRide&gt; taxiRide = taxiRideDataStreamSource.filter(new FilterFunction&lt;TaxiRide&gt;() &#123; @Override public boolean filter(TaxiRide value) throws Exception &#123; return value.isStart &amp;&amp; value.getRideId() % 1000 != 0; &#125; &#125;) .keyBy(new KeySelector&lt;TaxiRide, Long&gt;() &#123; @Override public Long getKey(TaxiRide value) throws Exception &#123; return value.getRideId(); &#125; &#125;); // join 将两个输入流以rideId为key， 合并 SingleOutputStreamOperator&lt;Tuple2&lt;TaxiFare, TaxiRide&gt;&gt; process = taxiFare.connect(taxiRide) .process(new ConnectProcess()); // 设置窗口 SingleOutputStreamOperator&lt;Tuple3&lt;Long, Float, Timestamp&gt;&gt; aggregate = process // 先将taxiFare 筛选出来，因为是要统计topN taxiFare .flatMap(new FlatMapFunction&lt;Tuple2&lt;TaxiFare, TaxiRide&gt;, TaxiFare&gt;() &#123; @Override public void flatMap(Tuple2&lt;TaxiFare, TaxiRide&gt; value, Collector&lt;TaxiFare&gt; out) throws Exception &#123; out.collect(value.f0); &#125; &#125;) // 因为是时间递增，所以watermark 很简单 .assignTimestampsAndWatermarks(new AscendingTimestampExtractor&lt;TaxiFare&gt;() &#123; @Override public long extractAscendingTimestamp(TaxiFare element) &#123;// System.out.println(element.getEventTime()); return element.getEventTime(); &#125; &#125;) // 根据 driverId 分组 .keyBy(new KeySelector&lt;TaxiFare, Long&gt;() &#123; @Override public Long getKey(TaxiFare value) throws Exception &#123; return value.getDriverId(); &#125; &#125;) // 设置时间窗口，每30min 计算一次最近1个小时的内driverId的总收入 .timeWindow(Time.hours(1), Time.minutes(30)) // 这个是累加函数,调用aggregate 结果会计算出同一个窗口中，每个driverId的收入总值 .aggregate(getAggregateFunction(), // 这个windowFunc 是格式化输出 new WindowFunction&lt;Float, Tuple3&lt;Long, Float, Timestamp&gt;, Long, TimeWindow&gt;() &#123; @Override public void apply(Long driverId, TimeWindow window, Iterable&lt;Float&gt; input, Collector&lt;Tuple3&lt;Long, Float, Timestamp&gt;&gt; out) throws Exception &#123; Float next = input.iterator().next(); out.collect(new Tuple3(driverId, next, new Timestamp(window.getEnd()))); &#125; &#125;); // topSize N int topSize = 3; aggregate // 根据时间进行分窗口 .keyBy(2) .timeWindow(Time.hours(1), Time.minutes(30)) .process(new topN(topSize)).print(); environment.execute("RideAndFareExercise"); &#125; 运行结果 参考[ververica]https://training.ververica.com/]]></content>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flink之获取topNWord]]></title>
    <url>%2F2019%2F06%2F12%2FFlink%2FFlink-learning-in-action-2%2F</url>
    <content type="text"><![CDATA[本片文章基于的逻辑上增加获取topN的逻辑，可以加深对Flink的认识。 描述中只是统计并输出了一定时间内的相同单词的次数，这次我们更深入点，统计一定时间内的前N个word. 思路： 获取运行环境 获取输入源 (socketTextStream) 对输入源进行算子操作 flatMap (拆分成单词，并给个默认值) keyby分组 timeWindow 划分时间窗口 reduce 对每一个窗口计算相同单词出现的次数 增加新窗口（里面的数据是上一步统计好次数之后的单词） 对上面窗口中的数据排序，输出前topN print 输出。 部分代码123456789101112// 对输入的数据进行拆分处理 DataStream&lt;Tuple2&lt;String, Long&gt;&gt; ret = socketTextStream.flatMap(split2Word()) // 根据tuple2 中的第一个值分组 .keyBy(0) // 设置窗口，每 30s为一个窗口，每5s计算一次 .timeWindow(Time.seconds(30), Time.seconds(5)) // 相同字母次数相加 .reduce(CountReduce()) // 滑动窗口，每 30s为一个窗口，每5s计算一次 （新增的逻辑） .windowAll(SlidingProcessingTimeWindows.of(Time.seconds(30), Time.seconds(5))) // 对同一个窗口的所有元素排序取前topSize （新增的逻辑） .process(new TopN(topSize)); TopN class 12345678910111213141516171819202122232425262728293031323334353637383940414243static class TopN extends ProcessAllWindowFunction&lt;Tuple2&lt;String, Long&gt;, Tuple2&lt;String, Long&gt;, TimeWindow&gt; &#123; private final int topSize; TopN(int topSize) &#123; this.topSize = topSize; &#125; @Override public void process(Context context, Iterable&lt;Tuple2&lt;String, Long&gt;&gt; elements, Collector&lt;Tuple2&lt;String, Long&gt;&gt; out) throws Exception &#123; /* 1 先创建一颗有序树， 2 依次往树里面放数据 3 如果超过topSize 那么就去掉树的最后一个节点 */ TreeMap&lt;Long, Tuple2&lt;String, Long&gt;&gt; treeMap = new TreeMap&lt;&gt;( new Comparator&lt;Long&gt;() &#123; @Override public int compare(Long o1, Long o2) &#123; return o2 &gt; o1 ? 1 : -1; &#125; &#125; ); for (Tuple2&lt;String, Long&gt; element : elements) &#123; treeMap.put(element.f1, element); if (treeMap.size() &gt; this.topSize) &#123; treeMap.pollLastEntry(); &#125; &#125; for (Entry&lt;Long, Tuple2&lt;String, Long&gt;&gt; longTuple2Entry : treeMap.entrySet()) &#123; out.collect(longTuple2Entry.getValue()); &#125; &#125; &#125; 完整代码完整代码请点我]]></content>
      <categories>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flink之第一个Flink程序]]></title>
    <url>%2F2019%2F06%2F11%2FFlink%2FFlink-learning-in-action-1%2F</url>
    <content type="text"><![CDATA[通过本篇文章，帮助你通过使用Maven 快速实现官网demo. 环境 操作系统： mac java版本：1.8 Flink版本：1.7.2 scala版本：2.11 maven 版本:Apache Maven 3.5.2 描述输入为连续的单词，每5s对30s内的单词进行计数并输出。 使用Maven 创建项目12345678mvn archetype:generate \ -DarchetypeGroupId=org.apache.Flink \ -DarchetypeArtifactId=Flink-quickstart-java \ -DarchetypeVersion=1.7.2 \ -DgroupId=Flink-learning-in-action \ -DartifactId=Flink-learning-in-action \ -Dversion=0.1 \ -Dpackage=myFlink 运行成功之后会再当前目录下生成一个名为 Flink-learning-in-action的目录。目录结构 1234567891011$ tree Flink-learning-in-actionFlink-learning-in-action├── pom.xml└── src └── main ├── java │ └── myFlink │ ├── BatchJob.java │ └── StreamingJob.java └── resources └── log4j.properties 代码思想 获取运行环境 获取输入源 (socketTextStream) 对输入源进行算子操作 flatMap (拆分成单词，并给个默认值) keyby分组 timeWindow 划分时间窗口 reduce 对每一个窗口计算相同单词出现的次数 print 输出。 部分代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public class SocketWindowCount &#123; public static void main(String[] args) throws Exception &#123; ParameterTool parameterTool = ParameterTool.fromArgs(args); String host = parameterTool.get("host", "localhost"); int port = parameterTool.getInt("port", 9000); // 先初始化执行环境 StreamExecutionEnvironment environment = StreamExecutionEnvironment.getExecutionEnvironment(); // 设置并发度为1， 方便观察输出 environment.setParallelism(1); // 输入流 DataStreamSource&lt;String&gt; socketTextStream = environment.socketTextStream(host, port); // 对输入的数据进行拆分处理 DataStream&lt;Tuple2&lt;String, Long&gt;&gt; reduce = socketTextStream.flatMap(split2Word()) // 根据tuple2 中的第一个值分组 .keyBy(0) // 设置窗口，每 30s为一个窗口，每5s计算一次 .timeWindow(Time.seconds(30), Time.seconds(5)) // 计算 .reduce(CountReduce()); // 打印到控制台 输出时间 reduce.addSink(new RichSinkFunction&lt;Tuple2&lt;String, Long&gt;&gt;() &#123; @Override public void invoke(Tuple2&lt;String, Long&gt; value, Context context) &#123; System.out.println(now() + " word: " + value.f0 + " count: " + value.f1); &#125; &#125;); environment.execute("SocketWindowCount"); &#125; // 统计相同值出现的次数 private static ReduceFunction&lt;Tuple2&lt;String, Long&gt;&gt; CountReduce() &#123; return new ReduceFunction&lt;Tuple2&lt;String, Long&gt;&gt;() &#123; @Override public Tuple2&lt;String, Long&gt; reduce(Tuple2&lt;String, Long&gt; value1, Tuple2&lt;String, Long&gt; value2) throws Exception &#123; return new Tuple2&lt;&gt;(value1.f0, value1.f1 + value2.f1); &#125; &#125;; &#125; // 将输入的一行 分割成单词，并初始化次数为1 private static FlatMapFunction&lt;String, Tuple2&lt;String, Long&gt;&gt; split2Word() &#123; return new FlatMapFunction&lt;String, Tuple2&lt;String, Long&gt;&gt;() &#123; @Override public void flatMap(String value, Collector&lt;Tuple2&lt;String, Long&gt;&gt; out) throws Exception &#123; String[] words = value.split("\\W"); for (String word : words) &#123; if (word.length() &gt; 0) &#123; out.collect(new Tuple2&lt;&gt;(word, 1L)); &#125; &#125; &#125; &#125;; &#125;&#125; 运行1 打开终端执行 1nc -l 9000 2 运行代码。 结果: 完整代码完整代码 参考资料java_api_quickstart]]></content>
      <categories>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
</search>
