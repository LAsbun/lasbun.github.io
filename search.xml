<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[flink之获取topNWord]]></title>
    <url>%2F2019%2F06%2F12%2Fflink-learning-in-action-2%2F</url>
    <content type="text"><![CDATA[本片文章基于上一篇文章的逻辑上增加获取topN的逻辑，可以加深对flink的认识。 描述上一篇文章中只是统计并输出了一定时间内的相同单词的次数，这次我们更深入点，统计一定时间内的前N个word. 思路： 获取运行环境 获取输入源 (socketTextStream) 对输入源进行算子操作 flatMap (拆分成单词，并给个默认值) keyby分组 timeWindow 划分时间窗口 reduce 对每一个窗口计算相同单词出现的次数 增加新窗口（里面的数据是上一步统计好次数之后的单词） 对上面窗口中的数据排序，输出前topN print 输出。 部分代码123456789101112// 对输入的数据进行拆分处理 DataStream&lt;Tuple2&lt;String, Long&gt;&gt; ret = socketTextStream.flatMap(split2Word()) // 根据tuple2 中的第一个值分组 .keyBy(0) // 设置窗口，每 30s为一个窗口，每5s计算一次 .timeWindow(Time.seconds(30), Time.seconds(5)) // 相同字母次数相加 .reduce(CountReduce()) // 滑动窗口，每 30s为一个窗口，每5s计算一次 （新增的逻辑） .windowAll(SlidingProcessingTimeWindows.of(Time.seconds(30), Time.seconds(5))) // 对同一个窗口的所有元素排序取前topSize （新增的逻辑） .process(new TopN(topSize)); TopN class 12345678910111213141516171819202122232425262728293031323334353637383940414243static class TopN extends ProcessAllWindowFunction&lt;Tuple2&lt;String, Long&gt;, Tuple2&lt;String, Long&gt;, TimeWindow&gt; &#123; private final int topSize; TopN(int topSize) &#123; this.topSize = topSize; &#125; @Override public void process(Context context, Iterable&lt;Tuple2&lt;String, Long&gt;&gt; elements, Collector&lt;Tuple2&lt;String, Long&gt;&gt; out) throws Exception &#123; /* 1 先创建一颗有序树， 2 依次往树里面放数据 3 如果超过topSize 那么就去掉树的最后一个节点 */ TreeMap&lt;Long, Tuple2&lt;String, Long&gt;&gt; treeMap = new TreeMap&lt;&gt;( new Comparator&lt;Long&gt;() &#123; @Override public int compare(Long o1, Long o2) &#123; return o2 &gt; o1 ? 1 : -1; &#125; &#125; ); for (Tuple2&lt;String, Long&gt; element : elements) &#123; treeMap.put(element.f1, element); if (treeMap.size() &gt; this.topSize) &#123; treeMap.pollLastEntry(); &#125; &#125; for (Entry&lt;Long, Tuple2&lt;String, Long&gt;&gt; longTuple2Entry : treeMap.entrySet()) &#123; out.collect(longTuple2Entry.getValue()); &#125; &#125; &#125; 完整代码完整代码请点我]]></content>
      <categories>
        <category>flink</category>
      </categories>
      <tags>
        <tag>flink</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flink之第一个flink程序]]></title>
    <url>%2F2019%2F06%2F11%2Fflink-learning-in-action-1%2F</url>
    <content type="text"><![CDATA[通过本篇文章，帮助你通过使用Maven 快速实现官网demo. 环境 操作系统： mac java版本：1.8 flink版本：1.7.2 scala版本：2.11 maven 版本:Apache Maven 3.5.2 描述输入为连续的单词，每5s对30s内的单词进行计数并输出。 使用Maven 创建项目12345678mvn archetype:generate \ -DarchetypeGroupId=org.apache.flink \ -DarchetypeArtifactId=flink-quickstart-java \ -DarchetypeVersion=1.7.2 \ -DgroupId=flink-learning-in-action \ -DartifactId=flink-learning-in-action \ -Dversion=0.1 \ -Dpackage=myflink 运行成功之后会再当前目录下生成一个名为 flink-learning-in-action的目录。目录结构 1234567891011$ tree flink-learning-in-actionflink-learning-in-action├── pom.xml└── src └── main ├── java │ └── myflink │ ├── BatchJob.java │ └── StreamingJob.java └── resources └── log4j.properties 代码思想 获取运行环境 获取输入源 (socketTextStream) 对输入源进行算子操作 flatMap (拆分成单词，并给个默认值) keyby分组 timeWindow 划分时间窗口 reduce 对每一个窗口计算相同单词出现的次数 print 输出。 部分代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public class SocketWindowCount &#123; public static void main(String[] args) throws Exception &#123; ParameterTool parameterTool = ParameterTool.fromArgs(args); String host = parameterTool.get("host", "localhost"); int port = parameterTool.getInt("port", 9000); // 先初始化执行环境 StreamExecutionEnvironment environment = StreamExecutionEnvironment.getExecutionEnvironment(); // 设置并发度为1， 方便观察输出 environment.setParallelism(1); // 输入流 DataStreamSource&lt;String&gt; socketTextStream = environment.socketTextStream(host, port); // 对输入的数据进行拆分处理 DataStream&lt;Tuple2&lt;String, Long&gt;&gt; reduce = socketTextStream.flatMap(split2Word()) // 根据tuple2 中的第一个值分组 .keyBy(0) // 设置窗口，每 30s为一个窗口，每5s计算一次 .timeWindow(Time.seconds(30), Time.seconds(5)) // 计算 .reduce(CountReduce()); // 打印到控制台 输出时间 reduce.addSink(new RichSinkFunction&lt;Tuple2&lt;String, Long&gt;&gt;() &#123; @Override public void invoke(Tuple2&lt;String, Long&gt; value, Context context) &#123; System.out.println(now() + " word: " + value.f0 + " count: " + value.f1); &#125; &#125;); environment.execute("SocketWindowCount"); &#125; // 统计相同值出现的次数 private static ReduceFunction&lt;Tuple2&lt;String, Long&gt;&gt; CountReduce() &#123; return new ReduceFunction&lt;Tuple2&lt;String, Long&gt;&gt;() &#123; @Override public Tuple2&lt;String, Long&gt; reduce(Tuple2&lt;String, Long&gt; value1, Tuple2&lt;String, Long&gt; value2) throws Exception &#123; return new Tuple2&lt;&gt;(value1.f0, value1.f1 + value2.f1); &#125; &#125;; &#125; // 将输入的一行 分割成单词，并初始化次数为1 private static FlatMapFunction&lt;String, Tuple2&lt;String, Long&gt;&gt; split2Word() &#123; return new FlatMapFunction&lt;String, Tuple2&lt;String, Long&gt;&gt;() &#123; @Override public void flatMap(String value, Collector&lt;Tuple2&lt;String, Long&gt;&gt; out) throws Exception &#123; String[] words = value.split("\\W"); for (String word : words) &#123; if (word.length() &gt; 0) &#123; out.collect(new Tuple2&lt;&gt;(word, 1L)); &#125; &#125; &#125; &#125;; &#125;&#125; 运行1 打开终端执行 1nc -l 9000 2 运行代码。 结果: 完整代码完整代码 参考资料java_api_quickstart]]></content>
      <categories>
        <category>flink</category>
      </categories>
      <tags>
        <tag>flink</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F06%2F01%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
