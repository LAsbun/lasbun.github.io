<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[并发编程]]></title>
    <url>%2F2019%2F12%2F09%2F%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[通过本片文章，你可以了解到：1 什么是并发编程2 并发编程有哪些挑战3 相关的解决方案 为啥要并发在程序中，并发本质上是提高任务的执行效率，减低程序运行的时间。不多解释 并发遇到的挑战有哪些&amp;&amp;解决方案上下文切换 首先要明确的就是即使是在单核cpu条件下，多线程也是支持的。从操作系统上来讲，CPU通过时间片机制来执行多线程。因为时间片很短，所以在我们看来是多线程并发执行，其实是cpu在内部根据时间片，在某一时间片时间结束后，保存当前线程状态，加载下一个线程之前的状态，然后在下一时间片时间内执行下一个线程的任务。保存当前线程状态，加载下一个线程的状态，其实就是上下文切换。举例就是说，你看一本英文书，有个词不会，然后你去翻词典，查到这个词，然后再回来继续读。去翻词典然后再回来继续读，这样读书效率不高的。 上下文切换解决方案本质上是减少上下文切换，或者是不使用系统切换。 无锁并发编程 多线程竞争锁的时候会进行上线文切换 CAS算法 CAS算法是无锁编程的一种算法 使用最小线程 使用最小的线程，以避免大量空闲线程等待浪费切换时间 使用协程 协程简单理解就是用户级的上下文切换，比系统上下文切换减少切换时间 死锁 作为开发，对于死锁肯定是不会陌生。如果你写的程序遇到了线程死锁，正常运行就有问题，更不用说并发来减少运行时间，反倒要延长时间。 死锁解决方案其实就是减少死锁。常见的有避免一个线程获取多个锁，使用定时锁（超过时间就释放掉）等等 资源限制 一台1核1G的服务器，可能最多支持同时跑40个线程，超过这个限制，cpu就会陷入疯狂切换上下文，也就执行不了实际的任务。或者说网络带宽是1M/s, 开多少线程也顶多下载速度是1M/s。 资源限制解决方案两个方向一是从程序上减少资源的浪费二是增加资源 参考《java并发的艺术》方腾飞 魏鹏 程晓明 著]]></content>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql 字段定义后面的(20)]]></title>
    <url>%2F2019%2F12%2F03%2Fmysql%2Fmysql%20bigint(20)%2F</url>
    <content type="text"><![CDATA[字段定义后面的(20) 其实是宽度，并不是长度 bigint(20) 后面的20是宽度，不是长度 binint -&gt; varchar(20+) 是不影响数据的。]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql高性能优化]]></title>
    <url>%2F2019%2F12%2F03%2Fmysql%2Fmysql%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[mysql高性能优化的一些策略 mysql高性能优化 参考地址 what 什么是mysql性能优化 why 为什么要了解mysql性能优化 how 怎么做性能优化 what mysql性能优化是对mysqlcrud操作的优化。 why 对于并发量大，要求性能高的服务，性能优化是不得不做的。 how 查询流程图 优化哲学优化有风险，涉足需谨慎 优化可能带来的问题 优化本身就有风险，只不过是没有意识到 优化有时候不总是对一个单纯的环境进行修改，还可能是对一个复杂的生产环境 任何技术都可以解决一个问题，单必然存在带来另外一个问题的风险 保持现状或者是更差都是失败的优化 优化的需求 稳定性和业务可持续性，通常比性能更重要 优化就存在变更，变更就可能带来风险 优化要由业务驱使 优化思路 安全和性能 安全—&gt;数据可持续性 性能—&gt;数据的高性能访问 优化的维度 硬件《 系统 《 数据库《sql以及索引 基本优化思路 硬件-&gt;系统-&gt;应用-&gt;数据库-&gt;架构(高可用，读写分离，分库分表)]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之享元模式（flyweight）]]></title>
    <url>%2F2019%2F12%2F03%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E4%BA%AB%E5%85%83%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[享元模式（flyweight） 享元模式（flyweight） 场景 频繁的创建可复用对象，有性能，特别是内存造成一定的压力 角色 抽象享元类 具体享元类 享元工厂类 优点 解决场景锁带来的问题 缺点 加深系统的复杂度 享元对象存活时间过长。 举例： java里面的整型(-128-127全部是用的缓存，也可以变相的理解为享元模式)]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之外观模式]]></title>
    <url>%2F2019%2F12%2F03%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[外观模式 外观模式 场景 内部接口众多，client需要手动调用每个接口 角色 外观角色 子系统角色 优点 对使用方简单化，减少client处理的对象数目，并对子系统使用更加容易 缺点 因外观类整合了子系统类，使用缺乏一定的灵活性.]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之命令模式(command)]]></title>
    <url>%2F2019%2F12%2F03%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[命令模式(command) 命令模式(command) 场景 解耦调用者与被调用者，使二者不直接交互（类似代理模式） 角色 调用者 命令接口(command) 具体命令(xxcommand) 被调用者(receiver) 客户端(这个其实有些时候可以跟调用者合并) 优点 解耦接口调用者与被调用者之间关系 缺点 命令太多，会导致系统复杂]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之单例模式]]></title>
    <url>%2F2019%2F12%2F03%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[单例模式 单例模式 场景- 某个类智能有一个示例，提供一个全局的访问点 节省系统资源，提高系统效率，严格限制访问。]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之装饰模式]]></title>
    <url>%2F2019%2F12%2F03%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%A3%85%E9%A5%B0%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[装饰模式 装饰模式 场景 对已有模块进行额外的行为操作（增加或者是撤销） 当不能采用继承的方式对系统进行扩充或者采用继承不利于系统扩展和维护时。不能采用继承的情况主要有两类：第一类是系统中存在大量独立的扩展，为支持每一种组合将产生大量的子类，使得子类数目呈爆炸性增长；第二类是因为类定义不能继承（如final类）. 角色 抽象接口 装饰抽象类(implements 抽象接口) 抽象实现类(实现 抽象接口) 装饰实现类（实现 装饰抽象类） 优点 不需要多重继承，装饰灵活 装饰组合灵活 新增额外行为不会影响原有系统，符合开闭原则 缺点 在过程中会生成多个动态的子类，增加系统的开销以及复杂度 多种装饰器，排错比较麻烦。]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之观察者模式]]></title>
    <url>%2F2019%2F12%2F03%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[观察者模式(observer。。 publish|subscribe) 从属模式，model-View等 观察者模式(observer。。 publish|subscribe) 从属模式，model-View等 场景 当一个对象状态改变之后，需要通知其他对象进行相应的动作 角色 抽象观察者 具体观察者 抽象观察目标 具体观察目标 优点 联动/广播通信/消息传递 符合开闭原则 缺点 观察者只知道目标变化，而不知道具体什么变化 观察者众多，会导致系统复杂]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之桥接模式]]></title>
    <url>%2F2019%2F12%2F03%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[桥接模式 桥接模式 场景 系统需要在抽象化与具体话之间更加灵活，避免多个层次的有静态的继承关系，通过桥接模式，可以再抽象层建立一个连接 系统存在多个独立变化，且每个维度都需要独立的变化，并且有一定的关联使用(一般是这个) 角色 抽象类Abstraction（维护一个实现类接口） (也可以理解这里是个桥，连接了具体实现类) 扩充抽象类(扩充Abstraction的接口, extends Abstraction) 实现类接口 具体实现类 优点 抽象类与具体实现类解耦分类，避免了多层次继承导致的系统复杂度 独立各维度模块，单纯的改动任意模块都不会对之前的有所影响. 缺点 大部分桥接工作都是在抽象类中做的，会带来一定的系统理解复杂度 桥接模式最常解决的问题是多个独立维度的问题，所以使用该模式要对独立模式有很好的拆解]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之工厂模式汇总]]></title>
    <url>%2F2019%2F12%2F03%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[工厂模式汇总 工厂模式汇总 简单工厂，方法工厂，抽象工厂总结 工厂模式目的就是解耦 存在等级结构（抽象类），且产品之间有一定的联系，就可以使用抽象工厂。 如果不存在等级结构，或者是工厂生产的产品无联系，可以使用方法工厂。 简单工厂一般是知道了需要的产品是什么样子。 抽象工厂是方法工厂的高级模式。 各类模式关键点 简单工厂 场景 根据不同参数，返回不同类的实例。 就是常用的工厂函数 优点 使用者不需要知道实现细节，只需要相关的类就好 使用以及维护代码方便 缺点 对于工厂类，负担过重，如果有额外的逻辑，可能会导致工厂过于复杂。 违反“开闭原则”，一旦添加新产品就不得不修改逻辑 包含角色 工厂 抽象产品 具体产品 uml图 方法工厂 优点 更符合“开闭原则”，新产品，只需要新建工厂类以及产品类即可。 简单工厂是需要更改工厂逻辑 符合单一职责原则。每个工厂生产对应的产品 简单工厂工厂生成所有的产品 不使用静态工厂，可以形成基于继承的等级结构 简单工厂使用静态工厂 总的来说，方法工厂是简单工厂的扩展，让扩展更简单，继承可行。 缺点 每增加一个产品，就要生成一个工厂，增加编译运行，项目代码复杂度 单一工厂只能生产一种产品 场景 不知道所需要的类是什么（简单工厂反之） 类通过子类创建对象 角色 抽象工厂 工厂 抽象产品 产品 uml 抽象工厂 优点 继承方法工厂的优点，解决方法工厂工厂只能生产单一产品的缺点 增加等级机构。并且对工厂产生的产品进行约束(产品簇) 缺点 产品簇的扩展比较复杂。如果新增一种产品，可能需要改动所有的工厂 场景 相关的产品存在一定的联系，存在一定的等级结构，就可以用抽象工厂。 (这里可以用方法工厂模式，因为工厂模式各个产品不存在等级结构，且不存在相关的联系) 角色 抽象工厂(可以生产多个产品) 具体工厂类 抽象产品 具体产品 uml图]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之建造者模式]]></title>
    <url>%2F2019%2F12%2F03%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[建造者模式 建造者模式 优点 不必知道产品的组装细节，直接沟通领导者即可获得所需，将产品本身与产品的创建解耦，可以在相同的步骤创造不同产品对象 创造者之间各自独立 更有效的掌控产品的生产过程 新的创建者无需更改原有类，更加符合开闭原则 缺点 产品之间类似，创建的步骤基本一致. 如差异性很大，该模式就不太符合 todo 还有一点待理解 角色 指挥者(Director) 抽象建造者 具体建造者 产品 场景 产品内部有多个内部结构，多个变量属性 产品对象的属性之间有一定的依赖，要有一定的顺序生产 产品创建复杂，且创建过程可以创建其他的产品.]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之代理模式]]></title>
    <url>%2F2019%2F12%2F03%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[代理模式 代理模式 场景 对于客户端不想或者是不能直接引用一个对象，需要引进一个代理 代理大致种类 虚拟代理 将一个大的对象，先用一个小对象代替，具体使用时在生成，减小系统消耗 远程代理 对于不同地址空间提供个局域代理对象，就像是在对统一地址空间操作 保护代理 权限保护 角色 接口Subject 代理Proxy(实现Sunject) 具体实现类(SubjectImpl) 优点 协调调用者与被调用者，降低系统耦合度 缺点 因为有代理，可能会降低系统的性能 代理实现可能会比较复杂（特别低是动态代理）]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之适配器模式]]></title>
    <url>%2F2019%2F12%2F03%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[适配器模式 适配器模式 场景（目的） 把适配的类的api转换成目标的api 一般是对外接口通用适配对外接口 角色 抽象Adapter 抽象Target 具体Target(实际上是这里做了一个适配,调用了不同的具体Adapter) 具体Adapter 优点 使用灵活，对上层友好，符合开闭，支持不同的适配 缺点 需要引用对象实例.]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之工厂模式vs建造者模式]]></title>
    <url>%2F2019%2F12%2F03%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%B0%81%E4%B8%8E%E4%BA%89%E9%94%8B%2F%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8Fvs%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[工厂模式vs建造者模式 工厂模式vs建造者模式举例： 人分为大人，小孩。大人可以抽烟喝酒，小孩子只会玩泥巴。 从角色上看 工厂模式 工厂 抽象产品类 具体产品类 建造者模式 指挥者 抽象builder 具体builder 产品 对外部来讲 使用工厂，外部需要知道有哪些产品 使用建造者，外部不知道有什么产品，也不知道是谁来建造，全部由指挥者来决定生产什么东西。 其他差异 关注的颗粒度不同 工厂模式关注的是产品的整体 建造者可以的话，更关注的是产品实现的步骤，顺序组合等 如何取舍 如果是关注产品的实现的步骤，顺序组合等，建议使用建造者模式。反之建议使用工厂模式。]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之单一职责原则]]></title>
    <url>%2F2019%2F12%2F03%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E5%9F%BA%E6%9C%AC%E5%8E%9F%E5%88%99%2F%E5%8D%95%E4%B8%80%E8%81%8C%E8%B4%A3%E5%8E%9F%E5%88%99%2F</url>
    <content type="text"><![CDATA[单一职责原则 单一职责原则(single Responsibility Principle) There should no more than one reason for a class to change. This is sometimes hard to say. 在符合业务场景下，尽量的对模块做到：职能单一，行为单一。]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之接口隔离原则]]></title>
    <url>%2F2019%2F12%2F03%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E5%9F%BA%E6%9C%AC%E5%8E%9F%E5%88%99%2F%E6%8E%A5%E5%8F%A3%E9%9A%94%E7%A6%BB%E5%8E%9F%E5%88%99%2F</url>
    <content type="text"><![CDATA[接口隔离原则 接口隔离原则 Clients should not be force do depend upon interfaces that they don’t need. The dependency of one class to another one should depend on the smallest possible interface. 客户端不应该依赖不需要的接口 类之间的依赖关系应该是最小的接口上。 对接口的规范 接口尽量小(如果与lsp冲突，以lsp为准) 接口要高内聚(提高接口,类内部处理能力，减少对外的交互) 要明白接口设计是有限度的。 实践 一个接口只服务于一个子模块或者业务逻辑 通过业务逻辑压缩接口中的public 方法接口要时常回顾，尽量的精简 已经被污染的接口，尽量去修改，若有风险，使用适配器适配 一切从业务触发.]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之开闭原则]]></title>
    <url>%2F2019%2F12%2F03%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E5%9F%BA%E6%9C%AC%E5%8E%9F%E5%88%99%2F%E5%BC%80%E9%97%AD%E5%8E%9F%E5%88%99%2F</url>
    <content type="text"><![CDATA[开闭原则 开闭原则 Software entities likes classes,modules and fuctions should be open for extension but close for modifications. 软件实体例如类，模块，方法，都应该对拓展开放，对修改关闭. 设计原则中的精神领袖。包含的东西太多。 具体怎么用，可以参考其他五个原则。 注意： 开闭原则也只是个原则，最合适的一定是结合业务 项目规章很重要 预知变化]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之依赖倒置原则]]></title>
    <url>%2F2019%2F12%2F03%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E5%9F%BA%E6%9C%AC%E5%8E%9F%E5%88%99%2F%E4%BE%9D%E8%B5%96%E5%80%92%E7%BD%AE%E5%8E%9F%E5%88%99%2F</url>
    <content type="text"><![CDATA[依赖倒置原则 依赖倒置原则（dependecy inversion principle） High level modules should not depend upon law level modules. Both should depend upon abstraction modules. Abstraction shuold not depend upon detail. Detail should depend upon abstraction. 高层模块不应该依赖底层模块，两者都要依赖其抽象 抽象不能依赖细节 细节应该依赖抽象 依赖的三种方式 作为构造函数 setter 接口声明 注意 任何类都应该尽量有抽象类或者接口，或者二者都有 变量表面尽量是抽象或者接口 任何类都不应该从具体类派生 尽量不要覆盖父类的方法（因为后期维护是个问题） 与 LSP 结合]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之迪米特原则（least knowledge principle）]]></title>
    <url>%2F2019%2F12%2F03%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E5%9F%BA%E6%9C%AC%E5%8E%9F%E5%88%99%2F%E8%BF%AA%E7%B1%B3%E7%89%B9%E5%8E%9F%E5%88%99%2F</url>
    <content type="text"><![CDATA[迪米特原则 迪米特原则(law of demeter) (least knowledge principle) Only talk to your imediate friends(只跟你最近的朋友聊天) 朋友类：（出现在成员变量，方法输入输出的类都是朋友类） 原则： 只和朋友聊 朋友之间不易耦合不要太强 自己的就是自己的]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之里氏替换原则(Liskov Substitution Principle，LSP)]]></title>
    <url>%2F2019%2F12%2F03%2F%E6%9E%B6%E6%9E%84%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E5%9F%BA%E6%9C%AC%E5%8E%9F%E5%88%99%2F%E9%87%8C%E6%B0%8F%E6%9B%BF%E6%8D%A2%E5%8E%9F%E5%88%99%2F</url>
    <content type="text"><![CDATA[里氏替换原则(Liskov Substitution Principle，LSP) 里氏替换原则(Liskov Substitution Principle，LSP) If for each object 01 of type S there is a object 02 of type T such that for all program P define in terms of T, the behavior of P is unchanged where o1 substitude o2, then S is a subtype of T.(对于每一个类型是S的对象，存在一个类型为T的对象，使得以T定义的程序P所在的对象由o2替换为o1时，行为不发生任何变化。那么S就是T的子类) Function that use pointers or refererence to base classes must be able to use objects of derived classes without knowing it.(使用基类的地方必须能透明的使用子类) 子类必须完全实现所有父类的方法 子类可以有自己的特性 覆盖或者实现父类的方法的时参数可以被放大 （可以理解为父类的入参类型是子类入参的子类） 注意： 尽量的不要子类太过于个性化，以免后期维护复杂。]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java微服务]]></title>
    <url>%2F2019%2F12%2F03%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%2Fjava%E5%BE%AE%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[java微服务 的一些对比 java微服务 微服务 概念 一种架构模式，提倡将单一应用划分为一组小的服务，服务之间相互协调，相互配合 特点 独立部署 不需要因单一服务重新部署全部服务 技术选型灵活 去中心化 容错 会隔离到单独的服务 扩展 每个小服务都可以增加额外的扩展 复杂度可控 每个微服务功能可以单一 在分布式环境下，REST方式的服务依赖要比RPC方式的依赖更为灵活 Dubbo 弊端 调用方与提供方依赖性太强 Spring-boot. 弊端 rest比rpc 更轻，不存在各种强依赖。但是要统一管理好文档 可以通过整合swagger 使每个服务代码与文档一体化，解决上面的问题 比较 Dubbo Spring-boot 交互方式 定义DTO json 调用方式 rpc http 代码入侵 配置xml,无代码入侵 注解配置有代码入侵 依赖情况 调用方与提供方强依赖 无依赖，可跨平台 版本管理 要有完善的版本管理 省略了版本管理的问题，但是具体字段约定要统一管理 服务注册中心 Zookeeper redis Netflix Eureka 服务网关 无 Netflix Zuul 断路（熔断器） 暂不完善 Netflix Hystrix 配置中心 无 Spring-cloud config 调用链追踪 无 Spring Cloud Sleuth 消息总线 无 spring-cloud 数据流 无 Spring Cloud Stream 封装了与Redis,Rabbit、Kafka等发送接收消息 批量任务 无 Spring Cloud Task Dubbo只是实现了服务治理 SpringCloud子项目分别覆盖了微服务架构体系下的方方面面，服务治理只是其中的一个方面 Dubbo额外提供了Filter扩展，对于上述“暂无”的部分，都可以通过扩展Filter来完善]]></content>
      <tags>
        <tag>java</tag>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微服务之前后端分离]]></title>
    <url>%2F2019%2F12%2F03%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%2F%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E6%98%AF%E4%BB%80%E4%B9%88%2F</url>
    <content type="text"><![CDATA[什么是前后端分离，主要主要职责是什么 前后端分离 [参考地址]: http://blog.720ui.com/2016/arch_web_server/ 主要是为了分工明确，职责清晰，实现产品更快速 前端职责: 页面UI,展示，交互等 后端职责：数据储存，业务逻辑，restful接口，性能，可用性，伸缩性，扩展性，安全性等]]></content>
      <tags>
        <tag>java</tag>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 基础学习之final finally finalize 区别]]></title>
    <url>%2F2019%2F12%2F03%2Fjava%20%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%2Ffinal%20finally%20finalize%20%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[final finally finalize 区别 final finally finalize 区别 final (可以修饰 类 方法 变量) 修饰类 表示不允许继承 final类中所有的成员方法都会隐式的定义为final方法。 修饰方法 表示子类不能重写此方法 提高效率 锁定方法 修饰变量 final成员变量表示常量，只能被赋值一次，赋值后其值不再改变 finally(跟try…except连用) 不关有没有异常都会执行。 注意： 只有当执行的时候，并且没有发生 线程被kill,断电，退出虚拟机等情况(这些情况不会执行finally)，finally才会执行. 特殊 123456789101112131415161718private int testFinallyString(String str) &#123; try &#123; return str.charAt(0) - &apos;0&apos;; &#125; catch (NullPointerException e) &#123; return 1; &#125; catch (StringIndexOutOfBoundsException e) &#123; return 2; &#125; finally &#123; return 6; &#125;&#125;// 调用函数System.out.println(testFinallyString(null) + &quot; &quot; + testFinallyString(&quot;0&quot;) + &quot; &quot; + testFinallyString(&quot;&quot;));// 结果将会输出 6 6 6// 原因是因为 finally 特殊，会撤销之前的return. finalize(在java.lang.Object里定义的) 这个方法在gc启动，该对象被回收的时候被调用 跟析构函数不一样. 注意： 这个跟c++ 中的析构函数是不一样的。 c++ 调用delete 时候，对象就会被删除掉。 java 里面的调用gc，也不一定会及时删除。而是根据下一个删除动作才会删除]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 基础学习之JVM学习]]></title>
    <url>%2F2019%2F12%2F03%2Fjava%20%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%2Fjava%E8%99%9A%E6%8B%9F%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[JVM学习 JVM学习 [参考]: https://blog.csdn.net/xiangzhihong8/article/details/80412795 “比较详细” [参考2]: https://blog.csdn.net/u011546655/article/details/52175550 概念 又称为JVM. 通过在实际的计算机上仿真模拟各种计算机功能的虚拟计算机。 主要由字节码指令集，寄存器，栈，垃圾回收堆和存储方法域构成。 java 程序 与操作系统之间的翻译官 Java 程序编译后 生成.class文件. JVM针对不同的都有不同的解释器，所以只要针对系统中有相关的jvm，那么对应的编译后的程序就可以运行起来. — 一份代码多次运行. JVM 生命周期 JVM 随Java程序开始而开始，结束而停止。一个Java程序会开启一个JVM进程，一台计算机上可以运行多个程序===&gt; 多个JVM进程 JVM将线程分为：守护线程和普通线程两种。 守护线程： JVM自己使用的线程，比如GC(垃圾回收) 普通线程一般是Java程序的线程，只要JVM有普通线程在执行，JVM就不会停止. JVM 内存模型 堆和方法区是所有线程共有的，虚拟机栈和本地方法栈和程序计数器都是线程私有的。 堆内存（线程共享） 分为年轻代和老年代. 还有一个永久代在1.8之前存在，1.8(含)之后永久代被移除。 堆内存是内存优化中的一个重要内容。 方法区（线程共享） 存储已经被虚拟机加载的类信息,常量，静态变量，即时编译(JIT)后的代码等数据。 因为线程共享，所以方法区的信息，必须要保证线程安全。如果有两个线程同时加载一个类，只能一次加载一个。 运行时，方法区内存可变更（扩展以及回收）。方法区里面的对象也可以被回收，但必须是该类没有任何引用的情况，才可以被回收。 程序计数器 职责: 字节码解释器依赖程序计数器来选取下一条要执行的指令。分支，循环，跳转，异常处理，线程恢复等基础功能都需要依赖这个计数器来完成。 JVM多线程依赖线程轮流切换并分配处理器执行时间的方式来实现的,为了每个线程切换后都能够找到正确的下一条指令，所以每个线程都有一个独立的程序计数器 Java虚拟机栈 即通常所说的堆栈里面的栈，用于Java方法运行时候的内存模型。 Java虚拟栈运行过程：每个方法执行的时候都会创建一个栈帧(stack Frame)用于存储变量表(强类型，所以内存大小不会更改),操作，动态链接，方法出口等信息。每个方法从调用到出栈 的过程，就对用栈帧在虚拟机中从入栈到出栈的过程。 本地方法栈 Native Method java调用非java代码的接口。(本质上还是) 主要用于存储本地方法的局部变量表，本地方法的操作数栈等信息，超过作用域时，被自动释放掉 主要用于JVM调用本地方法接口(Native)。 类加载过程 Load 一，通过类的全限定名(java.package.class) 获取定义好的二进制字节流(这个应该是编译好的.class文件) 二，将字节流代表的静态存储结构转化为方法区的运行时的数据结构 三，在Java堆生成一个代表该类的java.lang.class对象,作为对方法区中这些数据的访问入口 注意： Load阶段是获取类的二进制类字节流的最佳阶段，开发既可以使用System类加载器，又可以使用自己的类加载器 Link 将Java中的二进制代码合并到JVM运行状态之中的过程 一， 验证： 确保被加载类正确 文件格式验证 验证字节流中是否符合class文件的规范。例如是否以OxCAFEBABE开头，主次版本号是否在当前虚拟机的处理范围之内，常量池中常量是否有不被包含支持的类型 元数据验证：对字节码描述的信息进行语义分析。保证其描述的信息与Java语言规范符合. 字节码验证：通过数据流和控制流分析，确定程序语义是合法的，符合逻辑的。 符号引用验证:确保解析动作能正确执行。 注意：验证很重要，但不是必须，对程序运行期没影响。由-Xverifynone参数。 二，准备：为类的静态变量分配内存，并将其初始化为初始值 这个时候分配内存仅是类变量(static),不是实例变量，实例变量会再对象实例化随对象一块分配在Java堆中. 这里的初始值为数据类型的零值(0, 0L, false, null等) 三，解析： 将类中相关符号引用转换为直接引用 Initialize 为类的静态变量设置正确的初始值 class加载器 Bootstap classLoader 负责加载$JAVA_HOME中 jre/lib/rt.jar 里所有的class或Xbootclassoath选项指定的jar包。由C++实现，不是ClassLoader子类。 Extension ClassLoader 负责加载java平台中扩展功能的一些jar包，包括$JAVA_HOME中jre/lib/*.jar 或 -Djava.ext.dirs指定目录下的jar包。 App classLoader 负责加载classpath中指定的jar包及 Djava.class.path 所指定目录下的类和jar包 Customer classLoader 通过java.lang.ClassLoader的子类自定义加载class，属于应用程序根据自身需要自定义的ClassLoader，如tomcat、jboss都会根据j2ee规范自行实现ClassLoader。]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 基础学习之反射的用途及实现&&简单的注解]]></title>
    <url>%2F2019%2F12%2F03%2Fjava%20%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%2F%E5%8F%8D%E5%B0%84%E7%9A%84%E7%94%A8%E9%80%94%E4%BB%A5%E5%8F%8A%E5%AE%9E%E7%8E%B0%26%26%E7%AE%80%E5%8D%95%E7%9A%84%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[反射的用途及实现&amp;&amp;简单的注解 反射的用途及实现&amp;&amp;简单的注解 反射基本概念 反射(reflection)是java的特征之一,允许java程序在运行中能够操作类或者对象内部相关属性(所属类，对象，变量以及方法)。 是运行时不是编译时 主要用途 google出来的都是开发通用框架 但是用的最多的应该利用注解以及反射实现一些通用的工具 反射中invoke过程 注解基本概念 放张网络图 [来源]: https://www.jianshu.com/p/83cff6b6971e {% asset_image 5618238-2e8f1e36d062f4d2.png %} 。 实现 下面是将同名对象copy, 并且根据不同的注解进行不同的处理 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879/*** 注解类**/@Target(value = &#123;ElementType.FIELD&#125;)@Retention(RetentionPolicy.RUNTIME)public @interface FieldsValidAnnotation &#123; // 将double * 100之后转换为Long boolean doubleMul100ToLong() default false; // 将double 转换为String boolean doubleToString() default false;&#125;/** * 转换两个变量name一样，但是不同类型的数据。 * * @param source 源变量 * @param target 目标变量 */public static void copyProties(final Object source, final Object target) &#123; if (source == null) &#123; return; &#125; Field[] fields = target.getClass().getDeclaredFields(); Method[] targetMethodList = target.getClass().getMethods(); for (Method targetMethod : targetMethodList) &#123; try &#123; // 不是set Func 就不 if (!targetMethod.getName().startsWith("set")) &#123; continue; &#125; String fieldName = targetMethod.getName().replaceFirst("set", ""); Field field = target.getClass().getDeclaredField(StringUtils.uncapitalize(fieldName)); field.setAccessible(true); Method sourceGetMethod = source.getClass() .getMethod("get" + fieldName, new Class[]&#123;&#125;); Object object = sourceGetMethod.invoke(source, new Object[]&#123;&#125;); object = realConvert(field, object); targetMethod.invoke(target, object); &#125; catch (Exception e) &#123; continue; &#125; &#125;&#125; /** * 注解. **/ private static Object realConvert(Field field, Object object) &#123; Annotation[] annotations = field.getAnnotations(); for (Annotation annotation : annotations) &#123; if (annotation.annotationType().getName().equals(FieldsValidAnnotation.class.getName())) &#123; if (((FieldsValidAnnotation) annotation).doubleMul100ToLong()) &#123; object = formatDigit(String.valueOf(object)); &#125; if (((FieldsValidAnnotation) annotation).doubleToString()) &#123; object = new BigDecimal(String.format("%.16f", object)).stripTrailingZeros().toString(); &#125; &#125; &#125; return object; &#125;]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 基础学习之抽象类与接口对比]]></title>
    <url>%2F2019%2F12%2F03%2Fjava%20%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%2F%E6%8A%BD%E8%B1%A1%E7%B1%BB%E4%B8%8E%E6%8E%A5%E5%8F%A3%E5%AF%B9%E6%AF%94%2F</url>
    <content type="text"><![CDATA[抽象类与接口对比 抽象类与接口对比 参数 抽象类 接口 默认的方法实现 可以有自己的 抽象函数，不存在实现 实现 extends implements 构造器 可以有 不能有 与正常java类 除了不可实例化，其他一样 完全不同 权限 private public protected 只能为public 多继承 子类一次只能继承一个抽象类 可以继承多个接口 速度 比接口快 接口要花时间找在类中实现的方法 添加新方法 不影响子类 子类必须要实现 如果是基本功能一直在改，直接用抽象类 如果是接口不变，或者多继承，使用抽象。]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 基础学习之Java.util.function 简单使用]]></title>
    <url>%2F2019%2F12%2F03%2Fjava%20%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%2FFunction%E7%AE%80%E5%8D%95%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Java.util.function 简单使用 Java.util.function 简单使用 有很多函数 Consumer 接受一个入参，无返回值。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@Datapublic class TestArgumentFunction &#123; private String a = "1"; private Integer b = 0; private Long c = 9L; private boolean d = true; @Test public void test() &#123; System.out.println("str " + getA()); setValue("bb ", this::setA); System.out.println("str " + getA()); System.out.println("In " + getB()); setValue(78, this::setB); System.out.println("In " + getB()); System.out.println("Lo " + getC()); setValue(78L, this::setC); System.out.println("Lo " + getC()); System.out.println("bo " + isD()); setValue(false, this::setD); System.out.println("bo " + isD()); /* result str 1 str bb In 0 In 78 Lo 9 Lo 78 bo true bo false */ &#125; public void set(String str, Consumer&lt;String&gt; function) &#123; function.accept(str); &#125; public void setA(String a) &#123; this.a = a; &#125; public String getA() &#123; return a; &#125; // 设置参数 private &lt;T&gt; void setValue(T value, Consumer&lt;T&gt; consumer) &#123; consumer.accept(value); &#125;&#125;]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 基础学习之int 与 Integer 区别]]></title>
    <url>%2F2019%2F12%2F03%2Fjava%20%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%2Fint%20%E4%B8%8EInteger%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[int 与 Integer 区别 int 与 Integer 区别 基本概念 java里面有基础类型和引用数据类型 (1）基本数据类型，分为boolean、byte、int、char、long、short、double、float； (2）引用数据类型 ，分为数组、类、接口。 为什么只提到了 int和Integer 因为Integer内部装箱做了一个额外的处理(用了缓存). 基本对比 Integer 是 int 的包装类，int 是基本数据类型. Integer 必须实例化才可以使用，int 可以直接赋值 Integer 实际是个类，所以是对象的引用，int是数据的存储 Integer 默认值为null, int 默认值为0. 并且int声明为0; 深入对比 Integer实际是对象，所以两个new的对象 是不等的(因为是new 内存地址不一样)。 123456789101112131415161718192021222324252627282930Integer i = new Integer(100);Integer j = new Integer(100);System.out.println(i == j); //false// ①注意：如果是-128到127直接的变量赋值，则 nteger b = 5; // 与 int b = 5; 一样Integer a = 5;Integer b = 5; // 与 int b = 5; 一样int c = 5;System.out.println(a == c); // trueSystem.out.println(a == b); // trueSystem.out.println(a.equals(b)); // true// ②如果是超过这个范围 那么结果就不一样了Integer a = 599999999;Integer b = 599999999;int c = 599999999;System.out.println(a == c); // trueSystem.out.println(a == b); // false 这个是false.System.out.println(a.equals(b)); // true// 出现①和②是因为  java在编译Integer a = 5 ;时，会翻译成为Integer a = Integer.valueOf(5)。而java API中对Integer类型的valueOf的定义如下，对于-128到127之间的数，会进行缓存，Integer a = 5 b = 5时，就会直接从缓存中取，就不会new了。见源码 public static Integer valueOf(int i) &#123; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); &#125;]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面向对象的特征与特性]]></title>
    <url>%2F2019%2F12%2F03%2Fjava%20%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%2F%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%9A%84%E7%89%B9%E5%BE%81%E4%B8%8E%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[面向对象的特征与特性 面向对象的特征与特性 特征（一般是表面） 封装 抽象 继承 多态 特性（一般是本质） 封装 继承 多态]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 基础学习之重载和重写的区别]]></title>
    <url>%2F2019%2F12%2F03%2Fjava%20%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%2F%E9%87%8D%E8%BD%BD%E5%92%8C%E9%87%8D%E5%86%99%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[重载和重写的区别 重载和重写的区别 重载(OverLoad)和重写(OverRiding) 本质上都是多态特性的实现. 重载是类统一调用方式。多个同名函数同时存在，但是有不同类型的入参(必须)和出参. 123456789101112131415@Testpublic void testOverLoad()&#123; System.out.println(testOL1()); // 1 System.out.println(testOL1(3));// 1.1 &#125; private Integer testOL1()&#123; return 1;&#125; private Double testOL1(Integer a)&#123; return 1.1;&#125; 重写(父子类之间的多态性) 对父类函数中的函数进行重新定义。 重写函数的入参（必须）和出参(必须)与父类函数一样. 子类重写函数权限不能少于父类的。]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flink之第一个Flink程序]]></title>
    <url>%2F2019%2F12%2F03%2FFlink%2FFlink-learning-in-action-1%2F</url>
    <content type="text"><![CDATA[通过本篇文章，帮助你通过使用Maven 快速实现官网demo. 环境 操作系统： mac java版本：1.8 Flink版本：1.7.2 scala版本：2.11 maven 版本:Apache Maven 3.5.2 描述输入为连续的单词，每5s对30s内的单词进行计数并输出。 使用Maven 创建项目12345678mvn archetype:generate \ -DarchetypeGroupId=org.apache.Flink \ -DarchetypeArtifactId=Flink-quickstart-java \ -DarchetypeVersion=1.7.2 \ -DgroupId=Flink-learning-in-action \ -DartifactId=Flink-learning-in-action \ -Dversion=0.1 \ -Dpackage=myFlink 运行成功之后会再当前目录下生成一个名为 Flink-learning-in-action的目录。目录结构 1234567891011$ tree Flink-learning-in-actionFlink-learning-in-action├── pom.xml└── src └── main ├── java │ └── myFlink │ ├── BatchJob.java │ └── StreamingJob.java └── resources └── log4j.properties 代码思想 获取运行环境 获取输入源 (socketTextStream) 对输入源进行算子操作 flatMap (拆分成单词，并给个默认值) keyby分组 timeWindow 划分时间窗口 reduce 对每一个窗口计算相同单词出现的次数 print 输出。 部分代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public class SocketWindowCount &#123; public static void main(String[] args) throws Exception &#123; ParameterTool parameterTool = ParameterTool.fromArgs(args); String host = parameterTool.get("host", "localhost"); int port = parameterTool.getInt("port", 9000); // 先初始化执行环境 StreamExecutionEnvironment environment = StreamExecutionEnvironment.getExecutionEnvironment(); // 设置并发度为1， 方便观察输出 environment.setParallelism(1); // 输入流 DataStreamSource&lt;String&gt; socketTextStream = environment.socketTextStream(host, port); // 对输入的数据进行拆分处理 DataStream&lt;Tuple2&lt;String, Long&gt;&gt; reduce = socketTextStream.flatMap(split2Word()) // 根据tuple2 中的第一个值分组 .keyBy(0) // 设置窗口，每 30s为一个窗口，每5s计算一次 .timeWindow(Time.seconds(30), Time.seconds(5)) // 计算 .reduce(CountReduce()); // 打印到控制台 输出时间 reduce.addSink(new RichSinkFunction&lt;Tuple2&lt;String, Long&gt;&gt;() &#123; @Override public void invoke(Tuple2&lt;String, Long&gt; value, Context context) &#123; System.out.println(now() + " word: " + value.f0 + " count: " + value.f1); &#125; &#125;); environment.execute("SocketWindowCount"); &#125; // 统计相同值出现的次数 private static ReduceFunction&lt;Tuple2&lt;String, Long&gt;&gt; CountReduce() &#123; return new ReduceFunction&lt;Tuple2&lt;String, Long&gt;&gt;() &#123; @Override public Tuple2&lt;String, Long&gt; reduce(Tuple2&lt;String, Long&gt; value1, Tuple2&lt;String, Long&gt; value2) throws Exception &#123; return new Tuple2&lt;&gt;(value1.f0, value1.f1 + value2.f1); &#125; &#125;; &#125; // 将输入的一行 分割成单词，并初始化次数为1 private static FlatMapFunction&lt;String, Tuple2&lt;String, Long&gt;&gt; split2Word() &#123; return new FlatMapFunction&lt;String, Tuple2&lt;String, Long&gt;&gt;() &#123; @Override public void flatMap(String value, Collector&lt;Tuple2&lt;String, Long&gt;&gt; out) throws Exception &#123; String[] words = value.split("\\W"); for (String word : words) &#123; if (word.length() &gt; 0) &#123; out.collect(new Tuple2&lt;&gt;(word, 1L)); &#125; &#125; &#125; &#125;; &#125;&#125; 运行1 打开终端执行 1nc -l 9000 2 运行代码。 结果: 完整代码完整代码 参考资料java_api_quickstart]]></content>
      <categories>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-data-jpa多源配置 隐式命名规则（驼峰转蛇形）失效 解决]]></title>
    <url>%2F2019%2F12%2F03%2FspringBoot%2Fspring-data-jpa%E5%A4%9A%E6%BA%90%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[spring-data-jpa多源配置 隐式命名规则（驼峰转蛇形）失效 解决 spring-data-jpa多源配置 隐式命名规则（驼峰转蛇形）失效 Q 配置好多源之后，隐式命名策略失效 A 要单独写一个配置JpaProperties的函数，在生成LocalContainerEntityManagerFactoryBean的时候，初始化12345678910111213141516171819202122232425//注入JPA配置实体@Autowiredprivate JpaProperties jpaProperties;//获取jpa配置信息private Map&lt;String, String&gt; getVendorProperties(DataSource dataSource) &#123; // 添加自己要选择的命名策略 jpaProperties.getHibernate().getNaming().setPhysicalStrategy("org.springframework.boot.orm.jpa.hibernate.SpringPhysicalNamingStrategy"); return jpaProperties.getHibernateProperties(dataSource);&#125;@Primary@Bean(name = "entityManagerFactorySpiderShard")public LocalContainerEntityManagerFactoryBean entityManagerFactorySpiderSharding( EntityManagerFactoryBuilder builder) &#123; return builder .dataSource(primaryDataSource) .packages("xx") // 在这里初始化每个源自己的命名规则 .properties(getVendorProperties(primaryDataSource)) .persistenceUnit("spiderShardPersistenceUnit") .build();&#125;]]></content>
      <tags>
        <tag>java</tag>
        <tag>spring boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 简单了解]]></title>
    <url>%2F2019%2F12%2F03%2FspringBoot%2F%E7%AE%80%E5%8D%95%E4%BA%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Spring Boot 简单了解 Spring Boot结构 spring-boot 提供Application类，便捷启动，以及刷新ApplicationContext 嵌套可选择性Web服务容器 外部配置 让ApplicationContext初始化配置更为方便，包括日志等 spring-boot-autoconfigure 自动注入 spring-boot-starters 三方包支持 spring-boot-cli spring-boot 终端命令 spring-boot-actuator 提供自身以及监控功能 spring-boot-actuator-autoconfigure spring-boot-actuator相关自动注入 spring-boot-test spring-boot 测试 spring-boot-test-autoconfigure 自动配置 spring-boot-loader 我理解是单元化测试加载相关项目 spring-boot-devtools 运维相关工具 个人理解1spring-boot 是spring 全家桶的易上手版，其中的自动注入，以及starters都是蛮好的思想，主要可以看这两个，其他的还是要看下spring相关的源码设计。 大佬的面试总结 梁桂钊 链接]]></content>
      <tags>
        <tag>java</tag>
        <tag>spring boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-boot 运行源码分析]]></title>
    <url>%2F2019%2F12%2F03%2FspringBoot%2Fspring-boot%2F</url>
    <content type="text"><![CDATA[spring-boot 运行源码分析 spring-boot 一个简单的demo。 1234567891011@SpringBootApplicationpublic class Main &#123; public static void main(String[] args) &#123; // 主要运行类 SpringApplication.run(Main.class, args); &#125;&#125; 可以看到源码 12345public static ConfigurableApplicationContext run(Object[] sources, String[] args) &#123; // 加载资源， // 再运行. return new SpringApplication(sources).run(args);&#125; 初始化资源 1234public SpringApplication(Object... sources) &#123; // 初始化资源。 initialize(sources);&#125; 1234567891011121314151617181920// 加载资源。主要初始化上下文，以及监听器@SuppressWarnings(&#123; &quot;unchecked&quot;, &quot;rawtypes&quot; &#125;)private void initialize(Object[] sources) &#123; if (sources != null &amp;&amp; sources.length &gt; 0) &#123; this.sources.addAll(Arrays.asList(sources)); &#125; // deduceWebEnvironment 判断是不是web环境 this.webEnvironment = deduceWebEnvironment(); // 获取ContextInitializer 应用程序初始化器 /* getSpringFactoriesInstances  会读取spring-core-xxx . META-INF 中的spring.factory中的文件。 */ setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); // listener 应用程序监听器 setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); // 找出main类，这里是MyApplication类 this.mainApplicationClass = deduceMainApplicationClass();&#125; spring.factory 主要包含了以下几个。1234567891011121314151617# PropertySource Loadersorg.springframework.boot.env.PropertySourceLoader# Failure Analyzersorg.springframework.boot.diagnostics.FailureAnalyzer# Run Listenersorg.springframework.boot.SpringApplicationRunListener# Environment Post Processorsorg.springframework.boot.env.EnvironmentPostProcessor# Application Listenersorg.springframework.context.ApplicationListener=# FailureAnalysisReportersorg.springframework.boot.diagnostics.FailureAnalysisReporter=]]></content>
      <tags>
        <tag>java</tag>
        <tag>spring boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[thread-state]]></title>
    <url>%2F2019%2F11%2F25%2Fjava%2Fthread-state%2F</url>
    <content type="text"><![CDATA[本文章介绍 Java Thread State各种状态.通过本篇文章你可以了解到：1 Java 线程中都有哪些状态2 这些状态之间的联系是怎样的3 使用jstack查看运行中的线程状态 Java 线程中的状态其实只要看下Thread.State源码就可以知道有几种类型了 1234567891011121314151617181920212223242526272829303132333435363738394041424344public enum State &#123; /** * 初始状态。线程刚创建，还没有调用start() */ NEW, /** * 正在运行的状态（java 将系统中的Ready和运行都笼统的成为运行中）。正在运行的线程有可能处于等待状态。例如等待系统io */ RUNNABLE, /** * 阻塞状态。等待锁的释放 */ BLOCKED, /** * 等待状态 * 线程变为等待状态，分为下面三种情况 * 1 Object.wait() 并且没有timeout参数 * 2 Thread.join 没有timeout参数 * 3 LockSupport.park() * 例如： * 一个线程调用了Object.wait(). 直到另外的线程调用了该Object.notify()或者是Object.notify()方法才会解除waiting状态。 */ WAITING, /** * 超时等待状态。等待一定时间后，自动释放该状态 * 例如：调用了下面的函数并有时间相关参数 * &lt;li&gt;&#123;@link #sleep Thread.sleep&#125;&lt;/li&gt; * &lt;li&gt;&#123;@link Object#wait(long) Object.wait&#125; with timeout&lt;/li&gt; * &lt;li&gt;&#123;@link #join(long) Thread.join&#125; with timeout&lt;/li&gt; * &lt;li&gt;&#123;@link LockSupport#parkNanos LockSupport.parkNanos&#125;&lt;/li&gt; * &lt;li&gt;&#123;@link LockSupport#parkUntil LockSupport.parkUntil&#125;&lt;/li&gt; * &lt;/ul&gt; */ TIMED_WAITING, /** * 线程终止状态 */ TERMINATED; &#125; 这些状态之间的联系是怎样的具体见下图（图源《Java 并发编程艺术》4.1.4节） 从上图可以到 1 初始化线程状态表示为New. 调用Thread.start()转换状态为RUNNABLE 2 调用Object.wait()/Object.join()/LockSupport.park会由RUNNABLE转换为WAITING转态。调用Object.notify()/Object.notifyAll()/LockSupport.unpark()才会由，WAITING转为RUNABLE 3 调用Thread.sleep(long)/Object.wait(long)/Thread.join(long)/LockSupport.pardNanos(long)/LockSupport.parkUntil(long) 由 RUNNABLE-&gt; TIMED_WAITING 反之通过Object.notify()/Object.notifyAll()/LockSupport.unpark()才会由，TIMED_WAITING转为RUNABLE 4 在调用synchronized函数时候，未获取到锁，会变为BLOCKED。 获取到之后即变为RUNNABLE 5 执行完成之后转换为TERMINATED 使用jstack查看运行中的线程状态 NEW 1234567@Testpublic void testNew() &#123; Thread thread = new Thread(); System.out.println(thread.getState()); // NEW&#125; RUNNABEL &amp;&amp; WAITING 1234567891011121314@Testpublic void testRunnable() throws InterruptedException &#123; Thread testRunnable = new Thread(new Runnable() &#123; @Override public void run() &#123; for (int i = 0; i &lt; Integer.MAX_VALUE; i++) &#123; System.out.println(i); &#125; &#125; &#125;, &quot;testRunnable&quot;); testRunnable.start(); testRunnable.join();&#125; testRunnable 线程是在运行 main此时状态为WAITING. 因为调用了thread.join函数 BLOCKED &amp;&amp; WAITING 123456789101112131415161718192021222324252627282930313233343536373839public static void main(String[] args)&#123; final Object lock = new Object(); Thread waitingA = new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (lock) &#123; try &#123; Thread.sleep(20000); System.out.println(&quot;waiting&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;, &quot;waitingA&quot;); Thread waitingB = new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (lock) &#123; try &#123; Thread.sleep(20000); System.out.println(&quot;waiting&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;, &quot;waitingB&quot;); waitingA.start(); waitingB.start();&#125; 可以看下图中 A TIMED_WAITING B因为A获取到了lock，而为BLOCKED状态]]></content>
      <tags>
        <tag>java, Thread-State</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[==equals]]></title>
    <url>%2F2019%2F11%2F25%2Fjava%20%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%2Fequal%2F</url>
    <content type="text"><![CDATA[通过本篇文章，你可以了解到 == 与equals的区别 == 比较的是 地址。 如果是基础类型就比较值。如果是对象就比较地址 equals() : 它的作用也是判断两个对象是否相等。但它一般有两种使用情况：情况1：类没有覆盖 equals() 方法。则通过 equals() 比较该类的两个对象时，等价于通过“==”比较这两个对象。情况2：类覆盖了 equals() 方法。一般，我们都覆盖 equals() 方法来比较两个对象的内容是否相等；若它们的内容相等，则返回 true (即，认为这两个对象相等)。 举个栗子 1234567891011121314151617public class test1 &#123; public static void main(String[] args) &#123; String a = new String(&quot;ab&quot;); // a 为一个引用 String b = new String(&quot;ab&quot;); // b为另一个引用,对象的内容一样 String aa = &quot;ab&quot;; // 放在常量池中 String bb = &quot;ab&quot;; // 从常量池中查找 if (aa == bb) // true System.out.println(&quot;aa==bb&quot;); if (a == b) // false，非同一对象 System.out.println(&quot;a==b&quot;); if (a.equals(b)) // true System.out.println(&quot;aEQb&quot;); if (42 == 42.0) &#123; // true System.out.println(&quot;true&quot;); &#125; &#125;&#125;]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA String vs StringBuffer vs StringBuilder]]></title>
    <url>%2F2019%2F11%2F25%2Fjava%20%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%2Fstring-stringbuilder-stringbuffer%2F</url>
    <content type="text"><![CDATA[通过本篇文章，你可以了解到StringBuffer与StringBuilder的区别。 String 不可变内部数据是由final 修饰的 1234public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123; /** The value is used for character storage. */ private final char value[]; StringBuffer vs StringBuilder 均可变StringBuffer 和 StringBuilder 都是继承AbstractStringBuilder。 12345678910abstract class AbstractStringBuilder implements Appendable, CharSequence &#123; /** * The value is used for character storage. */ char[] value; /** * The count is the number of characters used. */ int count; 线程安全性 StringBuffer 是线程安全的 使用synchronized 修饰了函数 StringBuilder 没有用synchronized修饰,是非线程安全的 数据修改 StringBuffer 每次都是对原有对象的引用修改 1234567@Overridepublic synchronized String toString() &#123; if (toStringCache == null) &#123; toStringCache = Arrays.copyOfRange(value, 0, count); &#125; return new String(toStringCache, true);&#125; StringBuilder 每次都是创建一个新的对象 12345@Overridepublic String toString() &#123; // Create a copy, don&apos;t share the array return new String(value, 0, count);&#125; 性能 相比之下 StringBuilder要比StringBuffer快，但是有线程不安全]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[同步，异步，阻塞，非阻塞]]></title>
    <url>%2F2019%2F11%2F12%2Fblock-non%2F</url>
    <content type="text"><![CDATA[同步，异步，阻塞，非阻塞是日常开发中经常聊的，但是真正说起来什么是这些东西的时候，还是有点绕. so 找找资料记录下. 重要 阻塞和非阻塞描述的是调用方。 同步与异步描述的是被调用方 以高科技钓鱼， 鱼咬钩之后会报警为例。 A调用B 阻塞抛竿之后，就一直看着鱼竿等着鱼咬钩A调用B，A一直等着B返回，在这期间A啥也不干 非阻塞抛竿之后，开始玩手机，不需要一直看鱼竿A调用B， A不用等着B,可以先忙着其他。 同步鱼咬钩,告警器才亮A调用B, B结束了之后才给A返回 异步鱼竿抛出之后，鱼没有咬钩，但是告警器可以闪烁A调用B, B先给A返回我收到了，等B结束之后再通过其他方式通知A（回调） 参考 漫话编程文章]]></content>
      <tags>
        <tag>概念</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[io模型]]></title>
    <url>%2F2019%2F11%2F12%2Fio-model%2F</url>
    <content type="text"><![CDATA[并发处理，对于各种io模型还是需要掌握的。 建议直接看最后面的链接，图文并茂理解更佳。 前提io其实就是输入输出. 就是平时的文件读取，或者是网络爬虫抓取页面（socket io）. 举例读取文件：将文件从磁盘读取到内存中，然后再从内存中读取到用户空间中 以钓鱼为例,拆分为抛竿，鱼咬钩，拉起三个操作 阻塞io 抛竿之后等着鱼咬钩然后再拉起 非阻塞io 抛竿之后，边玩手机边看鱼咬钩，然后再拉起 I/O复用 一次性抛多个鱼竿，挨个检查各个鱼竿有没有咬钩，咬钩了就拉起 信号驱动IO 鱼竿上面有个报警器，抛竿之后，一直玩手机，直到鱼咬钩触发了报警，然后再拉起 异步IO 抛竿之后，干其他的，鱼咬钩之后自动拉起，然后再通知你 参考 漫话编程]]></content>
      <tags>
        <tag>io</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop-hbase-zookeeper]]></title>
    <url>%2F2019%2F11%2F02%2Fhadoop%2Fhadoop-hbase-zookeeper%2F</url>
    <content type="text"><![CDATA[大数据开发，hadoop,hbase 环境搭建肯定是必不可少少了。之前已经把hadoop搞清楚了，但是直到今天才把Hbase搭建成功（虽然中间还是有点瑕疵），记录下相关的操作. 系统相关配置 三台机器centos7(master(10.211.55.20), slave1(10.211.55.21), slave2(10.211.55.22)) java 1.8 hadoop 2.7.2 hbase 1.4.9 zookeeper 3.4.14 各节点功能 节点/hostname 服务 master/10.211.55.20 DataNode JournalNodeNodeManagerQuorumPeerMainHRegionServerNameNodeJpsHMaster slave1/10.211.55.21 JournalNode ResourceManager NodeManager HRegionServerQuorumPeerMain NameNode slave2/10.211.55.22 JournalNodeHRegionServerNodeManagerDataNodeQuorumPeerMain 预先配置 用户(hadoop) 在三台机器上创建hadoop用户（之后的操作都是在用户hadoop下操作的） 1useradd hadoop 开启免密登录 1234# 在三台机器上分别执行ssh-copy-id 10.211.55.20ssh-copy-id 10.211.55.21ssh-copy-id 10.211.55.22 下载相关安装包到/home/hadoop（我们的安装目录）下面，解压，此时的目录下为 12345hadoop@master [04:47:44 PM] [~/hadoop-2.7.2]-&gt; % lsbin lib logs sbinetc libexec NOTICE.txt shareinclude LICENSE.txt README.txt tmp 配置java文件 将下面的几句话添加到.bashrc中(因为我用的是zsh,所以是.zshrc), 三台机器都需要配置 1234# jdk1.8export JAVA_HOME=/home/hadoop/jdk1.8export PATH=$JAVA_HOME/bin:$PATHexport CLASS_PATH=$JAVA_HOME/lib 添加完之后，记得source .bashrc 或者是source .zshrc 关闭三台机器的防火墙,分别登录到三台机器上执行 1234567891011121314151617# 关闭防火墙sudo systemctl stop firewalld.service# 开机关闭防火墙sudo systemctl disable firewalld.service## 验证是否关闭成功sudo systemctl status firewalld.service ## 执行上面的命令后，出现下面的日志即表示已经关闭防火墙了● firewalld.service - firewalld - dynamic firewall daemon Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled; vendor preset: enabled) Active: inactive (dead) Docs: man:firewalld(1)Nov 01 06:54:04 slave1 systemd[1]: Starting fir...Nov 01 06:54:05 slave1 systemd[1]: Started fire...Nov 01 07:38:19 slave1 systemd[1]: Stopping fir...Nov 01 07:38:20 slave1 systemd[1]: Stopped fire...Hint: Some lines were ellipsized, use -l to show in full. zookeeper 在 master(10.211.55.20上) 12cd /home/hadoop/zookeeper-3.4.14/confmv zoo_sample.cfg zoo.cfg 将下面的东西复制进zoo.cfg 删除原来的配置 12345678910111213141516171819202122232425262728293031# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial# synchronization phase can takeinitLimit=10# The number of ticks that can pass between# sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just# example sakes.dataDir=/home/hadoop/zookeeper-3.4.14/data/zkdata# the port at which the clients will connectclientPort=2181# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the# administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to &quot;0&quot; to disable auto purge feature#autopurge.purgeInterval=1server.1=master:2888:3888server.2=slave1:2888:3888server.3=slave2:2888:3888 创建zookeeper 数据保存文件夹 123mkdir -p /home/hadoop/zookeeper-3.4.14/data/zkdatacd /home/hadoop/zookeeper-3.4.14/data/zkdataecho &quot;1&quot; &gt; myid 将master机器上改过之后的zookeeper 文件夹发送到slave1以及slave2机器上 ​ 123cd ~scp -r zookeeper-3.4.14 10.211.55.21:/home/hadoopscp -r zookeeper-3.4.14 10.211.55.22:/home/hadoop 登录到slave1 1echo &quot;2&quot; /home/hadoop/zookeeper-3.4.14/data/zkdata/myid 登录到slave2 1echo &quot;2&quot; /home/hadoop/zookeeper-3.4.14/data/zkdata/myid 分别登录上三台机器执行下面命令，启动zookeeper集群 12cd /home/hadoop/zookeeper-3.4.14./bin/zkServer.sh start 启动成功之后，检测三台机器状态(因zookeeper内部选取机制，所以下面的leader与fellower仅供参考，并不一定是下面的情况) 1234567891011121314151617hadoop@master [04:48:24 PM] [~/zookeeper-3.4.14]-&gt; % ./bin/zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /home/hadoop/zookeeper-3.4.14/bin/../conf/zoo.cfgMode: followerhadoop@slave1 [04:49:18 PM] [~/zookeeper-3.4.14]-&gt; % ./bin/zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /home/hadoop/zookeeper-3.4.14/bin/../conf/zoo.cfgMode: leaderhadoop@slave2 [04:49:24 PM] [~/zookeeper-3.4.14]-&gt; % ./bin/zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /home/hadoop/zookeeper-3.4.14/bin/../conf/zoo.cfgMode: follower hadoop 修改配置(下面的操作都是在/home/hadoop/hadoop-2.7.2/etc/hadoop目录下面进行修改) 修改hadoop-env.sh 12# 找到JAVA_HOME 修改为export JAVA_HOME=/home/hadoop/jdk1.8 vi core-site.xml 12345678910111213141516171819&lt;configuration&gt; &lt;!-- hdfs地址，ha模式中是连接到nameservice --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://ns1&lt;/value&gt; &lt;/property&gt; &lt;!-- 这里的路径默认是NameNode、DataNode、JournalNode等存放数据的公共目录，也可以单独指定 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/home/hadoop/hadoop-2.7.2/tmp&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定ZooKeeper集群的地址和端口。注意，数量一定是奇数，且不少于三个节点--&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;master:2181,slave1:2181,slave2:2181&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; vi hdfs-site.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485&lt;configuration&gt; &lt;!-- 指定副本数，不能超过机器节点数 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt; &lt;!-- 为namenode集群定义一个services name --&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;ns1&lt;/value&gt; &lt;/property&gt; &lt;!-- nameservice 包含哪些namenode，为各个namenode起名 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.ns1&lt;/name&gt; &lt;value&gt;master,slave1&lt;/value&gt; &lt;/property&gt; &lt;!-- 名为master的namenode的rpc地址和端口号，rpc用来和datanode通讯 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.ns1.master&lt;/name&gt; &lt;value&gt;master:9000&lt;/value&gt; &lt;/property&gt; &lt;!-- 名为slave1的namenode的rpc地址和端口号，rpc用来和datanode通讯 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.ns1.slave1&lt;/name&gt; &lt;value&gt;slave1:9000&lt;/value&gt; &lt;/property&gt; &lt;!--名为master的namenode的http地址和端口号，用来和web客户端通讯 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.ns1.master&lt;/name&gt; &lt;value&gt;master:50070&lt;/value&gt; &lt;/property&gt; &lt;!-- 名为slave1的namenode的http地址和端口号，用来和web客户端通讯 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.ns1.slave1&lt;/name&gt; &lt;value&gt;slave1:50070&lt;/value&gt; &lt;/property&gt; &lt;!-- namenode间用于共享编辑日志的journal节点列表 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://master:8485;slave1:8485;slave2:8485/ns1&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定该集群出现故障时，是否自动切换到另一台namenode --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled.ns1&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- journalnode 上用于存放edits日志的目录 --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;/home/hadoop/hadoop-2.7.2/tmp/data/dfs/journalnode&lt;/value&gt; &lt;/property&gt; &lt;!-- 客户端连接可用状态的NameNode所用的代理类 --&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.ns1&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt; &lt;/property&gt; &lt;!-- 一旦需要NameNode切换，使用ssh方式进行操作 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;sshfence&lt;/value&gt; &lt;/property&gt; &lt;!-- 如果使用ssh进行故障切换，使用ssh通信时用的密钥存储的位置 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt; &lt;value&gt;/home/hadoop/.ssh/id_rsa&lt;/value&gt; &lt;/property&gt; &lt;!-- connect-timeout超时时间 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;/name&gt; &lt;value&gt;30000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; vi mapred-site.xml 1234567&lt;!-- 采用yarn作为mapreduce的资源调度框架 --&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; vi yarn-site.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;configuration&gt; &lt;!-- 启用HA高可用性 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定resourcemanager的名字 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt; &lt;value&gt;yrc&lt;/value&gt; &lt;/property&gt; &lt;!-- 使用了2个resourcemanager,分别指定Resourcemanager的地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt; &lt;value&gt;rm1,rm2&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定rm1的地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt; &lt;value&gt;master&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定rm2的地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt; &lt;value&gt;slave1&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定当前机器master作为rm1 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.id&lt;/name&gt; &lt;value&gt;rm1&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定zookeeper集群机器 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt; &lt;value&gt;master:2181,slave1:2181,slave2:2181&lt;/value&gt; &lt;/property&gt; &lt;!-- NodeManager上运行的附属服务，默认是mapreduce_shuffle --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; vi slaves(删除localhost) 123masterslave1slave2 将修改后的文件夹发送到其他两台机器 123cd ~scp -r hadoop-2.7.2 10.211.55.21:/home/hadoopscp -r hadoop-2.7.2 10.211.55.22:/home/hadoop 登录到slave1 修改/etc/hadoop/yarn-site.xml 1234&lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.id&lt;/name&gt; &lt;value&gt;rm2&lt;/value&gt;&lt;/property&gt; 登录到slave2 。 对/etc/hadoop/yarn-site.xml删除上面的键值对 初始化 在三台机器上使用命令启动journalnode 12cd /home/hadoop/hadoop-2.7.2./sbin/hadoop-daemon.sh start journalnode 在master机器上执行 123cd /home/hadoop/hadoop-2.7.2./bin/hdfs namenode -format./hdfs zkfc -formatZK 这个时候目录在目录上会出现一个tmp目录(/home/hadoop/hadoop-2.7.2/tmp) 将该目录发送到slave1,/home/hadoop/hadoop-2.7.2文件夹中 1scp -r tmp 10.211.55.21:/home/hadoop/hadoop-2.7.2 在slave1 机器上执行 12cd /home/hadoop/hadoop-2.7.2./bin/hdfs namenode -bootstrapStanby 在maser机器上启动hadoop集群 123cd /home/hadoop/hadoop-2.7.2./sbin/start-dfs.sh./sbin/start-yarn.sh 如果正常启动成功，那么在master执行jps,会出现 12345624624 DataNode24179 JournalNode25075 NodeManager25977 NameNode1147 Jps24974 ResourceManager hbase 登录到master,进入目录hbase配置目录 1cd /home/hadoop/hbase-1.4.9/conf vim hbase-env.sh 12345678//配置JDKexport JAVA_HOME=/opt/jdk//配置hbase 启动进程idexport HBASE_PID_DIR=/home/hadoop/hbase-1.4.9/pids//不用自带的zkexport HBASE_MANAGES_ZK=false vi hbase-site.xml 12345678910111213141516171819202122232425262728293031323334353637&lt;configuration&gt; &lt;!-- 设置HRegionServers共享目录，请加上端口号 --&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://master:9000/hbase&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定HMaster主机 --&gt; &lt;property&gt; &lt;name&gt;hbase.master&lt;/name&gt; &lt;value&gt;hdfs://master:60000&lt;/value&gt; &lt;/property&gt; &lt;!-- 启用分布式模式 --&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定Zookeeper集群位置 --&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;master:2181,slave1:2181,slave2:2181&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定独立Zookeeper安装路径 --&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt; &lt;value&gt;/home/hadoop/zookeeper-3.4.14&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定ZooKeeper集群端口 --&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt; &lt;value&gt;2181&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; vi regionservers 123masterslave1slave2 创建pids 1mkdir -p /home/hadoop/hbase-1.4.9/pids 将hbase发送到其他机器上 123cd ~scp -r hbase-1.4.9 10.211.55.21:/home/hadoopscp -r hbase-1.4.9 10.211.55.22:/home/hadoop 启动hbase 12cd /home/hadoop/hbase-1.4.9./bin/start-hbase.sh 如果启动成功，执行hbase shell 出现下面提示，即表示成功. 12345678-&gt; % ./bin/hbase shell2019-11-01 16:37:41,780 WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicableHBase ShellUse &quot;help&quot; to get list of supported commands.Use &quot;exit&quot; to quit this interactive shell.Version 1.4.9, rd625b212e46d01cb17db9ac2e9e927fdb201afa1, Wed Dec 5 11:54:10 PST 2018hbase(main):001:0&gt; 注意 如果hadoop namenode 全部是standy,需要手动指定active （master机器） 12cd /home/hadoop/hadoop-2.7.2./bin/hdfs haadmin -transitionToActive --forcemanual master 参考（都是大佬啊）]]></content>
      <tags>
        <tag>hadoop</tag>
        <tag>hbase</tag>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[network-programming-foundation]]></title>
    <url>%2F2019%2F08%2F01%2Fnetwork-programming-foundation%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[scrapy(2)之执行分析]]></title>
    <url>%2F2019%2F07%2F17%2Fpython%2Fscrapy-2%2F</url>
    <content type="text"><![CDATA[根据之前写的scrapy-1,我们分析到了初始化引擎。下面就实际运行是如何运行的。 scapy.crawler.Crawler.crawl 主要工作 实例化spider （这个源码就跳过了，就是简单的创建spider实例，并将参数设置好） 实例化engine (下面详细讲下)1234567891011121314151617181920212223242526272829303132@defer.inlineCallbacksdef crawl(self, *args, **kwargs): assert not self.crawling, &quot;Crawling already taking place&quot; self.crawling = True try: self.spider = self._create_spider(*args, **kwargs) ## 这个就是实例化了一个scrapy.core.engine.ExecutionEngine类 self.engine = self._create_engine() # 这里就是从自定义的start_url里面读取url,并封装成 scrapy.http.request.Request实例 start_requests = iter(self.spider.start_requests()) yield self.engine.open_spider(self.spider, start_requests) yield defer.maybeDeferred(self.engine.start) except Exception: # In Python 2 reraising an exception after yield discards # the original traceback (see https://bugs.python.org/issue7563), # so sys.exc_info() workaround is used. # This workaround also works in Python 3, but it is not needed, # and it is slower, so in Python 3 we use native `raise`. if six.PY2: exc_info = sys.exc_info() self.crawling = False if self.engine is not None: yield self.engine.close() if six.PY2: six.reraise(*exc_info) raisedef _create_engine(self): return ExecutionEngine(self, lambda _: self.stop()) 这个函数在creat_engine之后，调用了open_spider函数。 scrapy.core.engine.ExecutionEngine.open_spider 主要做了以下动作 将_next_request 注册到twisted 实例化调度器 中间件封装start_request 将事件，start_reqeusts,调度器封装成slot 并将其设置为实例属性 调用scheduler.open函数，初始化去重过滤器中间件（默认是DUPEFILTER_CLASS = ‘scrapy.dupefilters.RFPDupeFilter’） 调用scraper.open_spider(spider) 生成pipline slot.nextcall.schedule() 这个是调用前面注册成CallLaterOnce的_next_request函数。 123456789101112131415161718192021@defer.inlineCallbacks def open_spider(self, spider, start_requests=(), close_if_idle=True): assert self.has_capacity(), &quot;No free spider slot when opening %r&quot; % \ spider.name logger.info(&quot;Spider opened&quot;, extra=&#123;&apos;spider&apos;: spider&#125;) ## 这里是将_next_requests 注册到了twisted nextcall = CallLaterOnce(self._next_request, spider) scheduler = self.scheduler_cls.from_crawler(self.crawler) start_requests = yield self.scraper.spidermw.process_start_requests(start_requests, spider) slot = Slot(start_requests, close_if_idle, nextcall, scheduler) self.slot = slot self.spider = spider # 初始化去重过滤器中间件（默认是DUPEFILTER_CLASS = &apos;scrapy.dupefilters.RFPDupeFilter&apos;） yield scheduler.open(spider) # 生成pipline yield self.scraper.open_spider(spider) self.crawler.stats.open_spider(spider) yield self.signals.send_catch_log_deferred(signals.spider_opened, spider=spider) # 这个是调用前面注册成CallLaterOnce的_next_request函数。 slot.nextcall.schedule() slot.heartbeat.start(5) _next_reuqests 需要注意的是 在调用 _next_request_from_scheduler 的时候，调用了Download 第一次调用_next_request_from_scheduler是没有的数据的，调用self._crawl之后才会吧request放进队列里面12345678910111213141516171819202122232425262728def _next_request(self, spider): slot = self.slot if not slot: return if self.paused: return # 是否需要等待 while not self._needs_backout(spider): # 是否有下一个request，如果没有就break if not self._next_request_from_scheduler(spider): break # 如果还有start_requests 并且没有等待，那么就获取下一个request 并放入队列中 if slot.start_requests and not self._needs_backout(spider): try: request = next(slot.start_requests) except StopIteration: slot.start_requests = None except Exception: slot.start_requests = None logger.error(&apos;Error while obtaining start requests&apos;, exc_info=True, extra=&#123;&apos;spider&apos;: spider&#125;) else: # 将request放进队列 self.crawl(request, spider) if self.spider_is_idle(spider) and slot.close_if_idle: self._spider_idle(spider) _next_request_from_scheduler 主要做的事情 先从scheduler.next_request() 获取队列中的next_request 调用engine._download 下载（需要注意的是，这里经过了下载中间件） 下面会详细分析 下载完成之后调用engine._handle_downloader_output 后面会讲到。下面先讲下如何下载的。1234567891011121314151617181920def _next_request_from_scheduler(self, spider): slot = self.slot request = slot.scheduler.next_request() if not request: return d = self._download(request, spider) ## d.addBoth(self._handle_downloader_output, request, spider) d.addErrback(lambda f: logger.info(&apos;Error while handling downloader output&apos;, exc_info=failure_to_exc_info(f), extra=&#123;&apos;spider&apos;: spider&#125;)) d.addBoth(lambda _: slot.remove_request(request)) d.addErrback(lambda f: logger.info(&apos;Error while removing request from slot&apos;, exc_info=failure_to_exc_info(f), extra=&#123;&apos;spider&apos;: spider&#125;)) d.addBoth(lambda _: slot.nextcall.schedule()) d.addErrback(lambda f: logger.info(&apos;Error while scheduling new request&apos;, exc_info=failure_to_exc_info(f), extra=&#123;&apos;spider&apos;: spider&#125;)) return d engine.crawl 实际就是把request放进调度器重123456789101112def crawl(self, request, spider): assert spider in self.open_spiders, \ &quot;Spider %r not opened when crawling: %s&quot; % (spider.name, request) self.schedule(request, spider) self.slot.nextcall.schedule()def schedule(self, request, spider): self.signals.send_catch_log(signal=signals.request_scheduled, request=request, spider=spider) if not self.slot.scheduler.enqueue_request(request): self.signals.send_catch_log(signal=signals.request_dropped, request=request, spider=spider) scheduler.enqueue_request 如果计算指纹 参考看下scrapy.utils.request.py中的request_fingerprint函数12345678910111213def enqueue_request(self, request):# 如果不需要过滤 或者是指纹重复就不进队列 if not request.dont_filter and self.df.request_seen(request): self.df.log(request, self.spider) return False dqok = self._dqpush(request) if dqok: self.stats.inc_value(&apos;scheduler/enqueued/disk&apos;, spider=self.spider) else: self._mqpush(request) self.stats.inc_value(&apos;scheduler/enqueued/memory&apos;, spider=self.spider) self.stats.inc_value(&apos;scheduler/enqueued&apos;, spider=self.spider) return True 上面介绍了如果request如何进队列，下面介绍下scrapy是如何下载request ExecutionEngine._download1234567891011121314151617181920212223def _download(self, request, spider): slot = self.slot slot.add_request(request) def _on_success(response): assert isinstance(response, (Response, Request)) if isinstance(response, Response): response.request = request # tie request to response received logkws = self.logformatter.crawled(request, response, spider) logger.log(*logformatter_adapter(logkws), extra=&#123;&apos;spider&apos;: spider&#125;) self.signals.send_catch_log(signal=signals.response_received, \ response=response, request=request, spider=spider) return response def _on_complete(_): slot.nextcall.schedule() return _ # 这里下载 调用的是scrapy.core.download.Downloader.fetch dwld = self.downloader.fetch(request, spider) # 注册成功之后的调用 dwld.addCallbacks(_on_success) # 注册完成 dwld.addBoth(_on_complete) return dwld scrapy.core.download.Downloader.fetch 注意 这里有个时间是完成之后，会从active中去除掉改request123456789def fetch(self, request, spider): def _deactivate(response): self.active.remove(request) return response self.active.add(request) ## 这里调用的是scrapy.core.downloader.DownloaderMiddlewareManager dfd = self.middleware.download(self._enqueue_request, request, spider) return dfd.addBoth(_deactivate) scrapy.core.downloader.DownloaderMiddlewareManager.download 注意 这个函数主要是调用了下载中间件，最后再proecss_request执行完之后调用** scrapy.core.downloader.Downloader._enqueue_request** 才会真正的调用的下载 这里注册了三个事件, 这些调用定义的下载中间件。 默认的请参考default_setting.py DOWNLOADER_MIDDLEWARES_BASE配置 process_request 处理下载 process_response 处理返回 process_exception 处理异常 process_request 处理完之后会调用self._enqueue_request函数 这个函数12345678910111213141516171819202122232425262728293031323334353637383940414243def download(self, download_func, request, spider): @defer.inlineCallbacks def process_request(request): for method in self.methods[&apos;process_request&apos;]: response = yield method(request=request, spider=spider) if response is not None and not isinstance(response, (Response, Request)): raise _InvalidOutput(&apos;Middleware %s.process_request must return None, Response or Request, got %s&apos; % \ (six.get_method_self(method).__class__.__name__, response.__class__.__name__)) if response: defer.returnValue(response) defer.returnValue((yield download_func(request=request, spider=spider))) @defer.inlineCallbacks def process_response(response): assert response is not None, &apos;Received None in process_response&apos; if isinstance(response, Request): defer.returnValue(response) for method in self.methods[&apos;process_response&apos;]: response = yield method(request=request, response=response, spider=spider) if not isinstance(response, (Response, Request)): raise _InvalidOutput(&apos;Middleware %s.process_response must return Response or Request, got %s&apos; % \ (six.get_method_self(method).__class__.__name__, type(response))) if isinstance(response, Request): defer.returnValue(response) defer.returnValue(response) @defer.inlineCallbacks def process_exception(_failure): exception = _failure.value for method in self.methods[&apos;process_exception&apos;]: response = yield method(request=request, exception=exception, spider=spider) if response is not None and not isinstance(response, (Response, Request)): raise _InvalidOutput(&apos;Middleware %s.process_exception must return None, Response or Request, got %s&apos; % \ (six.get_method_self(method).__class__.__name__, type(response))) if response: defer.returnValue(response) defer.returnValue(_failure) ## 注册事件 deferred = mustbe_deferred(process_request, request) deferred.addErrback(process_exception) deferred.addCallback(process_response) return deferred scrapy.core.downloader.Downloader._enqueue_request/_process_queue/_download 这里涉及到了三个Downloader的函数 -_enqueue_request 将request 和spider封装成slot 放进队列后，调用_process_queue _process_queue 在判断是否需要延迟之后，调用_download，进行下载 _download 调用self.handlers.download_request(默认的是scrapy.core.downloader.handlers.DownloadHandlers)，这个函数会根据不同的scheme选择不同的handler. 默认的分为 1234567 &apos;data&apos;: &apos;scrapy.core.downloader.handlers.datauri.DataURIDownloadHandler&apos;, &apos;file&apos;: &apos;scrapy.core.downloader.handlers.file.FileDownloadHandler&apos;, &apos;http&apos;: &apos;scrapy.core.downloader.handlers.http.HTTPDownloadHandler&apos;, &apos;https&apos;: &apos;scrapy.core.downloader.handlers.http.HTTPDownloadHandler&apos;, &apos;s3&apos;: &apos;scrapy.core.downloader.handlers.s3.S3DownloadHandler&apos;, &apos;ftp&apos;: &apos;scrapy.core.downloader.handlers.ftp.FTPDownloadHandler&apos;,&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869def _enqueue_request(self, request, spider): key, slot = self._get_slot(request, spider) request.meta[self.DOWNLOAD_SLOT] = key def _deactivate(response): slot.active.remove(request) return response slot.active.add(request) self.signals.send_catch_log(signal=signals.request_reached_downloader, request=request, spider=spider) deferred = defer.Deferred().addBoth(_deactivate) slot.queue.append((request, deferred)) self._process_queue(spider, slot) return deferreddef _process_queue(self, spider, slot): if slot.latercall and slot.latercall.active(): return # Delay queue processing if a download_delay is configured now = time() delay = slot.download_delay() if delay: penalty = delay - now + slot.lastseen if penalty &gt; 0: slot.latercall = reactor.callLater(penalty, self._process_queue, spider, slot) return # Process enqueued requests if there are free slots to transfer for this slot while slot.queue and slot.free_transfer_slots() &gt; 0: slot.lastseen = now request, deferred = slot.queue.popleft() dfd = self._download(slot, request, spider) dfd.chainDeferred(deferred) # prevent burst if inter-request delays were configured if delay: self._process_queue(spider, slot) breakdef _download(self, slot, request, spider): # The order is very important for the following deferreds. Do not change! # 1. Create the download deferred dfd = mustbe_deferred(self.handlers.download_request, request, spider) # 2. Notify response_downloaded listeners about the recent download # before querying queue for next request def _downloaded(response): self.signals.send_catch_log(signal=signals.response_downloaded, response=response, request=request, spider=spider) return response dfd.addCallback(_downloaded) # 3. After response arrives, remove the request from transferring # state to free up the transferring slot so it can be used by the # following requests (perhaps those which came from the downloader # middleware itself) slot.transferring.add(request) def finish_transferring(_): slot.transferring.remove(request) self._process_queue(spider, slot) return _ return dfd.addBoth(finish_transferring) 至此，下载以及下载中间件的处理已经完成了。我们现在回到### _next_request_from_scheduler,看下前面所讲到的engine._handle_downloader_output。 ExecutionEngine._handle_downloader_output 如果返回的response是request 那么久调用crawl方法，将request放入scheduler 如果返回的response 不是request。调用scraper.enqueue_scrape方法，处理response.123456789101112def _handle_downloader_output(self, response, request, spider): assert isinstance(response, (Request, Response, Failure)), response # downloader middleware can return requests (for example, redirects) if isinstance(response, Request): self.crawl(response, spider) return # response is a Response or Failure d = self.scraper.enqueue_scrape(response, request, spider) d.addErrback(lambda f: logger.error(&apos;Error while enqueuing downloader output&apos;, exc_info=failure_to_exc_info(f), extra=&#123;&apos;spider&apos;: spider&#125;)) return d scrapy.core.scraper.Scraper.enqueue_scrape 注册结束处理事件(从active队列中移除掉)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# 将结果放入slot队列中def enqueue_scrape(self, response, request, spider): slot = self.slot dfd = slot.add_response_request(response, request) # 这个就是处理完成之后，已出队列中response def finish_scraping(_): slot.finish_response(response, request) self._check_if_closing(spider, slot) self._scrape_next(spider, slot) return _ dfd.addBoth(finish_scraping) dfd.addErrback( lambda f: logger.error(&apos;Scraper bug processing %(request)s&apos;, &#123;&apos;request&apos;: request&#125;, exc_info=failure_to_exc_info(f), extra=&#123;&apos;spider&apos;: spider&#125;)) self._scrape_next(spider, slot) return dfd# 取出队列中的元素，进行处理def _scrape_next(self, spider, slot): while slot.queue: response, request, deferred = slot.next_response_request_deferred() self._scrape(response, request, spider).chainDeferred(deferred)# 注册 两个时间def _scrape(self, response, request, spider): &quot;&quot;&quot;Handle the downloaded response or failure through the spider callback/errback&quot;&quot;&quot; assert isinstance(response, (Response, Failure)) dfd = self._scrape2(response, request, spider) # returns spiders processed output # 这个是处理错误 dfd.addErrback(self.handle_spider_error, request, response, spider) # 处理callback dfd.addCallback(self.handle_spider_output, request, response, spider) return dfd# 如果成功就调用下载中间件以及在经过中间件处理完之后调用call_spider函数，调用，否则就记录下载失败相关信息def _scrape2(self, request_result, request, spider): &quot;&quot;&quot;Handle the different cases of request&apos;s result been a Response or a Failure&quot;&quot;&quot; ## 这里调用的是scrapy.core.spidermw.SpiderMiddlewareManager.scrape_response if not isinstance(request_result, Failure): return self.spidermw.scrape_response( self.call_spider, request_result, request, spider) else: dfd = self.call_spider(request_result, request, spider) return dfd.addErrback( self._log_download_errors, request_result, request, spider)# 调用spider.callback和spider.parse函数def call_spider(self, result, request, spider): result.request = request dfd = defer_result(result) dfd.addCallbacks(request.callback or spider.parse, request.errback) return dfd.addCallback(iterate_spider_output) scrapy.core.spidermw.SpiderMiddlewareManager.scrape_response 先调用process_spider_input, 预处理response 注意此时没有调用spider中的callback或者是parse函数 执行完process_spider_input后 调用scrapy.core.scraper.Scraper.call_spider函数， 如果有异常会调用process_spider_exception 如果无异常会调用 process_spider_output 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778def scrape_response(self, scrape_func, response, request, spider): fname = lambda f:&apos;%s.%s&apos; % ( six.get_method_self(f).__class__.__name__, six.get_method_function(f).__name__) def process_spider_input(response): for method in self.methods[&apos;process_spider_input&apos;]: try: result = method(response=response, spider=spider) if result is not None: raise _InvalidOutput(&apos;Middleware &#123;&#125; must return None or raise an exception, got &#123;&#125;&apos; \ .format(fname(method), type(result))) except _InvalidOutput: raise except Exception: return scrape_func(Failure(), request, spider) return scrape_func(response, request, spider) def process_spider_exception(_failure, start_index=0): exception = _failure.value # don&apos;t handle _InvalidOutput exception if isinstance(exception, _InvalidOutput): return _failure method_list = islice(self.methods[&apos;process_spider_exception&apos;], start_index, None) for method_index, method in enumerate(method_list, start=start_index): if method is None: continue result = method(response=response, exception=exception, spider=spider) if _isiterable(result): # stop exception handling by handing control over to the # process_spider_output chain if an iterable has been returned return process_spider_output(result, method_index+1) elif result is None: continue else: raise _InvalidOutput(&apos;Middleware &#123;&#125; must return None or an iterable, got &#123;&#125;&apos; \ .format(fname(method), type(result))) return _failure def process_spider_output(result, start_index=0): # items in this iterable do not need to go through the process_spider_output # chain, they went through it already from the process_spider_exception method recovered = MutableChain() def evaluate_iterable(iterable, index): try: for r in iterable: yield r except Exception as ex: exception_result = process_spider_exception(Failure(ex), index+1) if isinstance(exception_result, Failure): raise recovered.extend(exception_result) method_list = islice(self.methods[&apos;process_spider_output&apos;], start_index, None) for method_index, method in enumerate(method_list, start=start_index): if method is None: continue # the following might fail directly if the output value is not a generator try: result = method(response=response, result=result, spider=spider) except Exception as ex: exception_result = process_spider_exception(Failure(ex), method_index+1) if isinstance(exception_result, Failure): raise return exception_result if _isiterable(result): result = evaluate_iterable(result, method_index) else: raise _InvalidOutput(&apos;Middleware &#123;&#125; must return an iterable, got &#123;&#125;&apos; \ .format(fname(method), type(result))) return chain(result, recovered) dfd = mustbe_deferred(process_spider_input, response) ## 注册了这个callback事件 dfd.addCallbacks(callback=process_spider_output, errback=process_spider_exception) return dfd 结至此，scrapy crawl xxx 整体流程分析完毕 核心类图 其中褐色表示方法 淡黄表示属性 仔细观察还是结合scrapy整体架构图的]]></content>
      <tags>
        <tag>scrapy</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊环境隔离]]></title>
    <url>%2F2019%2F07%2F16%2F%E8%81%8A%E8%81%8A%E5%85%B6%E4%BB%96%2F%E8%81%8A%E8%81%8A%E7%8E%AF%E5%A2%83%E9%9A%94%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[环境问题是日常开发以及服务上线碰到的问题。这里简单聊下自己所知道的环境隔离的方案 参考有赞环境隔离分享]]></content>
      <tags>
        <tag>环境隔离</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊dubbo与zookeeper]]></title>
    <url>%2F2019%2F07%2F16%2F%E8%81%8A%E8%81%8A%E5%85%B6%E4%BB%96%2F%E8%81%8A%E8%81%8Adubbo%E4%B8%8Ezookeeper%2F</url>
    <content type="text"><![CDATA[dubbo简单来讲就是一个远程调用RPC协议框架。本质上还是个协议 zookeeper是一个注册中心。本质上还是一个软件(software) dubbo 分组 vs zk分组dubbo 分组本意上是当应用有多种版本的时候，可以用group。 （从这点来看用来做环境弱隔离也是可以的）zk分组实际上是根据物理机ip分组。]]></content>
      <tags>
        <tag>java</tag>
        <tag>zookeeper</tag>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scrapy(1)深入-环境配置]]></title>
    <url>%2F2019%2F07%2F02%2Fpython%2Fscrapy-1%2F</url>
    <content type="text"><![CDATA[scrapy 是python 爬虫框架中用度最广，且简单的流行款。这里笔者依据源码，分析下 scrapy crawl xxx 之后的操作。 scrapy crawl xxx 调用流程 由setup.py 123entry_points=&#123; &apos;console_scripts&apos;: [&apos;scrapy = scrapy.cmdline:execute&apos;] &#125; 我们找到开始的python 脚本 scrapy.cmdline:execute 主要做了下面几件事情 初始化环境配置，在项目中运行项目 初始化CrawlProcess 调用run1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162def execute(argv=None, settings=None): if argv is None: argv = sys.argv # --- 兼容之前版本配置 --- if settings is None and &apos;scrapy.conf&apos; in sys.modules: from scrapy import conf if hasattr(conf, &apos;settings&apos;): settings = conf.settings # ------------------------------------------------------------------ # 初始化scrapy.cfg 以及 scrapy.settings.default_setting.py 中的配置 if settings is None: settings = get_project_settings() # set EDITOR from environment if available try: editor = os.environ[&apos;EDITOR&apos;] except KeyError: pass else: settings[&apos;EDITOR&apos;] = editor # 输出deprecated 配置 check_deprecated_settings(settings) # --- 兼容之前版本配置--- import warnings from scrapy.exceptions import ScrapyDeprecationWarning with warnings.catch_warnings(): warnings.simplefilter(&quot;ignore&quot;, ScrapyDeprecationWarning) from scrapy import conf conf.settings = settings # ------------------------------------------------------------------ # 判断是否在project中 inproject = inside_project() # 加载支持的命令 即package scrapy.commands下面的所有的文件 集合成字典 cmds = _get_commands_dict(settings, inproject) cmdname = _pop_command_name(argv) parser = optparse.OptionParser(formatter=optparse.TitledHelpFormatter(), \ conflict_handler=&apos;resolve&apos;) if not cmdname: _print_commands(settings, inproject) sys.exit(0) elif cmdname not in cmds: _print_unknown_command(settings, cmdname, inproject) sys.exit(2) cmd = cmds[cmdname] parser.usage = &quot;scrapy %s %s&quot; % (cmdname, cmd.syntax()) parser.description = cmd.long_desc() settings.setdict(cmd.default_settings, priority=&apos;command&apos;) cmd.settings = settings cmd.add_options(parser) # 解析参数 opts, args = parser.parse_args(args=argv[1:]) # 这里是对命令中一些参数进行设置 比如是 ```-logfile=xxx.xx```等 _run_print_help(parser, cmd.process_options, args, opts) # 爬虫运行类 cmd.crawler_process = CrawlerProcess(settings) # 执行 cmd 中的run类。 ** 在这里就是执行scrapy.commands.crawler.run函数** _run_print_help(parser, _run_command, cmd, args, opts) sys.exit(cmd.exitcode) scray.crawler.CrawlerProcess 这个类是继承了scray.crawler.CrawlerRunner，主要是增加了一个start函数。需要注意的是init 函数。 scray.crawler.CrawlerRunner.init 中有个属性是spider_loader 是所有爬虫类的加载器，默认使用的是 default_setting.py中的 SPIDER_LOADER_CLASS =’scrapy.spiderloader.SpiderLoader’。 scrapy.commands.crawler.run 这里就是调用了CrawlProcess.crawl/start 函数 123456789101112def run(self, args, opts): if len(args) &lt; 1: raise UsageError() elif len(args) &gt; 1: raise UsageError(&quot;running &apos;scrapy crawl&apos; with more than one spider is no longer supported&quot;) spname = args[0] self.crawler_process.crawl(spname, **opts.spargs) self.crawler_process.start() if self.crawler_process.bootstrap_failed: self.exitcode = 1 CrawlProcess.crawl/CrawlerRunner.crawl 实际上这个调用的是父类 rawlerRunner.crawl 主要工作 初始化并返回一个scrapy.crawler.Crawler实例 调用_crawl函数12345678910def crawl(self, crawler_or_spidercls, *args, **kwargs): if isinstance(crawler_or_spidercls, Spider): raise ValueError( &apos;The crawler_or_spidercls argument cannot be a spider object, &apos; &apos;it must be a spider class (or a Crawler object)&apos;) ## 返回一个scrapy.crawler.Crawler对象 crawler = self.create_crawler(crawler_or_spidercls) ## 调用 CrawlerRunner._crawl 函数 return self._crawl(crawler, *args, **kwargs) scrapy.crawler.Crawler 初始化1234567891011121314151617181920212223242526272829303132333435363738def __init__(self, spidercls, settings=None): if isinstance(spidercls, Spider): raise ValueError( &apos;The spidercls argument must be a class, not an object&apos;) if isinstance(settings, dict) or settings is None: settings = Settings(settings) self.spidercls = spidercls self.settings = settings.copy() self.spidercls.update_settings(self.settings) d = dict(overridden_settings(self.settings)) logger.info(&quot;Overridden settings: %(settings)r&quot;, &#123;&apos;settings&apos;: d&#125;) self.signals = SignalManager(self) self.stats = load_object(self.settings[&apos;STATS_CLASS&apos;])(self) handler = LogCounterHandler(self, level=self.settings.get(&apos;LOG_LEVEL&apos;)) logging.root.addHandler(handler) if get_scrapy_root_handler() is not None: # scrapy root handler already installed: update it with new settings install_scrapy_root_handler(self.settings) # lambda is assigned to Crawler attribute because this way it is not # garbage collected after leaving __init__ scope self.__remove_handler = lambda: logging.root.removeHandler(handler) self.signals.connect(self.__remove_handler, signals.engine_stopped) lf_cls = load_object(self.settings[&apos;LOG_FORMATTER&apos;]) self.logformatter = lf_cls.from_crawler(self) self.extensions = ExtensionManager.from_crawler(self) self.settings.freeze() self.crawling = False # spider 实例 初始化 self.spider = None # 核心engine self.engine = NoneCrawlerRunner._crawl 主要工作 上面初始化了一个Crawler 对象， 调用Crawler.crawl函数（初始化引擎等其他配置） 12345678910111213def _crawl(self, crawler, *args, **kwargs): self.crawlers.add(crawler) // Crawler.crawl d = crawler.crawl(*args, **kwargs) self._active.add(d) def _done(result): self.crawlers.discard(crawler) self._active.discard(d) self.bootstrap_failed |= not getattr(crawler, &apos;spider&apos;, None) return result return d.addBoth(_done) scapy.crawler.Crawler.crawl 主要工作 实例化spider （这个源码就跳过了，就是简单的创建spider实例，并将参数设置好） 实例化engine (下面详细讲下)12345678910111213141516171819202122232425262728293031@defer.inlineCallbacksdef crawl(self, *args, **kwargs): assert not self.crawling, &quot;Crawling already taking place&quot; self.crawling = True try: self.spider = self._create_spider(*args, **kwargs) ## 这个就是实例化了一个scrapy.engine.ExecutionEngine类 self.engine = self._create_engine() start_requests = iter(self.spider.start_requests()) yield self.engine.open_spider(self.spider, start_requests) yield defer.maybeDeferred(self.engine.start) except Exception: # In Python 2 reraising an exception after yield discards # the original traceback (see https://bugs.python.org/issue7563), # so sys.exc_info() workaround is used. # This workaround also works in Python 3, but it is not needed, # and it is slower, so in Python 3 we use native `raise`. if six.PY2: exc_info = sys.exc_info() self.crawling = False if self.engine is not None: yield self.engine.close() if six.PY2: six.reraise(*exc_info) raisedef _create_engine(self): return ExecutionEngine(self, lambda _: self.stop()) scrapy.engine.ExecutionEngine init 函数主要工作 加载调度器(默认是SCHEDULER = ‘scrapy.core.scheduler.Scheduler’) 加载下载器(默认是DOWNLOADER = ‘scrapy.core.downloader.Downloader’) 初始化 scrapy.core.scrapyer.Scraper 对象(下面详解)1234567891011121314151617class ExecutionEngine(object): def __init__(self, crawler, spider_closed_callback): self.crawler = crawler self.settings = crawler.settings self.signals = crawler.signals self.logformatter = crawler.logformatter self.slot = None self.spider = None self.running = False self.paused = False self.scheduler_cls = load_object(self.settings[&apos;SCHEDULER&apos;]) downloader_cls = load_object(self.settings[&apos;DOWNLOADER&apos;]) self.downloader = downloader_cls(crawler) # self.scraper = Scraper(crawler) self._spider_closed_callback = spider_closed_callback scrapy.core.scrapyer.Scraper 主要工作 (连接 middleware pipline spider) 初始化中间件 初始化item1234567891011class Scraper(object): def __init__(self, crawler): self.slot = None self.spidermw = SpiderMiddlewareManager.from_crawler(crawler) itemproc_cls = load_object(crawler.settings[&apos;ITEM_PROCESSOR&apos;]) self.itemproc = itemproc_cls.from_crawler(crawler) self.concurrent_items = crawler.settings.getint(&apos;CONCURRENT_ITEMS&apos;) self.crawler = crawler self.signals = crawler.signals self.logformatter = crawler.logformatter 到此核心插件初始化就完成了。]]></content>
      <tags>
        <tag>scrapy</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flink之Flink 简单介绍]]></title>
    <url>%2F2019%2F06%2F15%2FFlink%2FFlink-4-What-is-Flink%2F</url>
    <content type="text"><![CDATA[通过前几篇Flink 实战的文章，应该对Flink有点印象了。接下来，本片文章就简单从基本概念，场景， 架构， 特点等方面介绍下Flink. 什么是Flink 官网介绍如下Apache Flink is a framework and distributed processing engine for stateful computations over unbounded and bounded data streams. 个人理解Flink 是一个框架和分布式处理引擎，可以对无界或有界数据流进行状态计算。 注意加粗的几个字是核心。下面会聊到。 能够解决什么问题 通用处理流/批处理。 适用场景 实时智能推荐 复杂事件处理 实时数仓与ETL 流数据分析 实时报表分析 基本的概念 流/批处理处理思想 Flink对于批处理认为是有界的流处理。而Spark则认为流处理是更快的批处理。那个更有优势不重要，符合自己的需求并扩展性良好即可。 流 stream 有界流（批处理）vs 无界流（流处理） 有界流：一批连续的数据有开始有结束。（几何中的段的概念） 无界流：连续且无边界的数据流。（几何中射线的概念） 实时流和record Stream 实时流：举例天猫双十一大盘 record Stream： 离线数据清洗。 状态 state 状态可以简单理解为在处理数据的过程中，每个数据的改变都是状态的改变。 时间 time Event time 时间发生的时间 Process Time 消息被计算处理的时间 Ingestion Time 摄取时间：事件进入流处理系统的时间。 架构 组件结构 参考 API&amp;&amp;组件库层 Flink 同时提供了高级的流处理API(eg flatmap filter等),以及相对低级的processFunction. 在API的基础上，抽象除了不同场景下的组件库（FlinkML(机器学习)，CEP(复杂事件处理)等） Runtime层 是Flink的核心层。支持分布式作业的执行，任务调度等。 Deploy 层 部署相关。支持 local, yarn ,cloud等运行环境。 注意 FLink组件库调用API(StreamAPI或者是DataSetAPI)， API(StreamAPI或者是DataSetAPI) 生成jobGraph,并传递给Runtime层，jobGraph 根据不同的部署环境，采用不同的配置项（Flink内置的）执行。 Flink 集群运行时架构 参考 jobManagers(master) 负责 （至少有一个） 协调分布式执行 任务调度 协调检查 协调错误恢复 taskManagers(slave) 负责 （至少有一个） 执行数据流任务 缓存并交换流数据 client 作为数据源的输入，输入之后，可以被清除，也可以或者是处理其他的任务。 特性 流处理 支持高吞吐，低延迟，高性能流处理操作 支持高度灵活窗口(slideWindow SessionWindow等) 支持状态计算，同时具有exactly-once特性 支持 batch on stream API StreamAPI BatchAPI 众多Libraries 机器学习 图处理 。。。 总结Flink 本质上还是只是一个专门解决流批数据处理的框架，并且在性能，稳定，开发，部署等方面具有独到之处。如果我们日常需求中有涉及到大数据处理，且很可能会涉及到协同分布式等，Flink是一个很好的选择。 参考Flink 官网文档]]></content>
      <categories>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flink之收入最高出租车司机]]></title>
    <url>%2F2019%2F06%2F14%2FFlink%2FFlink-learning-in-action-3%2F</url>
    <content type="text"><![CDATA[本篇文章使用纽约市2009-1015年关于出租车驾驶的公共数据集，模拟现实数据流，获取一定时间内收入最高的出租车司机。 输入输出输入: 详见下面数据集输出：每个小时收入收入topN的driverId.额外条件：模拟丢失数据。每n条记录丢失一条数据。 数据集网站New York City Taxi &amp; Limousine Commission提供了关于纽约市从2009-1015年关于出租车驾驶的公共数据集。 下载：12wget http://training.ververica.com/trainingData/nycTaxiRides.gzwget http://training.ververica.com/trainingData/nycTaxiFares.gz TaxiRides 行程信息。每次出行包含两条记录。分别标识为 行程开始start 和 行程结束end。数据集结构 1234567891011rideId : Long // 唯一行程idtaxiId : Long // 出租车唯一id driverId : Long // 出租车司机唯一idisStart : Boolean // 是否是行程开始。false标识行程结束 startTime : DateTime // 行程开始时间endTime : DateTime // 行程结束时间 对于行程开始记录该值为 1970-01-01 00:00:00startLon : Float // 开始行程的经度startLat : Float // 开始行程的纬度endLon : Float // 结束的经度endLat : Float // 结束的纬度passengerCnt : Short // 乘客数量 TaxiRides 数据示例 TaxiFares 费用信息。 与上面行程信息对应 12345678rideId : Long // 唯一行程idtaxiId : Long // 出租车唯一iddriverId : Long // 出租车司机唯一idstartTime : DateTime // 行程开始时间paymentType : String // CSH or CRDtip : Float // tip for this ride (消费)tolls : Float // tolls for this ridetotalFare : Float // total fare collected TaxiFares 数据示例 分析通过上面的数据集以及输入输出的要求，可以分析如下：先根据上满两个数据集，生成输入流。再根据ridrId进行join，对join的结果进行窗口分割，最后对窗口内的数据入库计算收入最高的n个driverId. 思路 生成数据流。（读取上面两个数据集） 模拟丢失数据 filter 根据routId 将两个输入流join (这里其实是过滤掉了filter过滤掉的数据的对应数据) 对上面join的结果划分窗口，并以driverId分组计算窗口内收入，(这里就是简单对taxiFare进行取topN) 选出topN 输出。 部分核心实现新建两个class 表示ride和fare 完整代码 对应source 完整代码 主要逻辑 完整代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394public static void main(String[] args) throws Exception &#123; // 初始化enviorment StreamExecutionEnvironment environment = StreamExecutionEnvironment.getExecutionEnvironment(); // 设置事件事件 environment.setStreamTimeCharacteristic(TimeCharacteristic.EventTime); // 读取输入流 DataStreamSource&lt;TaxiFare&gt; taxiFareDataStreamSource = environment .addSource(new TaxiFareSource()); DataStream&lt;TaxiFare&gt; taxiFare = taxiFareDataStreamSource .keyBy(new KeySelector&lt;TaxiFare, Long&gt;() &#123; @Override public Long getKey(TaxiFare value) throws Exception &#123; return value.getRideId(); &#125; &#125;);// taxiFareDataStreamSource.print(); DataStreamSource&lt;TaxiRide&gt; taxiRideDataStreamSource = environment .addSource(new TaxiRideSource());// taxiRideDataStreamSource.print(); // 对source 过滤掉rided % 1000 == 0, 模拟现实世界丢失数据 DataStream&lt;TaxiRide&gt; taxiRide = taxiRideDataStreamSource.filter(new FilterFunction&lt;TaxiRide&gt;() &#123; @Override public boolean filter(TaxiRide value) throws Exception &#123; return value.isStart &amp;&amp; value.getRideId() % 1000 != 0; &#125; &#125;) .keyBy(new KeySelector&lt;TaxiRide, Long&gt;() &#123; @Override public Long getKey(TaxiRide value) throws Exception &#123; return value.getRideId(); &#125; &#125;); // join 将两个输入流以rideId为key， 合并 SingleOutputStreamOperator&lt;Tuple2&lt;TaxiFare, TaxiRide&gt;&gt; process = taxiFare.connect(taxiRide) .process(new ConnectProcess()); // 设置窗口 SingleOutputStreamOperator&lt;Tuple3&lt;Long, Float, Timestamp&gt;&gt; aggregate = process // 先将taxiFare 筛选出来，因为是要统计topN taxiFare .flatMap(new FlatMapFunction&lt;Tuple2&lt;TaxiFare, TaxiRide&gt;, TaxiFare&gt;() &#123; @Override public void flatMap(Tuple2&lt;TaxiFare, TaxiRide&gt; value, Collector&lt;TaxiFare&gt; out) throws Exception &#123; out.collect(value.f0); &#125; &#125;) // 因为是时间递增，所以watermark 很简单 .assignTimestampsAndWatermarks(new AscendingTimestampExtractor&lt;TaxiFare&gt;() &#123; @Override public long extractAscendingTimestamp(TaxiFare element) &#123;// System.out.println(element.getEventTime()); return element.getEventTime(); &#125; &#125;) // 根据 driverId 分组 .keyBy(new KeySelector&lt;TaxiFare, Long&gt;() &#123; @Override public Long getKey(TaxiFare value) throws Exception &#123; return value.getDriverId(); &#125; &#125;) // 设置时间窗口，每30min 计算一次最近1个小时的内driverId的总收入 .timeWindow(Time.hours(1), Time.minutes(30)) // 这个是累加函数,调用aggregate 结果会计算出同一个窗口中，每个driverId的收入总值 .aggregate(getAggregateFunction(), // 这个windowFunc 是格式化输出 new WindowFunction&lt;Float, Tuple3&lt;Long, Float, Timestamp&gt;, Long, TimeWindow&gt;() &#123; @Override public void apply(Long driverId, TimeWindow window, Iterable&lt;Float&gt; input, Collector&lt;Tuple3&lt;Long, Float, Timestamp&gt;&gt; out) throws Exception &#123; Float next = input.iterator().next(); out.collect(new Tuple3(driverId, next, new Timestamp(window.getEnd()))); &#125; &#125;); // topSize N int topSize = 3; aggregate // 根据时间进行分窗口 .keyBy(2) .timeWindow(Time.hours(1), Time.minutes(30)) .process(new topN(topSize)).print(); environment.execute("RideAndFareExercise"); &#125; 运行结果 参考[ververica]https://training.ververica.com/]]></content>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flink之获取topNWord]]></title>
    <url>%2F2019%2F06%2F12%2FFlink%2FFlink-learning-in-action-2%2F</url>
    <content type="text"><![CDATA[本片文章基于的逻辑上增加获取topN的逻辑，可以加深对Flink的认识。 描述中只是统计并输出了一定时间内的相同单词的次数，这次我们更深入点，统计一定时间内的前N个word. 思路： 获取运行环境 获取输入源 (socketTextStream) 对输入源进行算子操作 flatMap (拆分成单词，并给个默认值) keyby分组 timeWindow 划分时间窗口 reduce 对每一个窗口计算相同单词出现的次数 增加新窗口（里面的数据是上一步统计好次数之后的单词） 对上面窗口中的数据排序，输出前topN print 输出。 部分代码123456789101112// 对输入的数据进行拆分处理 DataStream&lt;Tuple2&lt;String, Long&gt;&gt; ret = socketTextStream.flatMap(split2Word()) // 根据tuple2 中的第一个值分组 .keyBy(0) // 设置窗口，每 30s为一个窗口，每5s计算一次 .timeWindow(Time.seconds(30), Time.seconds(5)) // 相同字母次数相加 .reduce(CountReduce()) // 滑动窗口，每 30s为一个窗口，每5s计算一次 （新增的逻辑） .windowAll(SlidingProcessingTimeWindows.of(Time.seconds(30), Time.seconds(5))) // 对同一个窗口的所有元素排序取前topSize （新增的逻辑） .process(new TopN(topSize)); TopN class 12345678910111213141516171819202122232425262728293031323334353637383940414243static class TopN extends ProcessAllWindowFunction&lt;Tuple2&lt;String, Long&gt;, Tuple2&lt;String, Long&gt;, TimeWindow&gt; &#123; private final int topSize; TopN(int topSize) &#123; this.topSize = topSize; &#125; @Override public void process(Context context, Iterable&lt;Tuple2&lt;String, Long&gt;&gt; elements, Collector&lt;Tuple2&lt;String, Long&gt;&gt; out) throws Exception &#123; /* 1 先创建一颗有序树， 2 依次往树里面放数据 3 如果超过topSize 那么就去掉树的最后一个节点 */ TreeMap&lt;Long, Tuple2&lt;String, Long&gt;&gt; treeMap = new TreeMap&lt;&gt;( new Comparator&lt;Long&gt;() &#123; @Override public int compare(Long o1, Long o2) &#123; return o2 &gt; o1 ? 1 : -1; &#125; &#125; ); for (Tuple2&lt;String, Long&gt; element : elements) &#123; treeMap.put(element.f1, element); if (treeMap.size() &gt; this.topSize) &#123; treeMap.pollLastEntry(); &#125; &#125; for (Entry&lt;Long, Tuple2&lt;String, Long&gt;&gt; longTuple2Entry : treeMap.entrySet()) &#123; out.collect(longTuple2Entry.getValue()); &#125; &#125; &#125; 完整代码完整代码请点我]]></content>
      <categories>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
</search>
